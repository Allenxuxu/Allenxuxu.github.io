<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on 徐旭 的博客</title><link>https://blog.iofree.xyz/posts/</link><description>Recent content in Posts on 徐旭 的博客</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 26 Dec 2021 10:53:19 +0800</lastBuildDate><atom:link href="https://blog.iofree.xyz/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Git自动设置不同邮箱</title><link>https://blog.iofree.xyz/posts/git/email/</link><pubDate>Sun, 26 Dec 2021 10:53:19 +0800</pubDate><guid>https://blog.iofree.xyz/posts/git/email/</guid><description>日常使用时，经常出现提交公司项目不小心用的私人邮箱，或者提交 Github 项目用了公司邮箱的情况，所以希望 Git 提交时能自动根据域名选择不同的邮箱。
全局设置必须配置用户名邮箱
git config --global user.useConfigOnly true 并且删除全局的 user.name 和 user.email 配置，这样本地如果有一些项目之前是读取全局配置邮箱的需要手动设置一下( 可以用复制下面的脚本里的部分代码进行自动设置，即 if 分支里的逻辑)。
所有的全局配置都在 ~/.gitconfig 文件中
设置 git hooks templates 目录
mkdir -p ~/.git-templates/hooks git config --global init.templatedir ~/.git-templates 然后在 ~/.git-templates/hooks目录里新建 post-checkout文件，内容如下：
#!/bin/bash if [[ $1 == 00000000000* ]]; then remote=`git remote -v | awk &amp;#39;/\(push\)$/ {print $2}&amp;#39;` email=xxx@xx.com # default name=&amp;#34;x x&amp;#34; if [[ $remote == *需要匹配的公司域名* ]]; then email=x@cc.com name=&amp;#34;x x&amp;#34; fi echo &amp;#34;Configuring user &amp;lt;name: $nameemail: $email&amp;gt;&amp;#34; git config user.</description></item><item><title>Go mod 小结</title><link>https://blog.iofree.xyz/posts/go/gomod/</link><pubDate>Wed, 12 May 2021 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/gomod/</guid><description>go.mod 文件 module example.com/foobar go 1.13 require ( example.com/apple v0.1.2 example.com/banana v1.2.3 example.com/banana/v2 v2.3.4 example.com/pineapple v0.0.0-20190924185754-1b0db40df49a ) exclude example.com/banana v1.2.4 replace example.com/apple v0.1.2 =&amp;gt; example.com/rda v0.1.0 replace example.com/banana =&amp;gt; example.com/hugebanana module：用于定义当前项目的模块路径。
go：用于设置预期的 Go 版本。
require：用于设置一个特定的模块版本。
exclude：用于从使用中排除一个特定的模块版本。
replace：用于将一个模块版本替换为另外一个模块版本。
版本表示方式 基于某一个commit的伪版本号
基本版本前缀-commit的UTC时间-commit的hash前12位 vX.0.0-yyyymmddhhmmss-abcdefabcdef vX.Y.Z-pre.0.yyyymmddhhmmss-abcdefabcdef
vX.Y.(Z+1)-0.yyyymmddhhmmss-abcdefabcdef
需要注意的是，同一个仓库的 v2.x.x 和之前小于 v2 大版本的代码被认为是两个不同的仓库。</description></item><item><title>Kafka 设计与理解</title><link>https://blog.iofree.xyz/posts/mq/kafka/</link><pubDate>Sun, 02 May 2021 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/mq/kafka/</guid><description>整体架构 图片来自 https://zhuanlan.zhihu.com/p/103249714
Producer 负责发布消息到Kafka broker。Producer发送消息到broker时，会根据分区策略选择将其存储到哪一个Partition。
常规的有轮询，随机等策略，主要是为了将消息均衡的发送到各个 partition，提高并行度，从而提高吞吐。常用的还有按 key 哈希，主要是为了实现业务 partition 有序的需求。
Consumer 消息消费者，从Kafka broker读取消息的客户端。
Consumer Group Consumer Group是Kafka提供的可扩展且具有容错性的消费者机制，每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。
Consumer Group下可以有一个或多个Consumer实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。 Group ID是一个字符串，在一个Kafka集群中，它标识唯一的一个Consumer Group。 Consumer Group下所有实例订阅的主题的单个分区，只能分配给组内的某个Consumer实例消费。 进度提交 消费者在消费的过程中需要记录自己消费了多少数据，即消费位置信息。在Kafka中，这个位置信息有个专门的术语：位移（Offset）。
Rebalance 何时触发 rebalance
组成员数量发生变化，有新成员加入，或者有成员实例崩溃退出。 订阅主题数量发生变化：Consumer Group可以使用正则表达式的方式订阅主题，比如果consumer.subscribe(Pattern.compile(“t.*c”))就表明该Group订阅所有以字母t开头、字母c结尾的主题。在Consumer Group的运行过程中，你新创建了一个满足这样条件的主题，那么该Group就会发生Rebalance 订阅主题的分区数发生变化，如主题扩容。 Rebalance本质上是一种协议，规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区Topic的每个分区。
比如某个Group下有20个Consumer实例，它订阅了一个具有100个分区的Topic。正常情况下，Kafka平均会为每个Consumer分配5个分区。这个分配的过程就叫Rebalance。
Rebalance 的流程 在消费者端，重平衡分为两个步骤：分别是 加入组 和 等待领导消费者（Leader Consumer）分配方案。这两个步骤分别对应两类特定的请求：JoinGroup请求和SyncGroup请求。
当组内成员加入组时，它会向 协调者 发送JoinGroup请求（后面会介绍协调者）。在该请求中，每个成员都要将自己订阅的主题上报，这样协调者就能收集到所有成员的订阅信息。一旦收集了全部成员的JoinGroup请求后，协调者会从这些成员中选择一个担任这个消费者组的领导者。
通常情况下，第一个发送JoinGroup请求的成员自动成为领导者。你一定要注意区分这里的领导者和之前我们介绍的领导者副本，它们不是一个概念。这里的领导者是具体的消费者实例，它既不是副本，也不是协调者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。
选出领导者之后，协调者会把消费者组订阅信息封装进JoinGroup请求的响应体中，然后发给领导者，由领导者统一做出分配方案后，进入到下一步：发送SyncGroup请求。
在这一步中，领导者向协调者发送SyncGroup请求，将刚刚做出的分配方案发给协调者。值得注意的是，其他成员也会向协调者发送SyncGroup请求，只不过请求体中并没有实际的内容。这一步的主要目的是让协调者接收分配方案，然后统一以SyncGroup响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。
JoinGroup请求的主要作用是将组成员订阅信息发送给领导者消费者，待领导者制定好分配方案后，重平衡流程进入到SyncGroup请求阶段。
SyncGroup请求的主要目的，就是让协调者把领导者制定的分配方案下发给各个组内成员。当所有成员都成功接收到分配方案后，消费者组进入到Stable状态，即开始正常的消费工作。
正常情况下，每个组内成员都会定期汇报位移给协调者。当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速地上报自己的位移信息，然后再开启正常的JoinGroup/SyncGroup请求发送。
Broker Kafka集群包含一个或多个服务器，这种服务器被称为broker。一个 broker 可以容纳多个 topic。brocker 是 kafka 中的核心组件，负责消息的存储，分区，路由信息的管理等。</description></item><item><title>Go1.16 embed 和 Vue</title><link>https://blog.iofree.xyz/posts/practice/gin-vue/</link><pubDate>Tue, 20 Apr 2021 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/practice/gin-vue/</guid><description>vue 相关代码： https://github.com/Allenxuxu/ginvue
先全局安装下 vue cli 并创建一个 demo 项目
npm install -g @vue/cli vue create web 然后我们进入 web 目录，修改生成的 package.json 文件调整一下 build 生成的静态文件目录。
&amp;ndash;dest 是指定输出的目录
**&amp;ndash;no-clean 是让他不要每次覆盖我们的目录，因为后面我们会放一个 go 文件到那个目录。 **
&amp;quot;build&amp;quot;: &amp;quot;vue-cli-service build --no-clean --dest ../static&amp;quot;, 再新增一个 vue.config.js 文件来修改下 , 这里将 production 的 publicPath 修改成带一个前缀 /ui/ , 这里主要就是为了后面我们的go 代码路由设置方便，所有的前端静态文件请求都带上 /ui 前缀，和后端 API 接口带 /api 前缀区分。
module.exports = { publicPath: process.env.NODE_ENV === 'production' ? '/ui/' : '/' } 最后我们再 web 目录运行 npm run build，会生成一个 static 目录（也就是我们修改的 package.</description></item><item><title>Golang slice map channel 小技巧</title><link>https://blog.iofree.xyz/posts/go/go-slice-map-channel/</link><pubDate>Sat, 17 Apr 2021 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/go-slice-map-channel/</guid><description>Slice vs Array Slice 和 Array 是不同的类型 package main func main() { s := make([]int, 100) printSlice(s) var a [100]int printArray(a) } func printSlice(s []int) { println(len(s)) // 100 println(cap(s)) // 100 } func printArray(a [100]int) { println(len(a)) // 100 println(cap(a)) // 100 } Slice 结构体
type slice struct { array unsafe.Pointer len int cap int } 下面的汇编表明，当类型是 slice 的时候，打印 len 或者 cap 的时候，会去栈上取数据:
MOVQ 0x28(SP), AX MOVQ AX, 0x8(SP) CALL 0xbfc [1:5]R_CALL:runtime.</description></item><item><title>RocketMQ 设计与理解</title><link>https://blog.iofree.xyz/posts/mq/rocketmq/</link><pubDate>Mon, 05 Apr 2021 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/mq/rocketmq/</guid><description>整体架构 RocketMQ 主要由 Producer、Broker、Consumer、Name Server 四个部分组成。
其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息，Name server 充当路由消息的提供者。
每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。
Topic Topic 是一种逻辑上的分区，是同一类消息的集合，每一个消息只能属于一个 Topic ，是RocketMQ进行消息订阅的基本单位。
每个 topic 会被分成很多 Messsage Queue ，和 Kafka 中的 Partition 概念一样，topic 的数据被分布在不同的 Message Queue 中。
在业务增长，消息量增大时，可以增大 topic 的 Message Queue，这样可以将压力分摊到更多的 broker 上。因为 Producer 可以发送消息的时候可以通过指定的算法，将消息均匀的发送到每个 Message Queue。
NameServer 生产者或消费者能够通过 Name Server查找各 Topic 相应的Broker IP 列表。 Name Server 可以多机部署变成一个集群保证高可用，但这些机器间彼此并不通信，也就是说三者的元数据舍弃了强一致性。
每一个 broker 启动时会向全部的 Name server 机器注册心跳，心跳里包含自己机器上 Topic 的拓扑信息，之后每隔 30s 更新一次，然后生产者和消费者启动的时候任选一台 Name Server 机器拉取所需的 Topic 的路由信息缓存在本地内存中，之后每隔 30s 定时从远端拉取更新本地缓存。</description></item><item><title>git 修改已经 commit 的邮箱信息</title><link>https://blog.iofree.xyz/posts/practice/git-amend/</link><pubDate>Thu, 10 Sep 2020 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/practice/git-amend/</guid><description>开发过程中，经常会出现提交邮箱搞错的情况。在公司项目中错误提交了自己的 GitHub 邮箱，或者在开源项目中提交了公司邮箱。
下面记录一下补救措施。
先修改 .git/config 或者 修改全局的，修改成你需要的邮箱信息。
[user] email = name@qq.com name = yourname git log 找到要修改的那一条 commit，复制要修改的commit 的前一条 commit 的哈希值。
git rebase -i {{刚刚复制的哈希值}}
# 或者最近 3 条 $ git rebase -i HEAD~3 然后后会出现一个 vim 打开的文本，将需要修改的 commit 信息前面的 pick 文本改成 edit，保存退出。
修改邮箱信息
git commit --amend --author=&amp;quot;name &amp;lt;name@qq.com&amp;gt;&amp;quot; --no-edit
然后 git rebase --continue
中间也可跳过或退出 rebase 模式git rebase --skip git rebase --abort
循环执行上面两步，当输出 Successfully rebased and updated refs/heads/master. 修改完成。</description></item><item><title>golang protobuf 字段为零值时 json 序列化忽略问题</title><link>https://blog.iofree.xyz/posts/practice/protobuf-json/</link><pubDate>Tue, 02 Jun 2020 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/practice/protobuf-json/</guid><description>protoc 编译生成的 pb.go 文件，默认情况下 tag 中会设置 json 忽略零值的返回属性 omitempty。
type Message struct { Header map[string]string `protobuf:&amp;#34;bytes,1,rep,name=header,proto3&amp;#34; json:&amp;#34;header,omitempty&amp;#34; protobuf_key:&amp;#34;bytes,1,opt,name=key,proto3&amp;#34; protobuf_val:&amp;#34;bytes,2,opt,name=value,proto3&amp;#34;` Body []byte `protobuf:&amp;#34;bytes,2,opt,name=body,proto3&amp;#34; json:&amp;#34;body,omitempty&amp;#34;` XXX_NoUnkeyedLiteral struct{} `json:&amp;#34;-&amp;#34;` XXX_unrecognized []byte `json:&amp;#34;-&amp;#34;` XXX_sizecache int32 `json:&amp;#34;-&amp;#34;` } 一个比较 hack 的方式，是在 pb.go 文件生成后，手动去删掉 omitempty 。每次手动去删除，比较麻烦且容易出错，下面提供一个 Makefile ，每次生成 pb.go 的时候就去删除 omitempty 。
proto: protoc --proto_path=. --go_out=. --micro_out=. config/config.proto ls config/*.pb.go | xargs -n1 -IX bash -c &amp;#39;sed s/,omitempty// X &amp;gt; X.tmp &amp;amp;&amp;amp; mv X{.tmp,}&amp;#39; proto 目标的第一个命令是调用 protoc 根据 config/config.</description></item><item><title>go chan 实用示例</title><link>https://blog.iofree.xyz/posts/go/go-channel/</link><pubDate>Sat, 30 May 2020 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/go-channel/</guid><description>尝试发送 select { case c &amp;lt;- struct{}{}: default: fmt.Println(&amp;#34;chan 已满，发送不成功&amp;#34;) } 尝试接收 select { case v := &amp;lt;- c: default: fmt.Println(&amp;#34;chan 中没有信息，接收不成功&amp;#34;) } 标准编译器对尝试发送和尝试接收代码块做了特别的优化，使得它们的执行效率比多 case分支的普通 select代码块执行效率高得多。
无阻塞的检查一个 chan 是否关闭 假设我们可以保证没有任何协程会向一个通道发送数据，则我们可以使用下面的代码来（并发安全地）检查此通道是否已经关闭，此检查不会阻塞当前协程。
func IsClosed(c chan struct{}) bool { select { case &amp;lt;-c: return true default: } return false } 最快回应 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;time&amp;#34; ) func source(c chan&amp;lt;- int, id int) { rb := rand.</description></item><item><title>二叉堆与堆排序</title><link>https://blog.iofree.xyz/posts/algorithm/heap/</link><pubDate>Sat, 30 May 2020 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/algorithm/heap/</guid><description>二叉堆是一组能够用堆有序的完全二叉树排序的元素，一般用数组来存储。
大顶堆， 每个结点的值都大于或等于其左右孩子结点的值，其顶部为最大值。
小顶堆，每个结点的值都小于或等于其左右孩子结点的值，其顶部为最小值。
二叉堆 性质 根节点在数组中的位置是 1 左边子节点 2i 右子节点 2i+1 父节点 i / 2 最后一个非叶子节点为 len / 2 根节点在数组中的位置是 0 左子节点 2i + 1 右边子节点 2i+ 2 父节点的下标是 (i − 1) / 2 最后一个非叶子节点为 len / 2 - 1 图片来自知乎
实现 构造二叉堆 找到最后一个非叶子节点 ( len / 2 或者 len / 2 - 1） 从最后一个非叶子节点下标索引开始递减，逐个下沉 插入节点 在数组的最末尾插入新节点 将最后一个节点上浮，时间复杂度为O(log n) 比较当前节点与父节点 不满足 堆性质* *则交换 删除根节点 删除根节点用于堆排序</description></item><item><title>二叉树的遍历模版（递归，迭代）</title><link>https://blog.iofree.xyz/posts/algorithm/tree-traversal/</link><pubDate>Sun, 26 Apr 2020 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/algorithm/tree-traversal/</guid><description>图片来自 leetcode
深度优先遍历（dfs） 前序遍历 中序遍历 后序遍历 广度优先遍历（bfs） type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 深度优先遍历 递归 递归版本，代码比较简单，只需改变 append 数据的位置即可。
前序遍历 func preorderTraversal(root *TreeNode) []int { var ret []int helper(root, &amp;amp;ret) return ret } func helper(root *TreeNode, data *[]int) { if root == nil { return } *data = append(*data, root.Val) helper(root.Left, data) helper(root.Right, data) } 中序遍历 func inorderTraversal(root *TreeNode) []int { var ret []int helper(root, &amp;amp;ret) return ret } func helper(root *TreeNode, data *[]int) { if root == nil { return } helper(root.</description></item><item><title>Github Actions 配置 CI/CD 自动发布 docker 镜像</title><link>https://blog.iofree.xyz/posts/practice/github-action-docker/</link><pubDate>Thu, 02 Apr 2020 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/practice/github-action-docker/</guid><description>Github Actions 是 Github 内置的 CI/CD 工具，现在已经对所有的开源项目免费开放了。
本文主要记录使用 Github Actions 实践 CI/CD 的一些配置。
功能目标 代码静态检查 代码单元测试 release/tag 时自动 build 镜像并推送到 docker hub 项目 Dockerfile 和 Makefile 项目主要目录
. ├── LICENSE ├── Makefile ├── README.md ├── config-srv │ ├── Makefile │ └── main.go ├── deployments │ ├── docker │ │ ├── config-srv │ │ │ └── Dockerfile ├── go.mod ├── go.sum config-srv 目录：服务代码 deployments 目录：所有服务的 Dockerfile Makefile 顶层 Makefile：build Docker 镜像 我们先看下顶层的 Makefile</description></item><item><title>go-micro 动态加载插件源码分析</title><link>https://blog.iofree.xyz/posts/go-micro/go-micro-plugin/</link><pubDate>Sat, 28 Mar 2020 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go-micro/go-micro-plugin/</guid><description>go-micro 框架支持动态加载插件，无需修改代码。
源码分析 启动服务前，设定 MICRO_PLUGIN 环境变量指定动态库 .so 文件路径，支持多个插件，逗号分割。程序启动前会读取 MICRO_PLUGIN 环境变量，并完成插件设定。
下面是其内部实现：
go-micro/service.go
func (s *service) Init(opts ...Option) { ... // setup the plugins for _, p := range strings.Split(os.Getenv(&amp;quot;MICRO_PLUGIN&amp;quot;), &amp;quot;,&amp;quot;) { if len(p) == 0 { continue } // 加载 .so 文件 c, err := plugin.Load(p) if err != nil { logger.Fatal(err) } // go-micro 初始化插件 if err := plugin.Init(c); err != nil { logger.Fatal(err) } } 从上面的代码可以看出，service 初始化化的时候，读取 MICRO_PLUGIN 环境变量中指定的 .</description></item><item><title>[gev] 自定义协议支持</title><link>https://blog.iofree.xyz/posts/open-source/gev-protocol/</link><pubDate>Thu, 31 Oct 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/open-source/gev-protocol/</guid><description>https://github.com/Allenxuxu/gev
gev 是一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库，支持自定义协议，轻松快速搭建高性能服务器。
TCP 为什么会&amp;quot;粘包&amp;quot; TCP 本身就是面向流的协议，就是一串没有界限的数据。所以本质上来说 TCP 粘包是一个伪命题。
TCP 底层并不关心上层业务数据，会套接字缓冲区的实际情况进行包的划分，一个完整的业务数据可能会被拆分成多次进行发送，也可能会将多个小的业务数据封装成一个大的数据包发送（Nagle算法）。
gev 如何优雅处理 gev 通过回调函数 OnMessage 通知用户数据到来，回调函数中会将用户数据缓冲区（ringbuffer）通过参数传递过来。
用户通过对 ringbuffer 操作，来进行数据解包，获取到完整用户数据后再进行业务操作。这样又一个明显的缺点，就是会让业务操作和自定义协议解析代码堆在一起。
所以，最近对 gev 进行了一次较大改动，主要是为了能够以插件的形式支持各种自定义的数据协议，让使用者可以便捷处理 TCP 粘包问题，专注于业务逻辑。
做法如下，定义一个接口 Protocol
// Protocol 自定义协议编解码接口 type Protocol interface { UnPacket(c *Connection, buffer *ringbuffer.RingBuffer) (interface{}, []byte) Packet(c *Connection, data []byte) []byte } 用户只需实现这个接口，并注册到 server 中，当客户端数据到来时，gev 会首先调用 UnPacket 方法，如果缓冲区中的数据足够组成一帧，则将数据解包，并返回真正的用户数据，然后在回调 OnMessage 函数并将数据通过参数传递。
下面，我们实现一个简单的自定义协议插件，来启动一个 Server ：
| 数据长度 n | payload | | 4字节 | n 字节 | // protocol.</description></item><item><title>Uber Go 风格指南</title><link>https://blog.iofree.xyz/posts/go/uber-go-guide/</link><pubDate>Sun, 13 Oct 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/uber-go-guide/</guid><description>Uber Go 风格指南 译文：https://github.com/Allenxuxu/uber-go-guide 原文：https://github.com/uber-go/guide/blob/master/style.md 简介 风格是指规范代码的共同约定。风格一词其实是有点用词不当的，因为共同约定的范畴远远不止 gofmt 所做的源代码格式化这些。
本指南旨在通过详尽描述 Uber 在编写 Go 代码中的注意事项（规定）来解释其中复杂之处。制定这些注意事项（规定）是为了提高代码可维护性同时也让工程师们高效的使用 Go 的特性。
这份指南最初由 Prashant Varanasi 和 Simon Newton 编写，目的是让一些同事快速上手 Go 。多年来，已经根据其他人的反馈不断修改。
这份文档记录了我们在 Uber 遵守的 Go 惯用准则。其中很多准则是 Go 的通用准则，其他方面依赖于外部资源：
Effective Go The Go common mistakes guide 所有的代码都应该通过 golint 和 go vet 检查。我们建议您设置编辑器：
保存时自动运行 goimports 自动运行 golint 和 go vet 来检查错误 您可以在这找到关于编辑器设定 Go tools 的相关信息：
https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins
指南 指向接口（interface）的指针 你基本永远不需要一个指向接口的指针。你应该直接将接口作为值传递，因为接口的底层数据就是指针。
一个接口包含两个字段：
类型指针，指向某些特定类型信息的指针。 数据指针。如果存储数据是一个指针变量，那就直接存储。如果存储数据是一个值变量，那就存储指向该值的指针。 如果你需要接口方法来修改这些底层数据，那你必须使用指针。</description></item><item><title>Go 网络库并发吞吐量测试</title><link>https://blog.iofree.xyz/posts/open-source/gev-benchmark/</link><pubDate>Sun, 22 Sep 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/open-source/gev-benchmark/</guid><description>https://github.com/Allenxuxu/gev
本文主要测试 gev 网络库和其他三方 Go 网络库以及标准库的吞吐量对比。
测试对象 gev ：一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库 eviop ：evio 的优化版本 evio ：Fast event-loop networking for Go gnet ：eviop 的网络模型替换版本 net 标准库 测试方法 采用陈硕测试 muduo 使用的 ping pong 协议来测试吞吐量。
简单地说，ping pong 协议是客户端和服务器都实现 echo 协议。当 TCP 连接建立时，客户端向服务器发送一些数据，服务器会 echo 回这些数据，然后客户端再 echo 回服务器。这些数据就会像乒乓球一样在客户端和服务器之间来回传送，直到有一方断开连接为止。这是用来测试吞吐量的常用办法。
测试的客户端代码： https://github.com/Allenxuxu/gev/blob/master/benchmarks/client/main.go
测试脚本：https://github.com/Allenxuxu/gev/blob/master/benchmarks/bench-pingpong.sh
主要做两项测试：
单线程单个 work 协程测试，测试并发连接数为 10/100/1000/10000 时的吞吐量 4线程4个 work 协程测试，测试并发连接数为 10/100/1000/10000 时的吞吐量 所有测试中，ping pong 消息的大小均为 4096 bytes，客户端始终是4线程运行。</description></item><item><title>开源 gev: Go 实现基于 Reactor 模式的非阻塞 TCP 网络库</title><link>https://blog.iofree.xyz/posts/open-source/gev/</link><pubDate>Thu, 19 Sep 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/open-source/gev/</guid><description>gev 轻量、快速的 Golang 网络库 gev 是一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库，支持自定义协议，轻松快速搭建高性能服务器。
为什么有 gev Golang 的 goroutine 虽然非常轻量，但是每启动一个 goroutine 仍需要 4k 左右的内存。读了鸟窝大佬的文章【百万 Go TCP 连接的思考: epoll方式减少资源占用】后，便去研究了了下 evio。
evio 虽然非常快，但是仍然存在一些问题，便尝试去优化它，于是有了 eviop 项目。关于 evio 的问题可以看我的另一篇博文 【Golang 网络库evio一些问题/bug和思考】。在优化 evio 完成 eviop 的过程中，因为其网络模型的缘故，愈加感觉修改它非常麻烦，成本比重新搞一个还高。
最终决定自己重搞一个，更加轻量，不需要的全去掉。加上大学时学习过 muduo ，便参考 muduo 的使用的 Reactor 模型实现 gev 。
在 linux 环境下，gev 底层使用 epoll ，这是 gev 会专注优化的地方。在 mac 下底层使用 kqueue，可能不会过多关注这部分的优化，毕竟很少有用 mac 做服务器的（Windows 环境&amp;quot;暂&amp;quot;不支持）。
特点 基于 epoll 和 kqueue 实现的高性能事件循环 支持多核多线程 动态扩容 Ring Buffer 实现的读写缓冲区 异步读写 SO_REUSEPORT 端口重用支持 支持 WebSocket 支持定时任务，延时任务 支持自定义协议，处理 TCP 粘包 网络模型 gev 只使用极少的 goroutine, 一个 goroutine 负责监听客户端连接，其他 goroutine （work 协程）负责处理已连接客户端的读写事件，work 协程数量可以配置，默认与运行主机 CPU 数量相同。</description></item><item><title>Go net/http 浅析</title><link>https://blog.iofree.xyz/posts/go/go-http/</link><pubDate>Sun, 15 Sep 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/go-http/</guid><description>GO HTTP Server 使用标准库构建 HTTP 服务 Go 语言标准库自带一个完善的 net/http 包，可以很方便编写一个可以直接运行的 Web 服务。
package main import ( &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; ) func hello(w http.ResponseWriter, r *http.Request) { log.Println(r.Method, r.Host, r.RequestURI) w.Write([]byte(&amp;#34;hello&amp;#34;)) } func main() { http.HandleFunc(&amp;#34;/hello&amp;#34;, hello) //设置访问的路由 // http.Handle(&amp;#34;/hello&amp;#34;, http.HandlerFunc(hello)) // 和上面写法等价 err := http.ListenAndServe(&amp;#34;:9090&amp;#34;, nil) //设置监听的端口并启动 HTTP 服务 if err != nil { log.Fatal(&amp;#34;ListenAndServe: &amp;#34;, err) } } $ curl -v 127.0.0.1:9090/hello * Trying 127.0.0.1... * TCP_NODELAY set * Connected to 127.</description></item><item><title>Go channel 拷贝问题</title><link>https://blog.iofree.xyz/posts/go/go-channel-copy/</link><pubDate>Wed, 21 Aug 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/go-channel-copy/</guid><description>Go 的 channel 使用非常方便，但是总听说 channel 会拷贝传递的数据，生怕频繁拷贝影响效率。
究竟是怎么个拷贝法呢，下面会有两个 demo 验证下。
先说结论： Go channel 的发送接收数据的拷贝和 Go 的函数传参道理是一样的，都是默认的值拷贝。 如果你传递一个值，那么 Go 会复制一份新的；如果传递一个指针，则会拷贝这个指针，不会去拷贝这个指针所指的变量（这一点 C++ 选手可能会理解比较深）。
所以，如果你需要通过 channel 传递一个很大的 struct ，那么应该传递 指针。但是，要非常注意通过 channel 发送后，不要修改这个指，这会导致线程间潜在的竞争。
下面是两个验证的小 demo：
通过 channel 传递指针 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) func recv(ch &amp;lt;-chan *int) { time.Sleep(1 * time.Second) out := &amp;lt;-ch fmt.Println(&amp;#34;recv : &amp;#34;, out, *out) } func main() { i := 1 ch := make(chan *int, 2) fmt.</description></item><item><title>拥抱 Go module</title><link>https://blog.iofree.xyz/posts/go/go-module/</link><pubDate>Tue, 20 Aug 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/go-module/</guid><description>go get 拉包一直时国内选手头疼的问题，虽然梯子可以解决问题，但是总是有很慢的时候，而且需要每台电脑都配置，特别是 CI 的服务器等，很烦人。
七牛云开源了 goproxy ，还免费提供 https://goproxy.cn 作为代理来拉包。
不过 GOPROXY 只有在 Go module 下才能使用，索性全面拥抱 Go module 一劳永逸。
修改一下配置文件，即可：
sudo vi /etc/profile 在最后添加如下内容，开启 Go module 和代理：
export GO111MODULE=on export GOPROXY=https://goproxy.cn 让配置文件立即生效
source /etc/profile 接下来就可以畅快 Go 了！
PS： Go 1.16 已经默认开启 go moudle了。</description></item><item><title>Golang 网络库 evio 一些问题/bug和思考</title><link>https://blog.iofree.xyz/posts/open-source/evio-code-bug/</link><pubDate>Thu, 15 Aug 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/open-source/evio-code-bug/</guid><description>Fast event-loop networking for Go
最近翻了 evio 的源码，发现一些问题，主要集中在 linux 平台 epoll 上和读写的处理。
用来唤醒 epoll 的 eventfd 写入数据没有读出 listen 的 fd 注册到所有事件循环，epoll 的惊群问题 loopWrite 在内核缓冲区满，无法一次写入时，出现写入数据丢失 eventfd 的使用问题 在 internal/internal_linux.go 中封装了 epoll 的使用 API 。
// Poll ... type Poll struct { fd int // epoll fd wfd int // wake fd notes noteQueue } 在 OpenPoll 时，会创建一个 eventfd 并将 fd 赋值给 Poll 的 wfd 成员， 并且注册到 epoll 监听可读事件。</description></item><item><title>Golang 高性能网络库 evio 源码解析</title><link>https://blog.iofree.xyz/posts/open-source/evio-code/</link><pubDate>Tue, 06 Aug 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/open-source/evio-code/</guid><description>阅读前提：了解 epoll
evio 是一个基于事件驱动的网络框架，它非常轻量而且相比 Go net 标准库更快。其底层使用epoll 和 kqueue 系统调度实现。
原理 evio 是 Reactor 模式的简单实现。Reactor 本质就是“non-blocking IO + IO multiplexing”，通过非阻塞IO+ IO 多路复用来处理并发。程序运行一个或者多个事件循环，通过在事件循环中注册回调的方式实现业务逻辑。
evio 将所有文件描述符设为非阻塞，并注册到事件循环（ epoll / kqueue ）中。相较于传统的 per thread per connection 的处理方法，线程使用更少，线程资源利用率更高。
evio 需要在服务启动前，注册回调函数，当事件循环中有事件到来时，会调用回调函数处理。
使用示例 先从一个简单的 echo server 的例子来了解 evio 。
package main import ( &amp;#34;flag&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;strings&amp;#34; &amp;#34;github.com/tidwall/evio&amp;#34; ) func main() { var port int var loops int var udp bool var trace bool var reuseport bool var stdlib bool flag.</description></item><item><title>Golang 极简入门教程</title><link>https://blog.iofree.xyz/posts/go/go-tutorials/</link><pubDate>Sun, 04 Aug 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/go-tutorials/</guid><description>Hello World 我们以传统的“hello world”案例开始吧。
package main import &amp;#34;fmt&amp;#34; func main() { fmt.Println(&amp;#34;Hello World&amp;#34;) } Go的源文件以 .go 为后缀名，这些文件名均由小写字母（推荐做法）组成且不包含空格和其他特殊字符，如 main.go 。如果文件名由多个部分组成，则使用下划线 _ 对它们进行分隔，如 main_test.go 。
Go是一门编译型语言,Go语言的工具链将源代码及其依赖转换成计算机的机器指令。Go语言提供的工具都通过一个单独的命令 go 调用，go 命令有一系列子命令。
$ go help Go is a tool for managing Go source code. Usage: go &amp;lt;command&amp;gt; [arguments] The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages .</description></item><item><title>dokcer swarm 部署go-micro微服务应用</title><link>https://blog.iofree.xyz/posts/docker/docker-swarm/</link><pubDate>Thu, 18 Jul 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/docker/docker-swarm/</guid><description>微服务应用使用容器部署非常方便，但是当应用服务注册自身地址(ip:port)到服务注册中心的时候，如果注册的是容器内的ip，别的服务是无法访问到的。
解决这个问题，可以在运行容器的时候指定网络模式为 host (&amp;ndash;net=host) ，这样就可以跳过 Docker 的独立网络栈，直接通过本机IP端口就可以访问，但是这样会大量占用本地端口。
最好的场景还是后端服务都在容器网络中，仅 API 网关暴露一个端口供外部访问，但是同时还后端服务还需要能实现跨机器的网络连通。
早期 Docker 本身的容器网络本身并不支持跨机器，也就是说明如果容器部署在不同的节点（服务器）上面，只能通过暴露端口到宿主机上，再通过宿主机之间进行通信。Docker 12.0 之后的版本自带 Docker Swarm，Docker Swarm 的 Overlay 网络驱动可以实现跨主机网络通信。Kubernetes 固然好，但是同时也非常重，学习成本也很大，Swarm 在小项目中还是有用武之地的。
dokcer swarm 集群搭建 准备两台安装有 docker 的机器： 192.168.0.1 192.168.0.2
192.168.0.1 创建master节点
# docker swarm init # docker swarm join \ --token SWMTKN-1-3uu3gjkdt6xgk06wd1c9gfog8xec99ga69ilcclyzyk181n5ki-6f7frw75gvpdwsl1yvpf885lw \ 192.168.0.1:2377 This node joined a swarm as a worker. 复制上面的 docker swarm join &amp;hellip; 在 192.168.0.2 上执行，即将本机加入 swarm 集群。
至此，我们已经创建了一个最基础的 swarm 的集群，执行命令查看：
# docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS r76ighlnw0p2r0tbd9wmoqaep server2 Ready Active rzqbzl58hlu89xoty4cedn0er * server1 Ready Active Leader 创建 overlay 网络 先创建一个可以跨机器的 overlay 网络</description></item><item><title>Go Micro hystrix 熔断</title><link>https://blog.iofree.xyz/posts/go-micro/go-micro-hystrix/</link><pubDate>Thu, 27 Jun 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go-micro/go-micro-hystrix/</guid><description>hystrix-go hystrix是Netflix开源的一个JAVA项目，不过GitHub也有golang的实现版本hystrix-go
hystrix-dashboard hystrix并没有自带一个仪表盘，无法直观的查看接口的健康状况。所以，我们采用GitHub的一个开源实现hystrix-dashboard。
docker run --name hystrix-dashboard -d -p 8081:9002 mlabouardy/hystrix-dashboard:latest micro API网关插件 关于hystrix的工作原理，可以查阅相关资料，这里只讲解如何封装插件在micro API网关中使用。
err := hystrix.Do(&amp;quot;my_command&amp;quot;, func() error { // talk to other services return nil }, nil) 使用hystrix.Do() 同步API，第一个参数是command, 应该是与当前请求一一对应的一个名称，如入“GET-/test”。第二个参数传入一个函数，函数包含我我们自己的错误逻辑，当请求失败时应该返回error。hystrix会根据我们的失败率执行熔断策略。
封装Handler // BreakerWrapper hystrix breaker func BreakerWrapper(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { name := r.Method + &amp;quot;-&amp;quot; + r.RequestURI log.Println(name) err := hystrix.Do(name, func() error { sct := &amp;amp;status_code.StatusCodeTracker{ResponseWriter: w, Status: http.StatusOK} h.</description></item><item><title>Go Micro 服务健康检查</title><link>https://blog.iofree.xyz/posts/go-micro/go-micro-ttl/</link><pubDate>Thu, 27 Jun 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go-micro/go-micro-ttl/</guid><description>服务健康检查 在微服务架构中，每个服务都会存在多个实例，可能部署在不同的主机中。因为网络或者主机等不确定因素，每个服务都可能会出现故障。我们需要能够监控每个服务实例的健康状态，当一个服务故障时，及时将它从注册中心删除。
实现 micro提供两个方法可以直接实现健康检查功能
micro.RegisterTTL(time.Second*30), micro.RegisterInterval(time.Second*20), Interval就是间隔多久服务会重新注册 TTL就是注册服务的过期时间，如果服务挂了，超过过期时间后，注册中心也会将服务删除
micro内部服务注册的流程 当我们执行service.Run() 时内部会执行Start() 在Start函数中又会执行s.opts.Server.Start()，方法的实现在go-micro/server/rpc_server.go中。 我们跳转到内部server的Start方法 可以发现micro使用一个定时器按照间隔时间去自动重新注册。当服务意外故障，无法向注册中心重新注册时，如果超过了设定的TTL时间，注册中心就会将服务删除。
修改源码 service := grpc.NewService( micro.Name(&amp;quot;go.micro.srv.hello&amp;quot;), micro.WrapHandler(ocplugin.NewHandlerWrapper(t)), + micro.RegisterTTL(time.Second*15), + micro.RegisterInterval(time.Second*10), // micro.Version(&amp;quot;latest&amp;quot;), ) service := web.NewService( web.Name(name), web.Version(&amp;quot;lastest&amp;quot;), + web.RegisterTTL(time.Second*15), + web.RegisterInterval(time.Second*10), web.MicroService(grpc.NewService()), )</description></item><item><title>Golang实现默认参数</title><link>https://blog.iofree.xyz/posts/go/go-options/</link><pubDate>Thu, 27 Jun 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go/go-options/</guid><description>在golang 中是不支持默认参数的，micro中有一种优雅的实现方法(并非 micro 首创)，叫做 Functional Options Patter。Functional Options 可以用来实现简洁的支持默认参数的函数方法。
options package server import ( &amp;#34;time&amp;#34; ) type Options struct { ConnectTimeOut time.Duration Name string Address string } type Option func(*Options) func newOptions(opt ...Option) Options { opts := Options{} for _, o := range opt { o(&amp;amp;opts) } if len(opts.Address) == 0 { opts.Address = DefaultAddress } if len(opts.Name) == 0 { opts.Name = DefaultName } if opts.ConnectTimeOut == time.Duration(0) { opts.</description></item><item><title>Go Micro API网管增加 JWT 鉴权</title><link>https://blog.iofree.xyz/posts/go-micro/go-micro-gateway-jwt/</link><pubDate>Mon, 24 Jun 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go-micro/go-micro-gateway-jwt/</guid><description>micro API网关 micro API网关是基于go-micro开发的，具有服务发现，负载均衡和RPC通信的能力。
业界普遍做法是将鉴权，限流，熔断等功能也纳入API网关。micro API网关本身是可插拔的，可以通过新增插件的方式加入其他功能。
JWT (JSON Web Token) JWT是是微服务中常用的授权技术，关于JWT的技术原理可以参考阮一峰的博文
JWT库封装 lib/token 目录下封装了JWT的库。有一点特殊的是，库中利用consul的KV存储和micro的go-config库实现了动态更新JWT的PrivateKey功能，实际生产中还是应该使用拥有发布和权限管理的配置中心。 go-config 是micro作者实现的一个可动态加载、可插拔的配置库，可以从多种格式文件或者远程服务获取配置。详情可以参考文档中文文档|英文文档 PrivateKey是JWT在编解码时使用的私钥，一旦泄漏，客户端便可以利用这个私钥篡改、伪造Token。所以一般生产环境中都必须具备动态更新私钥的能力，一旦发现泄漏可以立即更改，或者定期更换私钥，提高安全性。 // InitConfig 初始化 func (srv *Token) InitConfig(address string, path ...string) { consulSource := consul.NewSource( consul.WithAddress(address), ) srv.conf = config.NewConfig() err := srv.conf.Load(consulSource) if err != nil { log.Fatal(err) } value := srv.conf.Get(path...).Bytes() if err != nil { log.Fatal(err) } srv.put(value) log.Println(&amp;quot;JWT privateKey:&amp;quot;, string(srv.get())) srv.enableAutoUpdate(path...) } func (srv *Token) enableAutoUpdate(path .</description></item><item><title>Go Micro jaeger 分布式链路追踪</title><link>https://blog.iofree.xyz/posts/go-micro/go-micro-jaeger/</link><pubDate>Mon, 24 Jun 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go-micro/go-micro-jaeger/</guid><description>安装jaeger jaeger提供一个all in one 的docker镜像，可以快速搭建实验环境
docker run -d --name jaeger -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:1.6 OpenTracing OpenTracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。 OpenTracing提供了用于运营支撑系统的和针对特定平台的辅助程序库。 jaeger兼容OpenTracing API，所以我们使用OpenTracing的程序库可以方便的替换追踪工具。 OpenTracing中文文档
jaeger使用 封住一下jaeger的初始化操作方便使用，详细用法可以查看 jaeger-client-go
// lib/tracer // NewTracer 创建一个jaeger Tracer func NewTracer(servicename string, addr string) (opentracing.Tracer, io.Closer, error) { cfg := jaegercfg.Configuration{ ServiceName: servicename, Sampler: &amp;amp;jaegercfg.SamplerConfig{ Type: jaeger.SamplerTypeConst, Param: 1, }, Reporter: &amp;amp;jaegercfg.ReporterConfig{ LogSpans: true, BufferFlushInterval: 1 * time.</description></item><item><title>Go Micro 重试机制</title><link>https://blog.iofree.xyz/posts/go-micro/go-micro-retry/</link><pubDate>Thu, 20 Jun 2019 11:22:38 +0800</pubDate><guid>https://blog.iofree.xyz/posts/go-micro/go-micro-retry/</guid><description>在分布式系统中，经常会有服务出现故障，所以良好的重试机制可以大大的提高系统的可用性。本文主要分析micro的客户端重试机制，以及实例演示。
micro 重试实现 micro框架提供方法设置客户端重试的次数。
Client.Init( client.Retries(3), ) 当client请求失败时，客户端会根据selector的策略选择下一个节点重试请求。这样当一个服务实例故障时，客户端可以自动调用另一个实例。
我们来看看micro 客户端内部重试的实现：
go-micro\client\rpc_client.go
func (r *rpcClient) Call(ctx context.Context, request Request, response interface{}, opts ...CallOption) error { ... //客户端call 调用函数， 在下面的循环中调用 call := func(i int) error { // call backoff first. Someone may want an initial start delay t, err := callOpts.Backoff(ctx, request, i) if err != nil { return errors.InternalServerError(&amp;quot;go.micro.client&amp;quot;, &amp;quot;backoff error: %v&amp;quot;, err.Error()) } // only sleep if greater than 0 if t.</description></item></channel></rss>