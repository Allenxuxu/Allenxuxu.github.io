[{"content":"整体架构  图片来自 https://zhuanlan.zhihu.com/p/103249714\n Producer 负责发布消息到Kafka broker。Producer发送消息到broker时，会根据分区策略选择将其存储到哪一个Partition。\n常规的有轮询，随机等策略，主要是为了将消息均衡的发送到各个 partition，提高并行度，从而提高吞吐。常用的还有按 key 哈希，主要是为了实现业务 partition 有序的需求。\nConsumer 消息消费者，从Kafka broker读取消息的客户端。\nConsumer Group Consumer Group是Kafka提供的可扩展且具有容错性的消费者机制，每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n Consumer Group下可以有一个或多个Consumer实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。 Group ID是一个字符串，在一个Kafka集群中，它标识唯一的一个Consumer Group。 Consumer Group下所有实例订阅的主题的单个分区，只能分配给组内的某个Consumer实例消费。  进度提交 消费者在消费的过程中需要记录自己消费了多少数据，即消费位置信息。在Kafka中，这个位置信息有个专门的术语：位移（Offset）。\nRebalance 何时触发 rebalance\n 组成员数量发生变化，有新成员加入，或者有成员实例崩溃退出。 订阅主题数量发生变化：Consumer Group可以使用正则表达式的方式订阅主题，比如果consumer.subscribe(Pattern.compile(“t.*c”))就表明该Group订阅所有以字母t开头、字母c结尾的主题。在Consumer Group的运行过程中，你新创建了一个满足这样条件的主题，那么该Group就会发生Rebalance 订阅主题的分区数发生变化，如主题扩容。  Rebalance本质上是一种协议，规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区Topic的每个分区。\n比如某个Group下有20个Consumer实例，它订阅了一个具有100个分区的Topic。正常情况下，Kafka平均会为每个Consumer分配5个分区。这个分配的过程就叫Rebalance。\nRebalance 的流程 在消费者端，重平衡分为两个步骤：分别是 加入组 和 等待领导消费者（Leader Consumer）分配方案。这两个步骤分别对应两类特定的请求：JoinGroup请求和SyncGroup请求。\n当组内成员加入组时，它会向 协调者 发送JoinGroup请求（后面会介绍协调者）。在该请求中，每个成员都要将自己订阅的主题上报，这样协调者就能收集到所有成员的订阅信息。一旦收集了全部成员的JoinGroup请求后，协调者会从这些成员中选择一个担任这个消费者组的领导者。\n通常情况下，第一个发送JoinGroup请求的成员自动成为领导者。你一定要注意区分这里的领导者和之前我们介绍的领导者副本，它们不是一个概念。这里的领导者是具体的消费者实例，它既不是副本，也不是协调者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。\n选出领导者之后，协调者会把消费者组订阅信息封装进JoinGroup请求的响应体中，然后发给领导者，由领导者统一做出分配方案后，进入到下一步：发送SyncGroup请求。\n在这一步中，领导者向协调者发送SyncGroup请求，将刚刚做出的分配方案发给协调者。值得注意的是，其他成员也会向协调者发送SyncGroup请求，只不过请求体中并没有实际的内容。这一步的主要目的是让协调者接收分配方案，然后统一以SyncGroup响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。\nJoinGroup请求的主要作用是将组成员订阅信息发送给领导者消费者，待领导者制定好分配方案后，重平衡流程进入到SyncGroup请求阶段。\nSyncGroup请求的主要目的，就是让协调者把领导者制定的分配方案下发给各个组内成员。当所有成员都成功接收到分配方案后，消费者组进入到Stable状态，即开始正常的消费工作。\n正常情况下，每个组内成员都会定期汇报位移给协调者。当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速地上报自己的位移信息，然后再开启正常的JoinGroup/SyncGroup请求发送。\nBroker Kafka集群包含一个或多个服务器，这种服务器被称为broker。一个 broker 可以容纳多个 topic。brocker 是 kafka 中的核心组件，负责消息的存储，分区，路由信息的管理等。\nPartition Kafka中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区0中，要么在分区1中。\n如你所见，Kafka的分区编号是从0开始的，如果Topic有100个分区，那么它们的分区号就是从0到99。讲到这里，你可能有这样的疑问：刚才提到的副本如何与这里的分区联系在一起呢？实际上，副本是在分区这个层级定义的。\n每个分区下可以配置若干个副本，其中只能有1个领导者副本和N-1个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从0开始，假设一个生产者向一个空分区写入了10条消息，那么这10条消息的位移依次是0、1、2、\u0026hellip;、9。\nKafka Broker 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机I/O操作，改为性能较好的顺序I/O写操作，这也是实现Kafka高吞吐量特性的一个重要手段。\n不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此Kafka必然要定期地删除消息以回收磁盘。简单来说就是通过日志段（Log Segment）机制。在Kafka底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。\nTopic Topic 是一种逻辑上的分区，是同一类消息的集合，每一个消息只能属于一个 Topic。\n为了使得Kafka的吞吐率提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。\n每个日志文件都是一个log entry序列，每个log entry包含一个4字节整型数值（值为N+5），1个字节的”magic value”，4个字节的CRC校验码，其后跟N个字节的消息体。每条消息都有一个当前Partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：\nmessage length ：4 bytes (value: 1+4+n) “magic” value ： 1 byte crc ： 4 bytes payload ： n bytes 这个log entry并非由一个文件构成，而是分成多个segment，每个segment以该segment第一条消息的offset命名并以“.kafka”为后缀。另外会有一个索引文件，它标明了每个segment下包含的log entry的offset范围。\n 图片来自：http://www.jasongj.com/2015/03/10/KafkaColumn1/\n 因为每条消息都被append到该Partition中，属于顺序写磁盘。但是如果 partition 过多，就会退化成随机写磁盘，因为 kafka 是每个 partition 一个目录去写，不同于 rokcetmq 的所有 queue 写一个文件。\nKafka 控制器 控制器组件（Controller），是Apache Kafka的核心组件。它的主要作用是在Apache ZooKeeper的帮助下管理和协调整个Kafka集群理和协调整个Kafka集群。集群中任意一台Broker都能充当控制器的角色，但是，在运行过程中，只能有一个Broker成为控制器，行使其管理和协调的职责。换句话说，每个正常运转的Kafka集群，在任意时刻都有且只有一个控制器\nBroker在启动时，会尝试去ZooKeeper中创建/controller节点。Kafka当前选举控制器的规则是：第一个成功创建/controller节点的Broker会被指定为控制器第一个成功创建/controller节点的Broker会被指定为控制器。控制器是做什么的？控制器是做什么的？我们经常说，控制器是起协调作用的组件，那么，这里的协调作用到底是指什么呢？我想了一下，控制器的职责大致可以分为5种，我们一起来看看。\n  主题管理（创建、删除、增加分区）：控制器帮助我们完成对Kafka主题的创建、删除以及分区增加的操作。\n  分区重分配。\n  Preferred领导者选举。\n  集群成员管理（新增Broker、Broker主动关闭、Broker宕机）：自动检测新增Broker、Broker主动关闭及被动宕机。\n这种自动检测是依赖于前面提到的Watch功能和ZooKeeper临时节点组合实现的。比如，控制器组件会利用Watch机制检 ZooKeeper的/brokers/ids节点下的子节点数量变更。目前，当有新Broker启动后，它会在/brokers下创建专属的znode节点。一旦创建完毕，ZooKeeper会通过Watch机制将消息通知推送给控制器，这样，控制器就能自动地感知到这个变化，进而开启后续的新增Broker作业。侦测Broker存活性则是依赖于刚刚提到的另一个机制：临时节点。每个Broker启动后，会在/brokers/ids下创建一个临时znode。当Broker宕机或主动关闭后，该Broker与ZooKeeper的会话结束，这个znode会被自动删除。同理，ZooKeeper的Watch机制将这一变更推送给控制器，这样控制器就能知道有Broker关闭或宕机了，从而进行“善后”。\n  向其他Broker提供数据服务：控制器上保存了最全的集群元数据信息，其他所有Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。\n这些数据其实在ZooKeeper中也保存了一份。每当控制器初始化时，它都会从ZooKeeper上读取对应的元数据并填充到自己的缓存中。有了这些数据，控制器就能对外提供数据服务了。这里的对外主要是指对其他Broker而言，控制器通过向这些Broker发送请求的方式将这些数据同步到其他Broker上。\n 所有主题信息。包括具体的分区信息，比如领导者副本是谁，ISR集合中有哪些副本等。 所有Broker信息。包括当前都有哪些运行中的Broker，哪些正在关闭中的Broker等。 所有涉及运维任务的分区。包括当前正在进行Preferred领导者选举以及分区重分配的分区列表。    控制器故障转移（Failover） 在Kafka集群运行过程中，只能有一台Broker充当控制器的角色，那么这就存在单点失效（Single Point of Failure）的风险。\n当运行中的控制器突然宕机或意外终止时，Kafka能够快速地感知到（通过 ZK 的 watch 机制），并立即重新选出新的的控制器。这个过程就被称为Failover，该过程是自动完成的，无需你手动干预。\n高水位和LeaderEpoch HW 和 LEO   LEO（last end offset）：日志末端位移，记录了该副本对象底层日志文件中下一条消息的位移值，副本写入消息的时候，会自动更新 LEO 值。\n  HW（high watermark）：HW 一定不会大于 LEO 值，小于 HW 值的消息被认为是“已提交，对消费者可见。\n  Log End Offset，简写是LEO，它表示副本写入下一条消息的位移值。同一个副本对象，其高水位值不会大于LEO值同一个副本对象。\nKafka所有副本都有对应的高水位和LEO值，而不仅仅是Leader副本。只不过Leader副本比较特殊，Kafka使用Leader副本的高水位来定义所在分区的高水位。\nleader 会保存两个类型的 LEO 值，一个是自己的 LEO，另一个是 remote LEO 值，remote LEO 值就是 follower 副本的 LEO 值，意味着 follower 副本的 LEO 值会保存两份，一份保存到 leader 副本中，一份保存到自己这里。\nLEO 更新机制：\n leader 副本自身的 LEO 值更新：在 Producer 消息发送过来时，即 leader 副本当前最新存储的消息位移位置 +1； follower 副本自身的 LEO 值更新：从 leader 副本中 fetch 到消息并写到本地日志文件时，即 follower 副本当前同步 leader 副本最新的消息位移位置 +1； leader 副本中的 remote LEO 值更新：每次 follower 副本发送 fetch 请求都会包含 follower 当前 LEO 值，leader 拿到该值就会尝试更新 remote LEO 值。  leader HW 更新机制：\nleader HW 更新分为故障时更新与正常时更新：\n故障时更新：\n 副本被选为 leader 副本时：当某个 follower 副本被选为分区的 leader 副本时，kafka 就会尝试更新 HW 值； 副本被踢出 ISR 时：如果某个副本追不上 leader 副本进度，或者所在 broker 崩溃了，导致被踢出 ISR，leader 也会检查 HW 值是否需要更新，毕竟 HW 值更新只跟处于 ISR 的副本 LEO 有关系。  正常时更新：\n producer 向 leader 副本写入消息时：在消息写入时会更新 leader LEO 值，因此需要再检查是否需要更新 HW 值； leader 处理 follower FETCH 请求时：follower 的 fetch 请求会携带 LEO 值，leader 会根据这个值更新对应的 remote LEO 值，同时也需要检查是否需要更新 HW 值。  follower HW 更新机制：\n follower 更新 HW 发生在其更新 LEO 之后，每次 follower Fetch 响应体都会包含 leader 的 HW 值，然后比较当前 LEO 值，取最小的作为新的 HW 值。  上图 stop4 说明 Follower副本的HW更新需要一轮额外的拉取请求才能实现。\n如果把上面那个例子扩展到多个Follower副本，情况可能更糟，也许需要多轮拉取请求。也就是说，Leader副本高水位更新和Follower副本高水位更新在时间上是存在错配的。这种错配是很多“数据丢失”或“数据不一致”问题的根源。\n数据丢失举例 第1步中的状态:\n 副本B作为leader收到producer的m2消息并写入本地文件，等待副本A拉取。 副本A发起消息拉取请求，请求中携带自己的最新的日志offset（LEO=1），B收到后更新自己的HW为1，并将HW=1的信息以及消息m2返回给A。 A收到拉取结果后更新本地的HW为1，并将m2写入本地文件。发起新一轮拉取请求（LEO=2），B收到A拉取请求后更新自己的HW为2，没有新数据只将HW=2的信息返回给A，并且回复给producer写入成功。此处的状态就是图中第一步的状态。  此时，如果没有异常，A会收到B的回复，得知目前的HW为2，然后更新自身的HW为2。\n但在第2步A重启了，没有来得及收到B的回复，此时B仍然是leader。\nA重启之后会以自己的 HW 为标准截断自己的日志，因为A作为follower不知道多出的日志是否是被提交过的，防止数据不一致从而截断多余的数据并尝试从leader那里重新同步\n第3步，B崩溃了，min.isr设置的是1，所以zookeeper会从ISRs中再选择一个作为leader，也就是A，但是A的数据不是完整的，从而出现了数据丢失现象。\nLeaderEpoch Leader Epoch，我们大致可以认为是Leader版本。它由两部分数据组成。\n  Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的Leader被认为是过期Leader，不能再行使Leader权力。\n  起始位移（Start Offset）。Leader副本在该Epoch值上写入的首条消息的位移。\n   举个例子来说明一下Leader Epoch。\n假设现在有两个Leader Epoch\u0026lt;0, 0\u0026gt;和\u0026lt;1, 120\u0026gt;，那么，第一个Leader Epoch表示版本号是0，这个版本的Leader从位移0开始保存消息，一共保存了120条消息。之后，Leader发生了变更，版本号增加到1，新版本的起始位移是120。\n Kafka Broker会在内存中为每个分区都缓存Leader Epoch数据，同时它还会定期地将这些信息持久化到一个checkpoint文件中。当Leader副本写入消息到磁盘时，Broker会尝试更新这部分缓存。如果该Leader是首次写入消息，那么Broker会向缓存中增加一个Leader Epoch条目，否则就不做更新。这样，每次有Leader变更时，新的Leader副本会查询这部分缓存，取出对应的Leader Epoch的起始位移，以避免数据丢失和不一致的情况\n引用Leader Epoch机制后，Follower副本B重启回来后，需要向A发送一个特殊的请求去获取Leader的LEO值。\n在这个例子中，该值为2。当获知到Leader LEO=2后，B发现该LEO值不比它自己的LEO值小，而且缓存中也没有保存任何起始位移值 \u0026gt; 2的Epoch条目，因此B无需执行任何日志截断操作。\nLeader Epoch 是对高水位机制的一个明显改进，即副本是否执行日志截断不再依赖于高水位进行判断。\n高可用 Replication 副本（Replica）本质是一个只能追加写消息的提交日志。根据Kafka副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的Broker上。\nKafka定义了两类副本：领导者副本(Leader)和追随者副本(Follower)。一主多从，这些副本保存着相同的数据。领导者副本对外提供服务，追随者副本只是不断异步拉取领导者副本的消息，不对外提供服务。\n当领导者副本挂掉了，或者说领导者副本所在的Broker宕机时，Kafka依托于ZooKeeper提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。老Leader副本重启回来后，只能作为追随者副本加入到集群中。\n为什么kafka的追随者副本不对外服务  方便实现“Read-your-writes”。所谓Read-your-writes，顾名思义就是，当你使用生产者API向Kafka成功写入消息后，马上使用消费者API去读取刚才生产的消息。 方便实现单调读（Monotonic Reads）。什么是单调读呢？就是对于一个消费者用户而言，在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。  ISR Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。\nISR 可以把他看成主从结构的升级版。对于每一个 partiton，可以分配一个或多个 Broker。 其中一个作为主节点，剩余的作为跟随者，跟随者会保存一个 partition 副本。生产者将消息发送到主节点后，主节点会广播给所有跟随者，跟随者收到后返回确认信息给主节点。 用户可以自由的配置副本数及当有几个副本写成功后，则认为消息成功保存。且同时，会在 ZooKeeper 上维护一个可用跟随者列表，列表中记录所有数据和主节点完全同步的跟随者列表。当主节点发生故障时，在列表中选择一个跟随者作为新的主节点提供服务。在这种策略下，假设总共有 m 个副本，要求至少有 n 个（0\u0026lt;n\u0026lt;m+1）副本写成功，则系统可以在最多 m-n 个机器故障的情况下保证可用性。\n 还有一种实现是基于 Raft 算法实现的多副本机制，具体细节可以参考官方的 paper。Raft 集群一般由奇数节点构成，如果要保证集群在 n 个节点故障的情况下可用，则至少需要有 2n+1 个节点。 与 ISR 方式相比，Raft 需要耗费更多的资源，但是整个复制和选举过程都是集群中的节点自主完成，不需要依赖 ZooKeeper 等第三者。 理论上 Raft 集群规模可以无限扩展而 ISR 模式下集群规模会受限于 ZooKeeper 集群的处理能力。\n ISR，也即In-sync Replica。每个Partition的Leader都会维护这样一个列表，该列表中，包含了所有与之同步的Replica（包含Leader自己）。每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。\nBroker端参数 replica.lag.time.max.ms，这个参数的含义是Follower副本能够落后Leader副本的最长时间间隔，当前默认值是10秒。这就是说，只要一个Follower副本落后Leader副本的时间不连续超过10秒，那么Kafka就认为该Follower副本与Leader是同步的，即使此时Follower副本中保存的消息明显少于Leader副本中的消息。我们在前面说过，Follower副本唯一的工作就是不断地从Leader副本拉取消息，然后写入到自己的提交日志中。如果这个同步过程的速度持续慢于Leader副本的消息写入速度，那么在replica.lag.time.max.ms时间后，此Follower副本就会被认为是与Leader副本不同步的，因此不能再放入ISR中。此时，Kafka会自动收缩ISR集合，将该副本“踢出”ISR。值得注意的是，倘若该副本后面慢慢地追上了Leader的进度，那么它是能够重新被加回ISR的。这也表明，ISR是一个动态调整的集合，而非静态不变的。\nUnclean领导者选举（Unclean Leader Election） 既然ISR是可以动态调整的，那么自然就可以出现这样的情形：ISR为空。因为Leader副本天然就在ISR中，如果ISR为空了，就说明Leader副本也“挂掉”了，Kafka需要重新选举一个新的Leader。\n此时该怎么选举新Leader呢？Kafka把所有不在ISR中的存活副本都称为非同步副本Kafka把所有不在ISR中的存活副本都称为非同步副本。通常来说，非同步副本落后Leader太多，因此，如果选择这些副本作为新Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老Leader中的消息。在Kafka中，选举这种副本的过程称为Unclean领导者选举。Broker端参数Broker端参数unclean.leader.election.enable控制是否允许Unclean领导者选举unclean.leader.election.enable控制是否允许Unclean领导者选举。\n开启Unclean领导者选举可能会造成数据丢失，但好处是，它使得分区Leader副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止Unclean领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。\n 推荐阅读\n为什么Kafka需要Leader Epoch\nKafka水位(high watermark)与leader epoch的讨论\nKafka高性能架构之道\n ","permalink":"https://mogutou.xyz/posts/mq/kafka/","summary":"整体架构  图片来自 https://zhuanlan.zhihu.com/p/103249714\n Producer 负责发布消息到Kafka broker。Producer发送消息到broker时，会根据分区策略选择将其存储到哪一个Partition。\n常规的有轮询，随机等策略，主要是为了将消息均衡的发送到各个 partition，提高并行度，从而提高吞吐。常用的还有按 key 哈希，主要是为了实现业务 partition 有序的需求。\nConsumer 消息消费者，从Kafka broker读取消息的客户端。\nConsumer Group Consumer Group是Kafka提供的可扩展且具有容错性的消费者机制，每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n Consumer Group下可以有一个或多个Consumer实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。 Group ID是一个字符串，在一个Kafka集群中，它标识唯一的一个Consumer Group。 Consumer Group下所有实例订阅的主题的单个分区，只能分配给组内的某个Consumer实例消费。  进度提交 消费者在消费的过程中需要记录自己消费了多少数据，即消费位置信息。在Kafka中，这个位置信息有个专门的术语：位移（Offset）。\nRebalance 何时触发 rebalance\n 组成员数量发生变化，有新成员加入，或者有成员实例崩溃退出。 订阅主题数量发生变化：Consumer Group可以使用正则表达式的方式订阅主题，比如果consumer.subscribe(Pattern.compile(“t.*c”))就表明该Group订阅所有以字母t开头、字母c结尾的主题。在Consumer Group的运行过程中，你新创建了一个满足这样条件的主题，那么该Group就会发生Rebalance 订阅主题的分区数发生变化，如主题扩容。  Rebalance本质上是一种协议，规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区Topic的每个分区。\n比如某个Group下有20个Consumer实例，它订阅了一个具有100个分区的Topic。正常情况下，Kafka平均会为每个Consumer分配5个分区。这个分配的过程就叫Rebalance。\nRebalance 的流程 在消费者端，重平衡分为两个步骤：分别是 加入组 和 等待领导消费者（Leader Consumer）分配方案。这两个步骤分别对应两类特定的请求：JoinGroup请求和SyncGroup请求。\n当组内成员加入组时，它会向 协调者 发送JoinGroup请求（后面会介绍协调者）。在该请求中，每个成员都要将自己订阅的主题上报，这样协调者就能收集到所有成员的订阅信息。一旦收集了全部成员的JoinGroup请求后，协调者会从这些成员中选择一个担任这个消费者组的领导者。\n通常情况下，第一个发送JoinGroup请求的成员自动成为领导者。你一定要注意区分这里的领导者和之前我们介绍的领导者副本，它们不是一个概念。这里的领导者是具体的消费者实例，它既不是副本，也不是协调者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。\n选出领导者之后，协调者会把消费者组订阅信息封装进JoinGroup请求的响应体中，然后发给领导者，由领导者统一做出分配方案后，进入到下一步：发送SyncGroup请求。\n在这一步中，领导者向协调者发送SyncGroup请求，将刚刚做出的分配方案发给协调者。值得注意的是，其他成员也会向协调者发送SyncGroup请求，只不过请求体中并没有实际的内容。这一步的主要目的是让协调者接收分配方案，然后统一以SyncGroup响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。\nJoinGroup请求的主要作用是将组成员订阅信息发送给领导者消费者，待领导者制定好分配方案后，重平衡流程进入到SyncGroup请求阶段。\nSyncGroup请求的主要目的，就是让协调者把领导者制定的分配方案下发给各个组内成员。当所有成员都成功接收到分配方案后，消费者组进入到Stable状态，即开始正常的消费工作。\n正常情况下，每个组内成员都会定期汇报位移给协调者。当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速地上报自己的位移信息，然后再开启正常的JoinGroup/SyncGroup请求发送。\nBroker Kafka集群包含一个或多个服务器，这种服务器被称为broker。一个 broker 可以容纳多个 topic。brocker 是 kafka 中的核心组件，负责消息的存储，分区，路由信息的管理等。","title":"Kafka 设计与理解"},{"content":"vue 相关代码： https://github.com/Allenxuxu/ginvue\n先全局安装下 vue cli 并创建一个 demo 项目\nnpm install -g @vue/cli vue create web 然后我们进入 web 目录，修改生成的 package.json 文件调整一下 build 生成的静态文件目录。\n\u0026ndash;dest 是指定输出的目录\n**\u0026ndash;no-clean 是让他不要每次覆盖我们的目录，因为后面我们会放一个 go 文件到那个目录。 **\n\u0026quot;build\u0026quot;: \u0026quot;vue-cli-service build --no-clean --dest ../static\u0026quot;, 再新增一个 vue.config.js 文件来修改下 , 这里将 production 的 publicPath 修改成带一个前缀 /ui/ , 这里主要就是为了后面我们的go 代码路由设置方便，所有的前端静态文件请求都带上 /ui 前缀，和后端 API 接口带 /api 前缀区分。\nmodule.exports = { publicPath: process.env.NODE_ENV === 'production' ? '/ui/' : '/' } 最后我们再 web 目录运行 npm run build，会生成一个 static 目录（也就是我们修改的 package.json 里指定的目录），里面会存放生成的静态文件。\n. ├── css │ └── app.fb0c6e1c.css ├── favicon.ico ├── img │ └── logo.82b9c7a5.png ├── index.html ├── js │ ├── app.cdde1042.js │ ├── app.cdde1042.js.map │ ├── app.e656f618.js │ ├── app.e656f618.js.map │ ├── chunk-vendors.ff672a17.js │ └── chunk-vendors.ff672a17.js.map go 我们再 static 目录里增加一个 go 文件，这里使用 1.16 的 embed 来嵌入当前目录的静态文件：\npackage static import \u0026quot;embed\u0026quot; //go:embed index.html favicon.ico css img js var Static embed.FS 最后看一下 main.go，主要就是这行 r.StaticFS(\u0026quot;/ui\u0026quot;, http.FS(static.Static)).\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/Allenxuxu/ginvue/static\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/pkg/browser\u0026#34; ) func main() { r := gin.Default() r.StaticFS(\u0026#34;/ui\u0026#34;, http.FS(static.Static)) r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) }) go func() { time.Sleep(time.Second) err := browser.OpenURL(\u0026#34;http://127.0.0.1:8080/ui\u0026#34;) if err != nil { fmt.Println(err) } fmt.Println(\u0026#34;Open: http://127.0.0.1:8080/ui\u0026#34;) }() r.Run() // listen and serve on 0.0.0.0:8080 (for windows \u0026#34;localhost:8080\u0026#34;) } 这里就可以直接 go run main.go 了，不依赖前端静态文件，直接在浏览器打开 http://127.0.0.1:8080/ui 即可。\n为了验证，可以 build 生成到其他目录， 然后运行。\ngo build -o /tmp/demo main.go 相关代码： https://github.com/Allenxuxu/ginvue\n","permalink":"https://mogutou.xyz/posts/practice/gin-vue/","summary":"vue 相关代码： https://github.com/Allenxuxu/ginvue\n先全局安装下 vue cli 并创建一个 demo 项目\nnpm install -g @vue/cli vue create web 然后我们进入 web 目录，修改生成的 package.json 文件调整一下 build 生成的静态文件目录。\n\u0026ndash;dest 是指定输出的目录\n**\u0026ndash;no-clean 是让他不要每次覆盖我们的目录，因为后面我们会放一个 go 文件到那个目录。 **\n\u0026quot;build\u0026quot;: \u0026quot;vue-cli-service build --no-clean --dest ../static\u0026quot;, 再新增一个 vue.config.js 文件来修改下 , 这里将 production 的 publicPath 修改成带一个前缀 /ui/ , 这里主要就是为了后面我们的go 代码路由设置方便，所有的前端静态文件请求都带上 /ui 前缀，和后端 API 接口带 /api 前缀区分。\nmodule.exports = { publicPath: process.env.NODE_ENV === 'production' ? '/ui/' : '/' } 最后我们再 web 目录运行 npm run build，会生成一个 static 目录（也就是我们修改的 package.","title":"Go1.16 embed 和 Vue"},{"content":"Slice vs Array Slice 和 Array 是不同的类型 package main func main() { s := make([]int, 100) printSlice(s) var a [100]int printArray(a) } func printSlice(s []int) { println(len(s)) // 100 println(cap(s)) // 100 } func printArray(a [100]int) { println(len(a)) // 100 println(cap(a)) // 100 }  Slice 结构体\n type slice struct { array unsafe.Pointer len int cap int } 下面的汇编表明，当类型是 slice 的时候，打印 len 或者 cap 的时候，会去栈上取数据:\nMOVQ 0x28(SP), AX MOVQ AX, 0x8(SP) CALL 0xbfc [1:5]R_CALL:runtime.printlock\u0026lt;1\u0026gt; MOVQ 0x8(SP), AX MOVQ AX, 0(SP) **而当类型是 array 时候，直接用的 0x64 (10进制 100)： **MOVQ $0x64, 0(SP)\n查看具体汇编代码 go tool compile -N -l main.go go tool objdump main.o Slice 的自动扩容 Slice 可以使用 append 函数新增数据，当容量不足的时候，会自动新申请一块空间，将原有数据复制过去，再新增数据。\nhttps://github.com/golang/go/blob/2ebe77a2fda1ee9ff6fd9a3e08933ad1ebaea039/src/runtime/slice.go#L125\n **当 cap \u0026lt; 1024 的时候，每次 *2 ** 当 cap \u0026gt;= 1024 的时候，每次 * 1.25 其中还会涉及内存对齐的调整  package main import \u0026quot;fmt\u0026quot; func main() { var s []int for i:=0;i\u0026lt;3;i++ { s = append(s, i) } fmt.Println(s) // [0 1 2] modifySlice(s) fmt.Println(s) // [1024 1 2] } func modifySlice(s []int) { s = append(s, 2048) s[0] = 1024 fmt.Println(s) // [1024 1 2 2048] } Golang 中都是值传递，所以 modifySlice 函数的入参，只是复制了 slice struct 中 array ，len， cap 三个字段的值来初始化函数内的局部变量 s 。\n所以，当函数内部进行 append 发送扩容了的话，会新申请一块空间，然后让 array 指针指向他。函数外部的 slice 变量是不会变化的，array 指针仍然不变。\n所以，个人觉得，对于需要在函数内部 append slice 的情况一律传递 *[]int 。\nvar s []int == nil package main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { var s []int d, _ := json.Marshal(s) fmt.Println(string(d)) // null fmt.Println(s == nil) // true s2 := []int{} d, _ = json.Marshal(s2) fmt.Println(string(d)) // [] fmt.Println(s2 == nil) // false } 高效的 append func BenchmarkAppendSlice(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { s := make([]int, 0, 10000) for j := 0; j \u0026lt; 10000; j++ { s = append(s, j) } } } func BenchmarkAppendSliceIndexed(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { s := make([]int, 10000) for j := 0; j \u0026lt; 10000; j++ { s[j] = j } } } BenchmarkAppendSlice-12 110247 10832 ns/op BenchmarkAppendSliceIndexed-12 137204 8585 ns/op 因为 append 操作内部会每次去检查容量是不是够，即每次调用 runtime.growslice ，下面为截取的部分汇编。\nMOVQ AX, 0x50(SP) LEAQ 0(IP), SI [3:7]R_PCREL:type.int MOVQ SI, 0(SP) MOVQ BX, 0x8(SP) MOVQ AX, 0x10(SP) MOVQ DX, 0x18(SP) MOVQ CX, 0x20(SP) NOPL 0(AX) CALL 0x5d6 [1:5]R_CALL:runtime.growslice\u0026lt;1\u0026gt; MOVQ 0x28(SP), BX MOVQ 0x30(SP), AX MOVQ 0x38(SP), DX LEAQ 0x1(AX), CX MOVQ 0x50(SP), AX JMP 0x57b 边界检查消除 https://gfw.go101.org/article/bounds-check-elimination.html\nfunc normal(s []int) int { i := 0 i += s[0] i += s[1] i += s[2] i += s[3] i += s[4] return i } func bce(s []int) int { _ = s[4] i := 0 i += s[0] i += s[1] i += s[2] i += s[3] i += s[4] return i } 第一种情况下，golang 会在每一次按下标取值时调用 runtime.panicIndex 检查是否越界。\n下面是截取的部分汇编：\n下面的需要开启优化选项来编译 go tool compile main.go\n normal\n CALL 0x8ce [1:5]R_CALL:runtime.panicIndex MOVL $0x3, AX CALL 0x8d8 [1:5]R_CALL:runtime.panicIndex MOVL $0x2, AX NOPL CALL 0x8e3 [1:5]R_CALL:runtime.panicIndex MOVL $0x1, AX CALL 0x8ed [1:5]R_CALL:runtime.panicIndex XORL AX, AX CALL 0x8f4 [1:5]R_CALL:runtime.panicIndex  Bce\n CALL 0xab8 [1:5]R_CALL:runtime.printint\u0026lt;1\u0026gt; CALL 0xabd [1:5]R_CALL:runtime.printnl\u0026lt;1\u0026gt; CALL 0xac2 [1:5]R_CALL:runtime.printunlock\u0026lt;1\u0026gt; MOVQ 0x18(SP), BP ADDQ $0x20, SP RET MOVL $0x3, AX CALL 0xad6 [1:5]R_CALL:runtime.panicIndex 总结  Golang 中 数组 和 slice 是两种完全不同的类型，也有着不同的行为  数组的不可改变，是其类型声明的一部分   Slice 本质是一个 struct，包含一个执行数据地址的指针，len 字段记录长度，cap 字段记录容量 Golang 中函数传参  如果是 slice ，则会复制内部的三个字段值来初始化一个新的 slice 变量   如果是 array，则会重新申请一块内存，复制整个数组的内容到新的 array 变量 *如果在函数内部 append 这个slice，一定要传递 []int Slice 的 append 函数内部会每次都调用 runtime.growslice ，检查是否需要扩容，在容量已经确定的情况下，用 index 更高效。 边界检查优化  Map Map 主要是要了解一些源码实现，详情可以看下面的文章分析\nhttps://qcrao.com/2019/05/22/dive-into-go-map/\n总结  Map 删除 key 不会缩容，也不会释放空间 Map 的 key value 都不可取值 Map 内部和 slice 类似，都是用指针指向具体存储，所以用 map 作为函数参数，在函数内部可以修改map  不同的是，如果在函数内部 map 发生扩容，是会作用于外部的 map 的，因为 map 内部采用拉链法，不同于 slice 的申请一个新空间然后复制过去   Map 非并发安全，并发访问使用 sync.Map  Channel https://qcrao.com/2019/07/22/dive-into-go-channel/\n总结  Channel 内部使用锁实现 Channel 会触发调度 Channel 发送的数据是值拷贝的，有必要的话需要传指针减少复制开销 For 循环里面的 select 内部的 break 只会跳出 select  ","permalink":"https://mogutou.xyz/posts/go/go-slice-map-channel/","summary":"Slice vs Array Slice 和 Array 是不同的类型 package main func main() { s := make([]int, 100) printSlice(s) var a [100]int printArray(a) } func printSlice(s []int) { println(len(s)) // 100 println(cap(s)) // 100 } func printArray(a [100]int) { println(len(a)) // 100 println(cap(a)) // 100 }  Slice 结构体\n type slice struct { array unsafe.Pointer len int cap int } 下面的汇编表明，当类型是 slice 的时候，打印 len 或者 cap 的时候，会去栈上取数据:\nMOVQ 0x28(SP), AX MOVQ AX, 0x8(SP) CALL 0xbfc [1:5]R_CALL:runtime.","title":"Golang slice map channel 小技巧"},{"content":"整体架构 RocketMQ 主要由 Producer、Broker、Consumer、Name Server 四个部分组成。\n其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息，Name server 充当路由消息的提供者。\n每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。\nTopic Topic 是一种逻辑上的分区，是同一类消息的集合，每一个消息只能属于一个 Topic ，是RocketMQ进行消息订阅的基本单位。\n每个 topic 会被分成很多 Messsage Queue ，和 Kafka 中的 Partition 概念一样，topic 的数据被分布在不同的 Message Queue 中。\n在业务增长，消息量增大时，可以增大 topic 的 Message Queue，这样可以将压力分摊到更多的 broker 上。因为 Producer 可以发送消息的时候可以通过指定的算法，将消息均匀的发送到每个 Message Queue。\nNameServer 生产者或消费者能够通过 Name Server查找各 Topic 相应的Broker IP 列表。 Name Server 可以多机部署变成一个集群保证高可用，但这些机器间彼此并不通信，也就是说三者的元数据舍弃了强一致性。\n每一个 broker 启动时会向全部的 Name server 机器注册心跳，心跳里包含自己机器上 Topic 的拓扑信息，之后每隔 30s 更新一次，然后生产者和消费者启动的时候任选一台 Name Server 机器拉取所需的 Topic 的路由信息缓存在本地内存中，之后每隔 30s 定时从远端拉取更新本地缓存。\nName Server 机器中定时监测 broker 的心跳，一旦失联，即关闭这个 Broker 的连接，但是不主动通知生产组和消费组。也就是说对于 broker 的上线下线，需要 Producer 和 Consumer 主动去拉取才会跟新，因此二者最长需要 30s 才能感知到某个 broker 故障。\nProducer Producer 负责生产消息，Producer 按照一定规则直接消息投递到 broker。RocketMQ 提供多种发送方式：\n 同步发送 异步发送 单向发送  同步和异步方式均需要Broker返回确认信息，单向发送不需要。\nProducer 作为客户端发送消息时候，需要根据消息的 Topic 从本地缓存的 TopicPublishInfoTable 获取路由信息。如果没有则更新路由信息会从NameServer上重新拉取，同时Producer会默认每隔30s向NameServer拉取一次路由信息。\n负载均衡 Producer端在发送消息的时候，会先根据Topic找到指定的TopicPublishInfo，在获取了TopicPublishInfo路由信息后，RocketMQ的客户端在默认方式下从 TopicPublishInfo 中的 messageQueueList 中按照一定策略选择一个队列（MessageQueue）进行发送消息。\n这个选择 MessageQueue，可以是随机选择，轮询，Hash 等，也支持自定义。\n高可用  发送重试 RocketMQ 支持同步、异步发送，不管哪种方式都可以在配置失败后重试，如果单个 Broker 发生故障，重试会选择其他 Broker 保证消息正常发送。默认会尝试发送三次。 客户端容错 RocketMQ 客户端会维护一个 Broker-发送延迟 关系。 根据这个关系选择一个发送延迟级别较低的 Broker 来发送消息，这样能最大限度地利用 Broker 的能力，剔除已经宕机、不可用或者发送延迟级别较高的Broker，尽量保证消息的正常发送。在选择时，对那些有“问题”的broker 进行退避。  Consumer Consumer 负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。\n在使用消费者时需要指定一个组名。一个消费者组可以订阅多个Topic。一个消费者组订阅一个 Topic 的某一个 Tag，这种记录被称为订阅关系。RocketMQ规定消费订阅关系（消费者组名-Topic-Tag）必须一致，一个消费者组中的实例订阅的Topic和Tag必须完全一致，否则就是订阅关系不一致。订阅关系不一致会导致消费消息紊乱。\n在Consumer启动后，它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包（其中包含了，消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。\n消费模式  集群消费 同一个消费组里的消费者“瓜分”所有消息来消费，同一个消息只会被一个消费者实例消费。因为集群模式的消费进度是保存在Broker端的，所以即使应用崩溃，消费进度也不会出错。 广播消费 同一个消费组里的消费者会消费所有消息，即同一个消息会被每一个消费者实例消费。广播消费的消费进度保存在客户端机器的文件中。如果文件弄丢了，那么消费进度就丢失了，可能会导致部分消息没有消费。  高可用  consumer并不能配置从master读还是slave读。当master不可用或者繁忙的时候consumer会被自动切换到从slave读。\n   重试，死信 重试 Topic：如果由于各种意外导致消息消费失败，那么该消息会自动被保存到重试Topic中，格式为“%RETRY%消费者组”，在订阅的时候会自动订阅这个重试Topic。 进入重试队列的消息有16次重试机会，每次都会按照一定的时间间隔进行，只要正常消费或者重试消费中有一次消费成功，就算消费成功。 死信Topic：死信Topic名字格式为“%DLQ%消费者组名”。如果正常消费1次失败，重试16次失败，那么消息会被保存到死信Topic中，进入死信Topic的消息不能被再次消费。RocketMQ认为，如果17次机会都失败了，说明生产者发送消息的格式发生了变化，或者消费服务出现了问题，需要人工介入处理。\n  Rebalance Rebalance（重平衡）机制，用于在发生Broker掉线、Topic扩容和缩容、消费者扩容和缩容等变化时，自动感知并调整自身消费，以尽量减少甚至避免消息没有被消费。 触发时机\n Consumer启动时 启动之后会立马进行Rebalance Consumer运行中 运行中会监听Broker发送过来的Rebalance消息，以及Consumer自身的定时任务（每隔20s）触发的Rebalance Consumer停止运行 停止时没有直接的调用Rebalance，而是会通知Broker自己下线了，然后Broker会通知其余的Consumer进行Rebalance。  Rebalance 核心逻辑主要在 client 侧。首先，Consumer 从 Broker 拉取自己订阅的所有 Topic 和 ConsumerGroup 下的消费者信息。然后会对 Topic 中 MessageQueue 和 消费者ID 进行排序，然后用消息队列默认分配算法来进行分配。排序是关键步骤，因为 consumer 之间并不通信，通过排序这样可以保证每一个 consumer 的视图一致，然后通过相同的分配算法，就能达到分配结果的一致。   消费进度保存 集群消费模式中，消费进度保存在broker 上，而广播模式中保存在客户端本地。\n消费进度是消费者组之间互相隔离的，Broker 上通过 Topic + 消费者组名称作为 key，value 中分别记录每个 MessageQueue 对应该消费者组的消费偏移量 offset。\n消费者侧会记录自己的消费进度到内存中的 OffsetTable，然后定时提交到 Broker 侧。\n由于一批消息的消费次序不确定，可能下标大的消息先被消费结束，下标小的由于延时尚未被消费，此时消费者向 Broker 提交的 offset 应该是已被消费的最小下标，从而保证消息不被遗漏，但缺点在于可能重复消费消息。\n消费方式 从用户应用的角度而言提供了两种消费形式：Pull、Push。\n Pull 用户主动Pull消息，自主管理位点，可以灵活地掌控消费进度和消费速度，适合流计算、消费特别耗时等特殊的消费场景。缺点也显而易见，需要从代码层面精准地控制消费，对开发人员有一定要求。 Push 代码接入非常简单，适合大部分业务场景。缺点是灵活度差，在了解其消费原理后，排查消费问题方可简单快捷。Push 模式的实现是使用长轮询的方式，并非由 broker 推送。  消息过滤 RocketMQ 的消费者可以根据 tag 进行消息过滤。消费者在 Pull 消息时，RocketMQ Broker 会根据 Tag 的 Hashcode 进行对比。如果不满足条件，消息不会返回给消费者，以节约宽带。字符串比较的速度相较Hashcode慢。Hashcode对比是数字比较，Java底层可以直接通过位运算进行对比，而字符串对比需要按照字符顺序比较，相比位运算更加耗时。由于Hashcode对比有Hash碰撞的危险，所以客户端会进行 二次 tag 过滤。\nBrocker 复制和刷盘 复制是指Broker与Broker之间的数据同步方式，分为同步和异步两种。\n 同步复制时，生产者会等待同步复制成功后，才返回生产者消息发送成功。 异步复制时，消息写入Master Broker后即为写入成功，此时系统有较低的写入延迟和较大的系统吞吐量。  刷盘是指数据发送到Broker的内存（通常指PageCache）后，以何种方式持久化到磁盘。\n 同步刷盘时，生产者会等待数据持久化到磁盘后，才返回生产者消息发送成功，可靠性极强。 异步刷盘时，消息写入PageCache即为写入成功，到达一定量时自动触发刷盘。此时系统有非常低的写入延迟和非常大的系统吞吐量。  存储 RocketMQ 主要存储的文件包括Comitlog文件、ConsumeQueue 文件、IndexFile文件。\n CommitLog：存储消息的元数据。RocketMQ将所有主题的消息存储在同一个文件中，确保消息发送时顺序写文件，尽最大能力确保消息发送的高性能与高吞吐量。每个文件大小一般是1GB，可以通过mapedFileSizeCommitLog进行配置。 ConsumerQueue：存储消息在CommitLog的索引。由于消息中间件一般是基于消息主题的订阅机制，这样便给按照消息主题检索消息带来了极大的不便。为了提高消息消费的效率，RocketMQ引入了ConsumeQueue消息队列文件，每个消息主题包含多个消息消费队列，每一个消息队列有一个消息文件。每个消费队列其实是commitlog的一个索引，提供给消费者做拉取消息、更新位点使用。  IndexFile：IndexFile索引文件，其主要设计理念就是为了加速消息的检索性能，根据消息的属性快速从Commitlog文件中检索消息，提供了一种通过key或者时间区间来查询消息的方法。全部的文件都是按照消息key创建的Hash索引。文件名是用创建时的时间戳命名的。  高可用 主从同步\n 4.5之前：提供Master Broker 和 Slave Broker之间的数据同步功能，以及主从切换。 当master挂了, 写入服务就不可用了，但是 slave 服务仍然提供可读服务。 4.5之后：引入了Dleger，使用Raft共识算法, 在master故障后自动选举新leader。  其他特性 消息顺序 消息有序指的是一类消息消费时，能按照发送的顺序来消费。\n顺序消息分为全局顺序消息与分区顺序消息，全局顺序是指某个Topic下的所有消息都要保证顺序；部分顺序消息只要保证每一组消息被顺序消费即可。\n 全局顺序 对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。 适用场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景。  全局消息的实现方式：一个全局顺序 topic 只创建一个Message Queue   分区顺序 对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。 同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。 Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。 适用场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。  延时消息 定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的topic。 broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。注意，messageDelayLevel是broker的属性，不属于某个topic。发消息时，设置delayLevel等级即可：msg.setDelayLevel(level)。level有以下三种情况：\n level == 0，消息为非延迟消息 1\u0026lt;=level\u0026lt;=maxLevel，消息延迟特定时间，例如level==1，延迟1s level \u0026gt; maxLevel，则level== maxLevel，例如level==20，延迟2h  定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，并根据delayTimeLevel存入特定的queue，queueId = delayTimeLevel – 1，即一个queue只存相同延迟的消息，保证具有相同发送延迟的消息能够顺序消费。broker会调度地消费SCHEDULE_TOPIC_XXXX，将消息写入真实的topic。\n需要注意的是，定时消息会在第一次写入和调度写入真实topic时都会计数，因此发送数量、tps都会变高。\n回溯消费 回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。\nRocketMQ支持按照时间回溯消费，时间维度精确到毫秒。\n事务消息 RocketMQ事务消息（Transactional Message）是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。RocketMQ的事务消息提供类似 X/Open XA 的分布事务功能，通过事务消息能达到分布式事务的最终一致。\n事务消息发送及提交：\n(1) 发送消息（Half Message）。\n(2) 服务端响应消息ACK写入结果。\n(3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。\n(4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）\n补偿流程：\n(1) 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”\n(2) Producer收到回查消息，检查回查消息对应的本地事务的状态\n(3) 根据本地事务状态，重新Commit或者Rollback\n其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。\nHalf Message 并未真正进入Topic的queue，而是用了临时queue来放所谓的half message，等提交事务后才会真正的将half message转移到topic下的queue。\n至少一次 至少一次(At least Once)指每个消息必须投递一次。Consumer先Pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack消息，但是可能会有 重复消费。\n","permalink":"https://mogutou.xyz/posts/mq/rocketmq/","summary":"整体架构 RocketMQ 主要由 Producer、Broker、Consumer、Name Server 四个部分组成。\n其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息，Name server 充当路由消息的提供者。\n每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。\nTopic Topic 是一种逻辑上的分区，是同一类消息的集合，每一个消息只能属于一个 Topic ，是RocketMQ进行消息订阅的基本单位。\n每个 topic 会被分成很多 Messsage Queue ，和 Kafka 中的 Partition 概念一样，topic 的数据被分布在不同的 Message Queue 中。\n在业务增长，消息量增大时，可以增大 topic 的 Message Queue，这样可以将压力分摊到更多的 broker 上。因为 Producer 可以发送消息的时候可以通过指定的算法，将消息均匀的发送到每个 Message Queue。\nNameServer 生产者或消费者能够通过 Name Server查找各 Topic 相应的Broker IP 列表。 Name Server 可以多机部署变成一个集群保证高可用，但这些机器间彼此并不通信，也就是说三者的元数据舍弃了强一致性。\n每一个 broker 启动时会向全部的 Name server 机器注册心跳，心跳里包含自己机器上 Topic 的拓扑信息，之后每隔 30s 更新一次，然后生产者和消费者启动的时候任选一台 Name Server 机器拉取所需的 Topic 的路由信息缓存在本地内存中，之后每隔 30s 定时从远端拉取更新本地缓存。","title":"RocketMQ 设计与理解"},{"content":"开发过程中，经常会出现提交邮箱搞错的情况。在公司项目中错误提交了自己的 GitHub 邮箱，或者在开源项目中提交了公司邮箱。\n下面记录一下补救措施。\n先修改 .git/config 或者 修改全局的，修改成你需要的邮箱信息。\n[user] email = name@qq.com name = yourname git log 找到要修改的那一条 commit，复制要修改的commit 的前一条 commit 的哈希值。\ngit rebase -i {{刚刚复制的哈希值}}\n然后后会出现一个 vim 打开的文本，将需要修改的 commit 信息前面的 pick 文本改成 edit，保存退出。\n修改邮箱信息\ngit commit --amend --author=\u0026quot;name \u0026lt;name@qq.com\u0026gt;\u0026quot; --no-edit\n这时候查看 git log 信息，发现邮箱已经更改了。\n强制 push 到远程（注意风险）\ngit push -f origin HEAD:master\ndone！\n","permalink":"https://mogutou.xyz/posts/practice/git-amend/","summary":"开发过程中，经常会出现提交邮箱搞错的情况。在公司项目中错误提交了自己的 GitHub 邮箱，或者在开源项目中提交了公司邮箱。\n下面记录一下补救措施。\n先修改 .git/config 或者 修改全局的，修改成你需要的邮箱信息。\n[user] email = name@qq.com name = yourname git log 找到要修改的那一条 commit，复制要修改的commit 的前一条 commit 的哈希值。\ngit rebase -i {{刚刚复制的哈希值}}\n然后后会出现一个 vim 打开的文本，将需要修改的 commit 信息前面的 pick 文本改成 edit，保存退出。\n修改邮箱信息\ngit commit --amend --author=\u0026quot;name \u0026lt;name@qq.com\u0026gt;\u0026quot; --no-edit\n这时候查看 git log 信息，发现邮箱已经更改了。\n强制 push 到远程（注意风险）\ngit push -f origin HEAD:master\ndone！","title":"git 修改已经 commit 的邮箱信息"},{"content":"protoc 编译生成的 pb.go 文件，默认情况下 tag 中会设置 json 忽略零值的返回属性 omitempty。\ntype Message struct { Header map[string]string `protobuf:\u0026#34;bytes,1,rep,name=header,proto3\u0026#34; json:\u0026#34;header,omitempty\u0026#34; protobuf_key:\u0026#34;bytes,1,opt,name=key,proto3\u0026#34; protobuf_val:\u0026#34;bytes,2,opt,name=value,proto3\u0026#34;` Body []byte `protobuf:\u0026#34;bytes,2,opt,name=body,proto3\u0026#34; json:\u0026#34;body,omitempty\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } 一个比较 hack 的方式，是在 pb.go 文件生成后，手动去删掉 omitempty 。每次手动去删除，比较麻烦且容易出错，下面提供一个 Makefile ，每次生成 pb.go 的时候就去删除 omitempty 。\nproto: protoc --proto_path=. --go_out=. --micro_out=. config/config.proto ls config/*.pb.go | xargs -n1 -IX bash -c \u0026#39;sed s/,omitempty// X \u0026gt; X.tmp \u0026amp;\u0026amp; mv X{.tmp,}\u0026#39; proto 目标的第一个命令是调用 protoc 根据 config/config.proto 生成 pb.go 文件；\n第二行命令就是将 config/*.pb.go 中的 omitempty 删除。\ntype Message struct { Header map[string]string `protobuf:\u0026#34;bytes,1,rep,name=header,proto3\u0026#34; json:\u0026#34;header\u0026#34; protobuf_key:\u0026#34;bytes,1,opt,name=key,proto3\u0026#34; protobuf_val:\u0026#34;bytes,2,opt,name=value,proto3\u0026#34;` Body []byte `protobuf:\u0026#34;bytes,2,opt,name=body,proto3\u0026#34; json:\u0026#34;body\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } 使用时，根据需要修改 config/config.proto 和 config/*.pb.go 即可。\n","permalink":"https://mogutou.xyz/posts/practice/protobuf-json/","summary":"protoc 编译生成的 pb.go 文件，默认情况下 tag 中会设置 json 忽略零值的返回属性 omitempty。\ntype Message struct { Header map[string]string `protobuf:\u0026#34;bytes,1,rep,name=header,proto3\u0026#34; json:\u0026#34;header,omitempty\u0026#34; protobuf_key:\u0026#34;bytes,1,opt,name=key,proto3\u0026#34; protobuf_val:\u0026#34;bytes,2,opt,name=value,proto3\u0026#34;` Body []byte `protobuf:\u0026#34;bytes,2,opt,name=body,proto3\u0026#34; json:\u0026#34;body,omitempty\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } 一个比较 hack 的方式，是在 pb.go 文件生成后，手动去删掉 omitempty 。每次手动去删除，比较麻烦且容易出错，下面提供一个 Makefile ，每次生成 pb.go 的时候就去删除 omitempty 。\nproto: protoc --proto_path=. --go_out=. --micro_out=. config/config.proto ls config/*.pb.go | xargs -n1 -IX bash -c \u0026#39;sed s/,omitempty// X \u0026gt; X.tmp \u0026amp;\u0026amp; mv X{.tmp,}\u0026#39; proto 目标的第一个命令是调用 protoc 根据 config/config.","title":"golang protobuf 字段为零值时 json 序列化忽略问题"},{"content":" 尝试发送  select { case c \u0026lt;- struct{}{}: default: fmt.Println(\u0026#34;chan 已满，发送不成功\u0026#34;) }  尝试接收  select { case v := \u0026lt;- c: default: fmt.Println(\u0026#34;chan 中没有信息，接收不成功\u0026#34;) }  标准编译器对尝试发送和尝试接收代码块做了特别的优化，使得它们的执行效率比多 case分支的普通 select代码块执行效率高得多。\n  无阻塞的检查一个 chan 是否关闭  假设我们可以保证没有任何协程会向一个通道发送数据，则我们可以使用下面的代码来（并发安全地）检查此通道是否已经关闭，此检查不会阻塞当前协程。\nfunc IsClosed(c chan struct{}) bool { select { case \u0026lt;-c: return true default: } return false }  最快回应  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) func source(c chan\u0026lt;- int, id int) { rb := rand.Intn(3)+1 // 休眠1秒/2秒/3秒 \ttime.Sleep(time.Duration(rb) * time.Second) // 使用尝试放松，防止阻塞 \tselect { case c \u0026lt;- id: default: } } func main() { rand.Seed(time.Now().UnixNano()) c := make(chan int, 1) // 此通道容量必须至少为1 \tfor i := 0; i \u0026lt; 5; i++ { go source(c, i) } id := \u0026lt;-c // 只采用第一个成功发送的回应数据 \tfmt.Println(id) }  超时机制  func doRequest(data chan int) { time.Sleep(time.Second * 10) data \u0026lt;- 1 } func requestWithTimeout(timeout time.Duration) (int, error) { data := make(chan int) go doRequest(data) // 可能需要超出预期的时长回应  select { case data := \u0026lt;-data: return data, nil case \u0026lt;-time.After(timeout): return 0, errors.New(\u0026#34;超时了！\u0026#34;) } }  防止重复 close chan  func Stop() error { select { case \u0026lt;-w.exit: default: close(w.exit)g } return nil } ","permalink":"https://mogutou.xyz/posts/go/go-channel/","summary":"尝试发送  select { case c \u0026lt;- struct{}{}: default: fmt.Println(\u0026#34;chan 已满，发送不成功\u0026#34;) }  尝试接收  select { case v := \u0026lt;- c: default: fmt.Println(\u0026#34;chan 中没有信息，接收不成功\u0026#34;) }  标准编译器对尝试发送和尝试接收代码块做了特别的优化，使得它们的执行效率比多 case分支的普通 select代码块执行效率高得多。\n  无阻塞的检查一个 chan 是否关闭  假设我们可以保证没有任何协程会向一个通道发送数据，则我们可以使用下面的代码来（并发安全地）检查此通道是否已经关闭，此检查不会阻塞当前协程。\nfunc IsClosed(c chan struct{}) bool { select { case \u0026lt;-c: return true default: } return false }  最快回应  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) func source(c chan\u0026lt;- int, id int) { rb := rand.","title":"go chan 实用示例"},{"content":"二叉堆是一组能够用堆有序的完全二叉树排序的元素，一般用数组来存储。\n大顶堆， 每个结点的值都大于或等于其左右孩子结点的值，其顶部为最大值。\n小顶堆，每个结点的值都小于或等于其左右孩子结点的值，其顶部为最小值。\n二叉堆 性质  根节点在数组中的位置是 1  左边子节点 2i 右子节点 2i+1 父节点 i / 2 最后一个非叶子节点为 len / 2   根节点在数组中的位置是 0 左子节点 2i + 1 右边子节点 2i+ 2 父节点的下标是 (i − 1) / 2 最后一个非叶子节点为 len / 2 - 1   图片来自知乎\n 实现 构造二叉堆  找到最后一个非叶子节点 ( len / 2 或者 len / 2 - 1） 从最后一个非叶子节点下标索引开始递减，逐个下沉  插入节点  在数组的最末尾插入新节点 将最后一个节点上浮，时间复杂度为O(log n)  比较当前节点与父节点 不满足 堆性质* *则交换    删除根节点  删除根节点用于堆排序\n  对于最大堆，删除根节点就是删除最大值；\n  对于最小堆，是删除最小值。\n  交换根节点和最后一个节点 将此时的根节点下沉，时间复杂度为O(log n)  比较当前节点与子节点（左，右） 不满足 堆性质 则交换   删除最后一个节点  代码 https://github.com/Allenxuxu/dsa/blob/master/heap/heap.go\n堆排序 堆排序是借助“堆”这种数据结构进行排序的排序算法。\n实现  将原数组构造成堆 将堆顶元素和数组最后一个元素交换，然后执行下沉操作修复堆（此时修复的堆长度-1，最后一个元素用来存放有序数据） 重复上述步骤，直至堆为空  代码 https://github.com/Allenxuxu/dsa/blob/master/sort/heapsort.go\ntype Interface interface { // Len is the number of elements in the collection.  Len() int // Less reports whether the element with  // index i should sort before the element with index j.  Less(i, j int) bool // Swap swaps the elements with indexes i and j.  Swap(i, j int) } func down(data Interface, root, n int) { for { child := 2*root + 1 // left child  if child \u0026amp;gt;= n { break } if child+1 \u0026amp;lt; n \u0026amp;amp;\u0026amp;amp; data.Less(child, child+1) { // right = child+1  child++ } if data.Less(child, root) { return } data.Swap(root, child) root = child } } func HeapSort(data Interface) { n := data.Len() // Build heap with greatest element at top.  for i := n/2 - 1; i \u0026amp;gt;= 0; i-- { down(data, i, n) } // Pop elements, largest first, into end of data.  for i := n - 1; i \u0026amp;gt;= 0; i-- { data.Swap(0, i) down(data, 0, i) } } 应用 堆排序是唯一能够同时最优化的利用空间和时间的方法 \u0026ndash; 在最坏的情况下也能保证使用 2NlogN 次比较和恒定额外空间。\n但是，现代系统中许多应用很少使用它，因为它无法利用缓存 \u0026ndash; 数组元素很少和相邻的元素进行比较。因此缓存命中次数远低于在相邻元素进行比较的算法，如快速排序，归并排序，甚至是希尔排序。\n","permalink":"https://mogutou.xyz/posts/algorithm/heap/","summary":"二叉堆是一组能够用堆有序的完全二叉树排序的元素，一般用数组来存储。\n大顶堆， 每个结点的值都大于或等于其左右孩子结点的值，其顶部为最大值。\n小顶堆，每个结点的值都小于或等于其左右孩子结点的值，其顶部为最小值。\n二叉堆 性质  根节点在数组中的位置是 1  左边子节点 2i 右子节点 2i+1 父节点 i / 2 最后一个非叶子节点为 len / 2   根节点在数组中的位置是 0 左子节点 2i + 1 右边子节点 2i+ 2 父节点的下标是 (i − 1) / 2 最后一个非叶子节点为 len / 2 - 1   图片来自知乎\n 实现 构造二叉堆  找到最后一个非叶子节点 ( len / 2 或者 len / 2 - 1） 从最后一个非叶子节点下标索引开始递减，逐个下沉  插入节点  在数组的最末尾插入新节点 将最后一个节点上浮，时间复杂度为O(log n)  比较当前节点与父节点 不满足 堆性质* *则交换    删除根节点  删除根节点用于堆排序","title":"二叉堆与堆排序"},{"content":" 图片来自 leetcode\n  深度优先遍历（dfs）  前序遍历 中序遍历 后序遍历   广度优先遍历（bfs）  type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 深度优先遍历 递归 递归版本，代码比较简单，只需改变 append 数据的位置即可。\n前序遍历 func preorderTraversal(root *TreeNode) []int { var ret []int helper(root, \u0026amp;ret) return ret } func helper(root *TreeNode, data *[]int) { if root == nil { return } *data = append(*data, root.Val) helper(root.Left, data) helper(root.Right, data) } 中序遍历 func inorderTraversal(root *TreeNode) []int { var ret []int helper(root, \u0026amp;ret) return ret } func helper(root *TreeNode, data *[]int) { if root == nil { return } helper(root.Left, data) *data = append(*data, root.Val) helper(root.Right, data) } 后序遍历 func postorderTraversal(root *TreeNode) []int { var ret []int helperPostOrder(root, \u0026amp;ret) return ret } func helperPostOrder(root *TreeNode, data *[]int) { if root == nil { return } helperPostOrder(root.Left, data) helperPostOrder(root.Right, data) *data = append(*data, root.Val) } 迭代 迭代版本，稍微复杂，需要模拟函数调用栈，需要使用 stack，只需要改变压栈的位置即可，代码模版性较好，便于记忆。\n在文末附录有基于 golang 标准库的 list 实现的 stack 。\n前序遍历 func preorderTraversal(root *TreeNode) []int { if root == nil { return nil } var ret []int s := stack.New() s.Push(root) for s.Len() \u0026gt; 0 { c := s.Pop() if c != nil { node := c.(*TreeNode) if node.Right != nil { //右节点先压栈，最后处理 \ts.Push(node.Right) } if node.Left != nil { s.Push(node.Left) } s.Push(node) //当前节点重新压栈（留着以后处理），因为先序遍历所以最后压栈 \ts.Push(nil) //在当前节点之前加入一个空节点表示已经访问过了 \t} else { // 当前 c == nil , 说明这个节点已经访问过了 \tnode := s.Pop().(*TreeNode) // node 是上面 s.Push(node) 中的那个 node \tret = append(ret, node.Val) } } return ret } 中序遍历 func inorderTraversal(root *TreeNode) []int { if root == nil { return nil } var ret []int s := stack.New() s.Push(root) for s.Len() \u0026gt; 0 { c := s.Pop() if c != nil { node := c.(*TreeNode) if node.Right != nil { s.Push(node.Right) //右节点先压栈，最后处理 \t} s.Push(node) s.Push(nil) if node.Left != nil { s.Push(node.Left) } } else { node := s.Pop().(*TreeNode) ret = append(ret, node.Val) } } return ret } 后序遍历 func postorderTraversal(root *TreeNode) []int { if root == nil { return nil } var ret []int s := stack.New() s.Push(root) for s.Len() \u0026gt; 0 { c := s.Pop() if c != nil { node := c.(*TreeNode) s.Push(node) s.Push(nil) if node.Right != nil { s.Push(node.Right) } if node.Left != nil { s.Push(node.Left) } } else { node := s.Pop().(*TreeNode) ret = append(ret, node.Val) } } return ret } 广度优先遍历 广度优先遍历需要使用 queue，文末附录有 queue 的简单实现。\nfunc levelOrder(root *TreeNode) [][]int { if root == nil { return nil } var ret [][]int q := queue.New(10) q.Push(root) for q.Len() \u0026gt; 0 { size := q.Len() tmp := make([]int, 0, size) for i := 0; i \u0026lt; size; i++ { node := q.Pop() tmp = append(tmp, node.Val) if node.Left != nil { q.Push(node.Left) } if node.Right != nil { q.Push(node.Right) } } ret = append(ret, tmp) } return ret } 附录 stack 实现 package stack import \u0026#34;container/list\u0026#34; type Stack interface { Push(v interface{}) Pop() interface{} Len() int } type stack struct { list *list.List } func New() Stack { return \u0026amp;stack{ list: list.New(), } } func (s *stack) Push(v interface{}) { s.list.PushBack(v) } func (s *stack) Pop() interface{} { v := s.list.Back() if v == nil { return nil } return s.list.Remove(v) } func (s *stack) Len() int { return s.list.Len() } queue实现 type queue struct { array []*TreeNode } func New(size int) *queue { return \u0026amp;queue{ array: make([]*TreeNode, 0, size), } } func (q *queue) Push(i *TreeNode) { q.array = append(q.array, i) } func (q *queue) Pop() *TreeNode { if q.Len() == 0 { return nil } e := q.array[0] q.array = q.array[1:] return e } func (q *queue) Len() int { return len(q.array) } ","permalink":"https://mogutou.xyz/posts/algorithm/tree-traversal/","summary":"图片来自 leetcode\n  深度优先遍历（dfs）  前序遍历 中序遍历 后序遍历   广度优先遍历（bfs）  type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 深度优先遍历 递归 递归版本，代码比较简单，只需改变 append 数据的位置即可。\n前序遍历 func preorderTraversal(root *TreeNode) []int { var ret []int helper(root, \u0026amp;ret) return ret } func helper(root *TreeNode, data *[]int) { if root == nil { return } *data = append(*data, root.Val) helper(root.Left, data) helper(root.Right, data) } 中序遍历 func inorderTraversal(root *TreeNode) []int { var ret []int helper(root, \u0026amp;ret) return ret } func helper(root *TreeNode, data *[]int) { if root == nil { return } helper(root.","title":"二叉树的遍历模版（递归，迭代）"},{"content":"Github Actions 是 Github 内置的 CI/CD 工具，现在已经对所有的开源项目免费开放了。\n本文主要记录使用 Github Actions 实践 CI/CD 的一些配置。\n功能目标  代码静态检查 代码单元测试 release/tag 时自动 build 镜像并推送到 docker hub  项目 Dockerfile 和 Makefile 项目主要目录\n. ├── LICENSE ├── Makefile ├── README.md ├── config-srv │ ├── Makefile │ └── main.go ├── deployments │ ├── docker │ │ ├── config-srv │ │ │ └── Dockerfile ├── go.mod ├── go.sum  config-srv 目录：服务代码 deployments 目录：所有服务的 Dockerfile Makefile 顶层 Makefile：build Docker 镜像  我们先看下顶层的 Makefile\n.PHONY: config-srv config-srv: docker build -f deployments/docker/config-srv/Dockerfile . -t config-srv 我们可以在后面配置的 Github Actions 配置文件中执行 make config-srv，这样就会执行 docker build -f deployments/docker/config-srv/Dockerfile . -t config-srv ，构建一个 docker 镜像。\n接下来，看一下 deployments/docker/config-srv/Dockerfile ，配置 Dockerfile 多阶段构建 。\nFROM golang:1.13-alpine as builder WORKDIR /root COPY ./ ./ RUN export GO111MODULE=on \u0026amp;\u0026amp; CGO_ENABLED=0 GOOS=linux go build -o build/config-srv config-srv/main.go FROM alpine:latest RUN apk --no-cache add ca-certificates WORKDIR /root COPY --from=builder /root/build/config-srv ./ ENTRYPOINT [\u0026quot;/root/config-srv\u0026quot;] Github Actions 具体配置 commit 提交自动 CI name: CI on: push: branches: - master paths-ignore: - \u0026#39;README.md\u0026#39; pull_request: branches: - master paths-ignore: - \u0026#39;README.md\u0026#39; jobs: lint: # 使用golangci-lint 进行静态检查 name: Lint runs-on: ubuntu-latest steps: - name: Set up Go 1.13 uses: actions/setup-go@v1 with: go-version: 1.13 id: go - name: Code uses: actions/checkout@v1 - name: Intsall Golangci-lint  run: curl -sfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh| sh -s -- -b . latest - name: Lint run: ./golangci-lint run --skip-dirs=\u0026#34;.git|.github|dashboard|doc\u0026#34; --timeout=5m test: name: Unit Testing # go test runs-on: ${{ matrix.os }} strategy: matrix: os: [ubuntu-latest] # 选择系统类型 steps: - name: Set up Go 1.13 uses: actions/setup-go@v1 with: go-version: 1.13 id: go - name: Code uses: actions/checkout@v1 - name: Go Get dependencies run: go get -v -t -d ./... - name: Go Test run: go test -v ./... release/tag 时自动 CI/CD name: Release on:\t# 限定在 master 分支 release 操作时触发 release: types: [published] branches: - master jobs: lint: # 静态检查 name: Lint runs-on: ubuntu-latest steps: - name: Set up Go 1.13 uses: actions/setup-go@v1 with: go-version: 1.13 id: go - name: Code uses: actions/checkout@v1 - name: Intsall Golangci-lint run: curl -sfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh| sh -s -- -b . latest - name: Lint run: ./golangci-lint run --skip-dirs=\u0026#34;.git|.github|dashboard|doc\u0026#34; --timeout=5m test: name: Unit Testing  # 单元测试 runs-on: ${{ matrix.os }} strategy: matrix: os: [ubuntu-latest] steps: - name: Set up Go 1.13 uses: actions/setup-go@v1 with: go-version: 1.13 id: go - name: Code uses: actions/checkout@v1 - name: Go Get dependencies run: go get -v -t -d ./... - name: Go Test run: go test -v ./... docker: # build docker 镜像并且推送 needs: [lint, test] name: docker build and push runs-on: ubuntu-latest steps: - name: Code uses: actions/checkout@v1 - name: Set env run: echo ::set-env name=RELEASE_VERSION::$(echo ${GITHUB_REF:10}) # 取tag名称，后面作为 docker 的 tag - name: tag run: echo ${{ env.RELEASE_VERSION }} - name: config-srv  # 执行代码仓库中的 Makefile ，在 Makefile 中执行 docker build 操作 run: |make config-srv docker login docker.io -u ${{ secrets.REGISTRY_USERNAME }} -p ${{ secrets.REGISTRY_PASSWORD }} docker tag config-srv:latest ${{ secrets.REGISTRY_USERNAME }}/config-srv:latest docker tag config-srv:latest ${{ secrets.REGISTRY_USERNAME }}/config-srv:${{ env.RELEASE_VERSION }} docker push ${{ secrets.REGISTRY_USERNAME }}/config-srv:latest docker push ${{ secrets.REGISTRY_USERNAME }}/config-srv:${{ env.RELEASE_VERSION }} 上述的 ${{ secrets.REGISTRY_USERNAME }} 等环境变量，皆在 Github - settings - secrets 中设置。登陆 docker hub 所需要的账号密码或者其他敏感信息都在此设置，避免明文写在 yaml 中。\n在 Github 的项目仓库顶层 .github/workflows 文件夹放置两个 yml 文件即可。每次 commit 提交都会触发 ci.yml 中的配置逻辑，当 release 发布时就会触发 release.yml 中的配置逻辑。\n.github └── workflows ├── ci.yml └── release.yml 1 directory, 2 files 触发的 pipeline 可以在项目主页 Tab 栏点击 Actions 查看。\n本文 Makefile ，Dockefile ，CI 配置都节取自 XConf 项目，可以去仓库查看完整配置。\n相关实践项目  XConf : 基于 go-micro 构建的分布式配置中心。 Gev: 一个轻量、快速的基于 Reactor 模式的非阻塞 Golang TCP 网络库，支持自定义协议，轻松快速搭建高性能服务器。  ","permalink":"https://mogutou.xyz/posts/practice/github-action-docker/","summary":"Github Actions 是 Github 内置的 CI/CD 工具，现在已经对所有的开源项目免费开放了。\n本文主要记录使用 Github Actions 实践 CI/CD 的一些配置。\n功能目标  代码静态检查 代码单元测试 release/tag 时自动 build 镜像并推送到 docker hub  项目 Dockerfile 和 Makefile 项目主要目录\n. ├── LICENSE ├── Makefile ├── README.md ├── config-srv │ ├── Makefile │ └── main.go ├── deployments │ ├── docker │ │ ├── config-srv │ │ │ └── Dockerfile ├── go.mod ├── go.sum  config-srv 目录：服务代码 deployments 目录：所有服务的 Dockerfile Makefile 顶层 Makefile：build Docker 镜像  我们先看下顶层的 Makefile","title":"Github Actions 配置 CI/CD 自动发布 docker 镜像"},{"content":"go-micro 框架支持动态加载插件，无需修改代码。\n源码分析 启动服务前，设定 MICRO_PLUGIN 环境变量指定动态库 .so 文件路径，支持多个插件，逗号分割。程序启动前会读取 MICRO_PLUGIN 环境变量，并完成插件设定。\n下面是其内部实现：\n go-micro/service.go\n func (s *service) Init(opts ...Option) { ... // setup the plugins for _, p := range strings.Split(os.Getenv(\u0026quot;MICRO_PLUGIN\u0026quot;), \u0026quot;,\u0026quot;) { if len(p) == 0 { continue } // 加载 .so 文件 c, err := plugin.Load(p) if err != nil { logger.Fatal(err) } // go-micro 初始化插件 if err := plugin.Init(c); err != nil { logger.Fatal(err) } } 从上面的代码可以看出，service 初始化化的时候，读取 MICRO_PLUGIN 环境变量中指定的 .so 文件路径。并且调用 plugin 包，逐个 Init 。\n下面我们看下 plugin 包的实现：\nplugin ├── default.go ├── plugin.go └── template.go 0 directories, 3 files plugin 包的实现非常简单，只有三个文件。\n go-micro/plugin/plugin.go\n // Plugin is a plugin loaded from a file type Plugin interface { // Initialise a plugin with the config Init(c *Config) error // Load loads a .so plugin at the given path Load(path string) (*Config, error) // Build a .so plugin with config at the path specified Build(path string, c *Config) error } plugin 包定义了这样一个接口\n Init(c *Config) error 方法用来注册插件； Load(path string) (*Config, error) 用来加载一个 .so 文件，并返回一个 Config ； Build(path string, c *Config) error 用来根据指定的 Config 变量生成一个 .so 文件。  go-micro 提供了一个默认的实现，在 go-micro/plugin/default.go 。\n先来看一下默认实现的 Load 方法：\nimport ( //... pg \u0026quot;plugin\u0026quot; //... ) // Load loads a plugin created with `go build -buildmode=plugin` func (p *plugin) Load(path string) (*Config, error) { // 调用标准库打开 .so 文件 plugin, err := pg.Open(path) if err != nil { return nil, err } // 在加载成功的动态库文件中寻找 Plugin 变量/函数 s, err := plugin.Lookup(\u0026quot;Plugin\u0026quot;) if err != nil { return nil, err } // 类型转换成 go-micro 定义的 Config 类型指针 pl, ok := s.(*Config) if !ok { return nil, errors.New(\u0026quot;could not cast Plugin object\u0026quot;) } return pl, nil } Load 方法主要就是调用标准库 plugin open 一个 .so 文件，然后寻找 Plugin 这个变量，并通过类型断言它转换成 *Config 。Config 是 go-micro 定义的一个类型：\n// Config is the plugin config type Config struct { // Name of the plugin e.g rabbitmq Name string // Type of the plugin e.g broker Type string // Path specifies the import path Path string // NewFunc creates an instance of the plugin NewFunc interface{} } 关于标准库 plugin 的用法，这里不再描述可以查看源码文件，里面有用法说明。需要特别说明的一点是，标准库 plugin 的 Lookup 方法返回 Symbol 类型，它可以类型转换成一个函数或者指向变量的指针。\n我们继续看 go-micro 的 Init 方法实现：\n// Init sets up the plugin func (p *plugin) Init(c *Config) error { switch c.Type { case \u0026quot;broker\u0026quot;: pg, ok := c.NewFunc.(func(...broker.Option) broker.Broker) if !ok { return fmt.Errorf(\u0026quot;Invalid plugin %s\u0026quot;, c.Name) } cmd.DefaultBrokers[c.Name] = pg case \u0026quot;client\u0026quot;: pg, ok := c.NewFunc.(func(...client.Option) client.Client) if !ok { return fmt.Errorf(\u0026quot;Invalid plugin %s\u0026quot;, c.Name) } cmd.DefaultClients[c.Name] = pg case \u0026quot;registry\u0026quot;: pg, ok := c.NewFunc.(func(...registry.Option) registry.Registry) if !ok { return fmt.Errorf(\u0026quot;Invalid plugin %s\u0026quot;, c.Name) } cmd.DefaultRegistries[c.Name] = pg // .... 省略一些 case default: return fmt.Errorf(\u0026quot;Unknown plugin type: %s for %s\u0026quot;, c.Type, c.Name) } return nil } 这个函数是 micro 实现动态加载的重点，Init 函数通过 Load 方法返回的 Config 变量进行选择，然后通过类型转换得到 对应的构建函数赋值给 go-micro 的 cmd 包里的全局变量 DefaultXXXs 。\n go-micro/config/cmd/cmd.go\n \tDefaultBrokers = map[string]func(...broker.Option) broker.Broker{ \u0026quot;service\u0026quot;: brokerSrv.NewBroker, \u0026quot;memory\u0026quot;: memory.NewBroker, \u0026quot;nats\u0026quot;: nats.NewBroker, } DefaultClients = map[string]func(...client.Option) client.Client{ \u0026quot;mucp\u0026quot;: cmucp.NewClient, \u0026quot;grpc\u0026quot;: cgrpc.NewClient, } 以 DefaultClients 为例，假设我们实现了一个 client 插件(需要实现 go-micro 的 client.Client 接口) 并实现了自己的创建函数 xrpc.NewClient 。那加载插件成功后， DefaultClients 变量就是\nmap[string]func(...client.Option) client.Client{ \u0026quot;mucp\u0026quot;: cmucp.NewClient, \u0026quot;grpc\u0026quot;: cgrpc.NewClient, \u0026quot;xrpc\u0026quot;: xrpc.NewClient, } 在 cmd 对象的 Before 方法中会根据程序启动时传入的参数来选择对应的插件。\n go-micro/config/cmd/cmd.go\n // Set the client if name := ctx.String(\u0026quot;client\u0026quot;); len(name) \u0026gt; 0 { // only change if we have the client and type differs if cl, ok := c.opts.Clients[name]; ok \u0026amp;\u0026amp; (*c.opts.Client).String() != name { *c.opts.Client = cl() } }  GLOBAL OPTIONS: \u0026ndash;client value Client for go-micro; rpc [$MICRO_CLIENT]\n 如果启动程序时设定了 client=xrpc ，必须记得设定 MICRO_PLUGIN 环境变量指定动态库。这里设定的 c.opts.Client 会被 micro 服务所使用，可以一步一步向上追溯，这里就不追踪了。\n上面的源码分析中，我们没有看 go-micro plugin 包的 Build 方法默认实现，现在我们来看一下：\n// Build generates a dso plugin using the go command `go build -buildmode=plugin` func (p *plugin) Build(path string, c *Config) error { path = strings.TrimSuffix(path, \u0026quot;.so\u0026quot;) // 在 tmp 目录创建一个临时go源码文件 temp := os.TempDir() base := filepath.Base(path) goFile := filepath.Join(temp, base+\u0026quot;.go\u0026quot;) // 根据模版生成 go 代码到文件中 if err := p.Generate(goFile, c); err != nil { return err } // defer 函数执行完成时候删除这个临时go源码文件 defer os.Remove(goFile) if err := os.MkdirAll(filepath.Dir(path), 0755); err != nil \u0026amp;\u0026amp; !os.IsExist(err) { return fmt.Errorf(\u0026quot;Failed to create dir %s: %v\u0026quot;, filepath.Dir(path), err) } // 将这个文件编译成动态库 cmd := exec.Command(\u0026quot;go\u0026quot;, \u0026quot;build\u0026quot;, \u0026quot;-buildmode=plugin\u0026quot;, \u0026quot;-o\u0026quot;, path+\u0026quot;.so\u0026quot;, goFile) cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr return cmd.Run() } 可以看出，主要就是更具传入的文件路径，创建目录，创建一个临时的go文件，然后调用 go build -buildmode=plugin 生成动态库。\n这里调用的一个 Generate 方法，这个方法通过 go 模版生成 go 文件。\n// Generate creates a go file at the specified path. // You must use `go build -buildmode=plugin`to build it. func (p *plugin) Generate(path string, c *Config) error { f, err := os.Create(path) if err != nil { return err } defer f.Close() t, err := template.New(c.Name).Parse(tmpl) if err != nil { return err } return t.Execute(f, c) } // ...  var ( tmpl = ` package main import ( \u0026#34;github.com/micro/go-micro/v2/plugin\u0026#34; \u0026#34;{{.Path}}\u0026#34; ) var Plugin = plugin.Config{ Name: \u0026#34;{{.Name}}\u0026#34;, Type: \u0026#34;{{.Type}}\u0026#34;, Path: \u0026#34;{{.Path}}\u0026#34;, NewFunc: {{.Name}}.{{.NewFunc}}, } ` ) 根据模版生成 go 文件中会有一个全局变量 Plugin，这也印证了 Load 方法中的 plugin.Lookup(\u0026quot;Plugin\u0026quot;) 。\n简单使用 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/micro/go-micro/v2/plugin\u0026quot; ) func main() { p := plugin.NewPlugin() if err := p.Build(\u0026quot;/tmp/test.so\u0026quot;, \u0026amp;plugin.Config{ Name: \u0026quot;client\u0026quot;, Type: \u0026quot;client\u0026quot;, Path: \u0026quot;github.com/micro/go-micro/v2/client\u0026quot;, NewFunc: \u0026quot;NewClient\u0026quot;, }); err != nil { panic(err) } c, err := plugin.Load(\u0026quot;/tmp/test.so\u0026quot;) if err != nil { panic(err) } fmt.Println(c.Name, c.Type, c.Path, c.NewFunc) } 上面的例子，主要是使用了 go-micro 的 plugin 包。先生成了 /tmp/test.so ，然后在 Load 这个动态库，打印 config 的内容。\n当然也可以，不通过 plugin.Build 生成动态库，直接手写一个 go 文件，手动编译成动态库。\n test.go\n package main import ( \u0026quot;github.com/micro/go-micro/v2/client\u0026quot; \u0026quot;github.com/micro/go-micro/v2/plugin\u0026quot; ) var Plugin = plugin.Config{ Name: \u0026quot;test\u0026quot;, Type: \u0026quot;client\u0026quot;, Path: \u0026quot;github.com/micro/go-micro/v2/client\u0026quot;, NewFunc: client.NewClient, } go build -buildmode=plugin -o ./test.so test.go go-micro 动态加载的主要场景 假设我们的 micro 服务 client 使用的是 grpc 的形式，现在希望改成 brpc 的形式。go-micro 支持的 client 插件中并不包含 brpc，我们自己使用 brpc 实现一个 client 插件，然后将其编译成动态库。\n在运行环境 MICRO_PLUGIN 变量指定动态库路径，并且修改程序的启动命令，指定 client=brpc 。这样就可以做到无需重新编译二进制，替换自己想要的插件。\n当然，自己在代码中重新 import 自己实现的插件库，显示指定 client 也是可以的。这样还可以将变更纳入版本管理，也是极好的。\n","permalink":"https://mogutou.xyz/posts/go-micro/go-micro-plugin/","summary":"go-micro 框架支持动态加载插件，无需修改代码。\n源码分析 启动服务前，设定 MICRO_PLUGIN 环境变量指定动态库 .so 文件路径，支持多个插件，逗号分割。程序启动前会读取 MICRO_PLUGIN 环境变量，并完成插件设定。\n下面是其内部实现：\n go-micro/service.go\n func (s *service) Init(opts ...Option) { ... // setup the plugins for _, p := range strings.Split(os.Getenv(\u0026quot;MICRO_PLUGIN\u0026quot;), \u0026quot;,\u0026quot;) { if len(p) == 0 { continue } // 加载 .so 文件 c, err := plugin.Load(p) if err != nil { logger.Fatal(err) } // go-micro 初始化插件 if err := plugin.Init(c); err != nil { logger.Fatal(err) } } 从上面的代码可以看出，service 初始化化的时候，读取 MICRO_PLUGIN 环境变量中指定的 .","title":"go-micro 动态加载插件源码分析"},{"content":"https://github.com/Allenxuxu/gev\n gev 是一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库，支持自定义协议，轻松快速搭建高性能服务器。\n TCP 为什么会\u0026quot;粘包\u0026quot; TCP 本身就是面向流的协议，就是一串没有界限的数据。所以本质上来说 TCP 粘包是一个伪命题。\nTCP 底层并不关心上层业务数据，会套接字缓冲区的实际情况进行包的划分，一个完整的业务数据可能会被拆分成多次进行发送，也可能会将多个小的业务数据封装成一个大的数据包发送（Nagle算法）。\ngev 如何优雅处理 gev 通过回调函数 OnMessage 通知用户数据到来，回调函数中会将用户数据缓冲区（ringbuffer）通过参数传递过来。\n用户通过对 ringbuffer 操作，来进行数据解包，获取到完整用户数据后再进行业务操作。这样又一个明显的缺点，就是会让业务操作和自定义协议解析代码堆在一起。\n所以，最近对 gev 进行了一次较大改动，主要是为了能够以插件的形式支持各种自定义的数据协议，让使用者可以便捷处理 TCP 粘包问题，专注于业务逻辑。\n做法如下，定义一个接口 Protocol\n// Protocol 自定义协议编解码接口 type Protocol interface { UnPacket(c *Connection, buffer *ringbuffer.RingBuffer) (interface{}, []byte) Packet(c *Connection, data []byte) []byte } 用户只需实现这个接口，并注册到 server 中，当客户端数据到来时，gev 会首先调用 UnPacket 方法，如果缓冲区中的数据足够组成一帧，则将数据解包，并返回真正的用户数据，然后在回调 OnMessage 函数并将数据通过参数传递。\n下面，我们实现一个简单的自定义协议插件，来启动一个 Server ：\n| 数据长度 n | payload | | 4字节 | n 字节 | // protocol.go package main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;github.com/Allenxuxu/gev/connection\u0026#34; \u0026#34;github.com/Allenxuxu/ringbuffer\u0026#34; \u0026#34;github.com/gobwas/pool/pbytes\u0026#34; ) const exampleHeaderLen = 4 type ExampleProtocol struct{} func (d *ExampleProtocol) UnPacket(c *connection.Connection, buffer *ringbuffer.RingBuffer) (interface{}, []byte) { if buffer.VirtualLength() \u0026gt; exampleHeaderLen { buf := pbytes.GetLen(exampleHeaderLen) defer pbytes.Put(buf) _, _ = buffer.VirtualRead(buf) dataLen := binary.BigEndian.Uint32(buf) if buffer.VirtualLength() \u0026gt;= int(dataLen) { ret := make([]byte, dataLen) _, _ = buffer.VirtualRead(ret) buffer.VirtualFlush() return nil, ret } else { buffer.VirtualRevert() } } return nil, nil } func (d *ExampleProtocol) Packet(c *connection.Connection, data []byte) []byte { dataLen := len(data) ret := make([]byte, exampleHeaderLen+dataLen) binary.BigEndian.PutUint32(ret, uint32(dataLen)) copy(ret[4:], data) return ret } // server.go package main import ( \u0026#34;flag\u0026#34; \u0026#34;log\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/Allenxuxu/gev\u0026#34; \u0026#34;github.com/Allenxuxu/gev/connection\u0026#34; ) type example struct{} func (s *example) OnConnect(c *connection.Connection) { log.Println(\u0026#34; OnConnect ： \u0026#34;, c.PeerAddr()) } func (s *example) OnMessage(c *connection.Connection, ctx interface{}, data []byte) (out []byte) { log.Println(\u0026#34;OnMessage：\u0026#34;, data) out = data return } func (s *example) OnClose(c *connection.Connection) { log.Println(\u0026#34;OnClose\u0026#34;) } func main() { handler := new(example) var port int var loops int flag.IntVar(\u0026amp;port, \u0026#34;port\u0026#34;, 1833, \u0026#34;server port\u0026#34;) flag.IntVar(\u0026amp;loops, \u0026#34;loops\u0026#34;, -1, \u0026#34;num loops\u0026#34;) flag.Parse() s, err := gev.NewServer(handler, gev.Address(\u0026#34;:\u0026#34;+strconv.Itoa(port)), gev.NumLoops(loops), gev.Protocol(\u0026amp;ExampleProtocol{})) if err != nil { panic(err) } log.Println(\u0026#34;server start\u0026#34;) s.Start() } 完整代码地址\n当回调 OnMessage 函数的时候，会通过参数传递已经拆好包的用户数据。\n当我们需要使用其他协议时，仅仅需要实现一个 Protocol 插件，然后只要 gev.NewServer 时指定即可：\ngev.NewServer(handler, gev.NumLoops(2), gev.Protocol(\u0026amp;XXXProtocol{})) 基于 Protocol Plugins 模式为 gev 实现 WebSocket 插件 得益于 Protocol Plugins 模式的引进，我可以将 WebSocket 的实现做成一个插件（WebSocket 协议构建在 TCP 之上），独立于 gev 之外。\npackage websocket import ( \u0026#34;log\u0026#34; \u0026#34;github.com/Allenxuxu/gev/connection\u0026#34; \u0026#34;github.com/Allenxuxu/gev/plugins/websocket/ws\u0026#34; \u0026#34;github.com/Allenxuxu/ringbuffer\u0026#34; ) // Protocol websocket type Protocol struct { upgrade *ws.Upgrader } // New 创建 websocket Protocol func New(u *ws.Upgrader) *Protocol { return \u0026amp;Protocol{upgrade: u} } // UnPacket 解析 websocket 协议，返回 header ，payload func (p *Protocol) UnPacket(c *connection.Connection, buffer *ringbuffer.RingBuffer) (ctx interface{}, out []byte) { upgraded := c.Context() if upgraded == nil { var err error out, _, err = p.upgrade.Upgrade(buffer) if err != nil { log.Println(\u0026#34;Websocket Upgrade :\u0026#34;, err) return } c.SetContext(true) } else { header, err := ws.VirtualReadHeader(buffer) if err != nil { log.Println(err) return } if buffer.VirtualLength() \u0026gt;= int(header.Length) { buffer.VirtualFlush() payload := make([]byte, int(header.Length)) _, _ = buffer.Read(payload) if header.Masked { ws.Cipher(payload, header.Mask, 0) } ctx = \u0026amp;header out = payload } else { buffer.VirtualRevert() } } return } // Packet 直接返回 func (p *Protocol) Packet(c *connection.Connection, data []byte) []byte { return data } 具体的实现，可以到仓库的 plugins/websocket 查看。\n","permalink":"https://mogutou.xyz/posts/open-source/gev-protocol/","summary":"https://github.com/Allenxuxu/gev\n gev 是一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库，支持自定义协议，轻松快速搭建高性能服务器。\n TCP 为什么会\u0026quot;粘包\u0026quot; TCP 本身就是面向流的协议，就是一串没有界限的数据。所以本质上来说 TCP 粘包是一个伪命题。\nTCP 底层并不关心上层业务数据，会套接字缓冲区的实际情况进行包的划分，一个完整的业务数据可能会被拆分成多次进行发送，也可能会将多个小的业务数据封装成一个大的数据包发送（Nagle算法）。\ngev 如何优雅处理 gev 通过回调函数 OnMessage 通知用户数据到来，回调函数中会将用户数据缓冲区（ringbuffer）通过参数传递过来。\n用户通过对 ringbuffer 操作，来进行数据解包，获取到完整用户数据后再进行业务操作。这样又一个明显的缺点，就是会让业务操作和自定义协议解析代码堆在一起。\n所以，最近对 gev 进行了一次较大改动，主要是为了能够以插件的形式支持各种自定义的数据协议，让使用者可以便捷处理 TCP 粘包问题，专注于业务逻辑。\n做法如下，定义一个接口 Protocol\n// Protocol 自定义协议编解码接口 type Protocol interface { UnPacket(c *Connection, buffer *ringbuffer.RingBuffer) (interface{}, []byte) Packet(c *Connection, data []byte) []byte } 用户只需实现这个接口，并注册到 server 中，当客户端数据到来时，gev 会首先调用 UnPacket 方法，如果缓冲区中的数据足够组成一帧，则将数据解包，并返回真正的用户数据，然后在回调 OnMessage 函数并将数据通过参数传递。\n下面，我们实现一个简单的自定义协议插件，来启动一个 Server ：\n| 数据长度 n | payload | | 4字节 | n 字节 | // protocol.","title":"[gev] 自定义协议支持"},{"content":"Uber Go 风格指南  译文：https://github.com/Allenxuxu/uber-go-guide 原文：https://github.com/uber-go/guide/blob/master/style.md  简介 风格是指规范代码的共同约定。风格一词其实是有点用词不当的，因为共同约定的范畴远远不止 gofmt 所做的源代码格式化这些。\n本指南旨在通过详尽描述 Uber 在编写 Go 代码中的注意事项（规定）来解释其中复杂之处。制定这些注意事项（规定）是为了提高代码可维护性同时也让工程师们高效的使用 Go 的特性。\n这份指南最初由 Prashant Varanasi 和 Simon Newton 编写，目的是让一些同事快速上手 Go 。多年来，已经根据其他人的反馈不断修改。\n这份文档记录了我们在 Uber 遵守的 Go 惯用准则。其中很多准则是 Go 的通用准则，其他方面依赖于外部资源：\n Effective Go The Go common mistakes guide  所有的代码都应该通过 golint 和 go vet 检查。我们建议您设置编辑器：\n 保存时自动运行 goimports 自动运行 golint 和 go vet 来检查错误  您可以在这找到关于编辑器设定 Go tools 的相关信息：\nhttps://github.com/golang/go/wiki/IDEsAndTextEditorPlugins\n指南 指向接口（interface）的指针 你基本永远不需要一个指向接口的指针。你应该直接将接口作为值传递，因为接口的底层数据就是指针。\n一个接口包含两个字段：\n 类型指针，指向某些特定类型信息的指针。 数据指针。如果存储数据是一个指针变量，那就直接存储。如果存储数据是一个值变量，那就存储指向该值的指针。  如果你需要接口方法来修改这些底层数据，那你必须使用指针。\n方法接收器和接口 具有值类型接收器的方法可以被值类型和指针类型调用。\n例如，\ntype S struct { data string } func (s S) Read() string { return s.data } func (s *S) Write(str string) { s.data = str } sVals := map[int]S{1: {\u0026#34;A\u0026#34;}} // 值类型变量只能调用 Read 方法 sVals[1].Read() // 无法编译通过: // sVals[0].Write(\u0026#34;test\u0026#34;)  sPtrs := map[int]*S{1: {\u0026#34;A\u0026#34;}} // 指针类型变量可以调用 Read 和 Write 方法： sPtrs[1].Read() sPtrs[1].Write(\u0026#34;test\u0026#34;) 同理，即使方法是值类型接收器，接口也可以通过指针来满足调用需求。\ntype F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} s1Val := S1{} s1Ptr := \u0026amp;S1{} s2Val := S2{} s2Ptr := \u0026amp;S2{} var i F i = s1Val i = s1Ptr i = s2Ptr // 无法编译通过, 因为 s2Val 是一个值类型变量, 并且 f 方法不具有值类型接收器。 // i = s2Val Effective Go 中关于 Pointers vs. Values 写的很棒。\n零值Mutexes是有效的 零值的 sync.Mutex 和 sync.RWMutex 是有效的，所以基本是不需要一个指向 Mutex 的指针的。\nmu := new(sync.Mutex) mu.Lock() var mu sync.Mutex mu.Lock() 如果你希望通过指针操作结构体，mutex 可以作为其非指针结构体字段，或者最好直接嵌入结构体中。\ntype smap struct { sync.Mutex data map[string]string } func newSMap() *smap { return \u0026amp;smap{ data: make(map[string]string), } } func (m *smap) Get(k string) string { m.Lock() defer m.Unlock() return m.data[k] } type SMap struct { mu sync.Mutex data map[string]string } func NewSMap() *SMap { return \u0026amp;SMap{ data: make(map[string]string), } } func (m *SMap) Get(k string) string { m.mu.Lock() defer m.mu.Unlock() return m.data[k] } Slices和Maps的边界拷贝操作 切片和 map 包含一个指针来指向底层数据，所以当需要复制他们时需要特别注意。\n接收Slices和Maps 请记住，如果存储了对 slice 或 map 的引用，那么用户是可以对其进行修改。\nfunc (d *Driver) SetTrips(trips []Trip) { d.trips = trips } trips := ... d1.SetTrips(trips) // 是想修改 d1.trips 吗？ trips[0] = ... func (d *Driver) SetTrips(trips []Trip) { d.trips = make([]Trip, len(trips)) copy(d.trips, trips) } trips := ... d1.SetTrips(trips) // 修改 trips[0] 并且不影响 d1.trips 。 trips[0] = ... 返回 Slices 和 Maps 同理，谨慎提防用户修改暴露内部状态的 slices 和 maps 。\ntype Stats struct { sync.Mutex counters map[string]int } // Snapshot 返回当前状态 func (s *Stats) Snapshot() map[string]int { s.Lock() defer s.Unlock() return s.counters } // snapshot 不再受锁保护了！ snapshot := stats.Snapshot() type Stats struct { sync.Mutex counters map[string]int } func (s *Stats) Snapshot() map[string]int { s.Lock() defer s.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result } // snapshot 是一分拷贝的内容了 snapshot := stats.Snapshot() 使用 defer 来做清理工作 使用 defer 来做资源的清理工作，例如文件的关闭和锁的释放。\np.Lock() if p.count \u0026lt; 10 { p.Unlock() return p.count } p.count++ newCount := p.count p.Unlock() return newCount // 当有多处 return 时容易忘记释放锁 p.Lock() defer p.Unlock() if p.count \u0026lt; 10 { return p.count } p.count++ return p.count // 可读性更高 defer 只有非常小的性能开销，只有当你能证明你的函数执行时间在纳秒级别时才可以不使用它。使用 defer 对代码可读性的提高是非常值得的，因为使用 defer 的成本真的非常小。特别是在一些主要是做内存操作的长函数中，函数中的其他计算操作远比 defer 重要。\nChannel 的大小设为 1 还是 None 通道的大小通常应该设为 1 或者设为无缓冲类型。默认情况下，通道是无缓冲类型的，大小为 0 。将通道大小设为其他任何数值都应该经过深思熟虑。认真考虑如何确定其大小，是什么阻止了工作中的通道被填满并阻塞了写入操作，以及何种情况会发生这样的现象。\n// 足以满足任何人！ c := make(chan int, 64) // 大小 为 1 c := make(chan int, 1) // or // 无缓冲 channel, 大小为 0 c := make(chan int) 枚举类型值从 1 开始 在 Go 中使用枚举的标准方法是声明一个自定义类型并通过 iota 关键字来声明一个 const 组。但是由于 Go 中变量的默认值都为该类型的零值，所以枚举变量的值应该从非零值开始。\ntype Operation int const ( Add Operation = iota Subtract Multiply ) // Add=0, Subtract=1, Multiply=2 type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) // Add=1, Subtract=2, Multiply=3 在某些情况下，从零值开始也是可以的。例如，当零值是我们期望的默认行为时。\ntype LogOutput int const ( LogToStdout LogOutput = iota LogToFile LogToRemote ) // LogToStdout=0, LogToFile=1, LogToRemote=2 错误类型 有很多种方法来声明 errors:\n errors.New 声明简单的静态字符串错误信息 fmt.Errorf 声明格式化的字符串错误信息 为自定义类型实现 Error() 方法 通过 \u0026quot;pkg/errors\u0026quot;.Wrap 包装错误类型  返回错误时，请考虑以下因素来作出最佳选择：\n 这是一个不需要其他额外信息的简单错误吗？如果是，使用error.New。 客户需要检测并处理此错误吗？如果是，那应该自定义类型，并实现 Error() 方法。 是否是在传递一个下游函数返回的错误？如果是，请查看error 封装部分。 其他，使用 fmt.Errorf 。  如果客户需要检测错误，并且是通过 errors.New 创建的一个简单的错误，请使用var 声明这个错误类型。\n// package foo  func Open() error { return errors.New(\u0026#34;could not open\u0026#34;) } // package bar  func use() { if err := foo.Open(); err != nil { if err.Error() == \u0026#34;could not open\u0026#34; { // handle  } else { panic(\u0026#34;unknown error\u0026#34;) } } } // package foo  var ErrCouldNotOpen = errors.New(\u0026#34;could not open\u0026#34;) func Open() error { return ErrCouldNotOpen } // package bar  if err := foo.Open(); err != nil { if err == foo.ErrCouldNotOpen { // handle  } else { panic(\u0026#34;unknown error\u0026#34;) } } 如果你有一个错误需要客户端来检测，并且你想向其添加更多信息（例如，它不是一个简单的静态字符串），那么应该声明一个自定义类型。\nfunc open(file string) error { return fmt.Errorf(\u0026#34;file %q not found\u0026#34;, file) } func use() { if err := open(); err != nil { if strings.Contains(err.Error(), \u0026#34;not found\u0026#34;) { // handle  } else { panic(\u0026#34;unknown error\u0026#34;) } } } type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\u0026#34;file %q not found\u0026#34;, e.file) } func open(file string) error { return errNotFound{file: file} } func use() { if err := open(); err != nil { if _, ok := err.(errNotFound); ok { // handle  } else { panic(\u0026#34;unknown error\u0026#34;) } } } 直接将自定义的错误类型设为导出需要特别小心，因为这意味着他们已经成为包的公开 API 的一部分了。更好的方式是暴露一个匹配函数来检测错误。\n// package foo  type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\u0026#34;file %q not found\u0026#34;, e.file) } func IsNotFoundError(err error) bool { _, ok := err.(errNotFound) return ok } func Open(file string) error { return errNotFound{file: file} } // package bar  if err := foo.Open(\u0026#34;foo\u0026#34;); err != nil { if foo.IsNotFoundError(err) { // handle  } else { panic(\u0026#34;unknown error\u0026#34;) } } Error 封装 下面提供三种主要的方法来传递函数调用失败返回的错误：\n 如果想要维护原始错误类型并且不需要添加额外的上下文信息，就直接返回原始错误。 使用 \u0026quot;pkg/errors\u0026quot;.Wrap 来增加上下文信息，这样返回的错误信息中就会包含更多的上下文信息，并且通过 \u0026quot;pkg/errors\u0026quot;.Cause 可以提取出原始错误信息。 如果调用方不需要检测或处理特定的错误情况，就直接使用 fmt.Errorf 。  情况允许的话建议增加更多的上下文信息来代替诸如 \u0026quot;connection refused\u0026quot; 之类模糊的错误信息。返回 \u0026quot;failed to call service foo: connection refused\u0026quot; 用户可以知道更多有用的错误信息。\n在将上下文信息添加到返回的错误时，请避免使用 \u0026ldquo;failed to\u0026rdquo; 之类的短语以保持信息简洁，这些短语描述的状态是显而易见的，并且会随着错误在堆栈中的传递而逐渐堆积：\ns, err := store.New() if err != nil { return fmt.Errorf( \u0026#34;failed to create new store: %s\u0026#34;, err) } s, err := store.New() if err != nil { return fmt.Errorf( \u0026#34;new store: %s\u0026#34;, err) } failed to x: failed to y: failed to create new store: the error x: y: new store: the error 但是，如果这个错误信息是会被发送到另一个系统时，必须清楚的表明这是一个错误（例如，日志中 err 标签或者 Failed 前缀）。\n另见 Don\u0026rsquo;t just check errors, handle them gracefully。\n处理类型断言失败 类型断言的单返回值形式在遇到类型错误时会直接 panic 。因此，请始终使用 \u0026ldquo;comma ok\u0026rdquo; 惯用方法。\nt := i.(string) t, ok := i.(string) if !ok { // handle the error gracefully } 不要 Panic 生产级的代码必须避免 panics 。panics 是级联故障的主要源头。如果错误发生，函数应该返回错误并且允许调用者决定如果处理它。\nfunc foo(bar string) { if len(bar) == 0 { panic(\u0026#34;bar must not be empty\u0026#34;) } // ... } func main() { if len(os.Args) != 2 { fmt.Println(\u0026#34;USAGE: foo \u0026lt;bar\u0026gt;\u0026#34;) os.Exit(1) } foo(os.Args[1]) } func foo(bar string) error { if len(bar) == 0 return errors.New(\u0026#34;bar must not be empty\u0026#34;) } // ...  return nil } func main() { if len(os.Args) != 2 { fmt.Println(\u0026#34;USAGE: foo \u0026lt;bar\u0026gt;\u0026#34;) os.Exit(1) } if err := foo(os.Args[1]); err != nil { panic(err) } } Panic/recover 并不是错误处理策略。程序只有在遇到无法处理的情况下才可以 panic ，例如，nil 引用。程序初始化时是一个例外情况：程序启动时遇到需要终止执行的错误可能会 painc 。\nvar _statusTemplate = template.Must(template.New(\u0026#34;name\u0026#34;).Parse(\u0026#34;_statusHTML\u0026#34;)) 即使是在测试中，也应优先选择 t.Fatal 或 t.FailNow 而非 panic，以确保测试标记为失败。\n// func TestFoo(t *testing.T)  f, err := ioutil.TempFile(\u0026#34;\u0026#34;, \u0026#34;test\u0026#34;) if err != nil { panic(\u0026#34;failed to set up test\u0026#34;) } // func TestFoo(t *testing.T)  f, err := ioutil.TempFile(\u0026#34;\u0026#34;, \u0026#34;test\u0026#34;) if err != nil { t.Fatal(\u0026#34;failed to set up test\u0026#34;) } 使用 go.uber.org/atomic Go 的 sync/atomic 包仅仅提供针对原始类型（int32, int64, \u0026hellip;）的原子操作。因此，很容易忘记使用原子操作来读写变量。\ngo.uber.org/atomic 通过隐藏基础类型，使这些操作类型安全。并且，它还提供一个方便的 atomic.Bool 类型。\ntype foo struct { running int32 // atomic } func (f* foo) start() { if atomic.SwapInt32(\u0026amp;f.running, 1) == 1 { // already running…  return } // start the Foo } func (f *foo) isRunning() bool { return f.running == 1 // race! } type foo struct { running atomic.Bool } func (f *foo) start() { if f.running.Swap(true) { // already running…  return } // start the Foo } func (f *foo) isRunning() bool { return f.running.Load() } 性能 性能方面的特定准则，仅适用于热路径。\nstrconv 性能优于 fmt 将原语转换为字符串或从字符串转换时，strconv 速度比 fmt 更快。\nfor i := 0; i \u0026lt; b.N; i++ { s := fmt.Sprint(rand.Int()) } for i := 0; i \u0026lt; b.N; i++ { s := strconv.Itoa(rand.Int()) } BenchmarkFmtSprint-4 143 ns/op 2 allocs/op BenchmarkStrconv-4 64.2 ns/op 1 allocs/op 避免 string to byte 的转换 不要反复地从字符串字面量创建 byte 切片。相反，执行一次转换后存储结果供后续使用。\nfor i := 0; i \u0026lt; b.N; i++ { w.Write([]byte(\u0026#34;Hello world\u0026#34;)) } data := []byte(\u0026#34;Hello world\u0026#34;) for i := 0; i \u0026lt; b.N; i++ { w.Write(data) } BenchmarkBad-4 50000000 22.2 ns/op BenchmarkGood-4 500000000 3.25 ns/op 代码风格 声明分组 Go 支持将相似的声明分组：\nimport \u0026#34;a\u0026#34; import \u0026#34;b\u0026#34; import ( \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; ) 分组同样适用于常量、变量和类型的声明：\nconst a = 1 const b = 2 var a = 1 var b = 2 type Area float64 type Volume float64 const ( a = 1 b = 2 ) var ( a = 1 b = 2 ) type ( Area float64 Volume float64 ) 仅将相似的声明放在同一组。不相关的声明不要放在同一个组内。\ntype Operation int const ( Add Operation = iota + 1 Subtract Multiply ENV_VAR = \u0026#34;MY_ENV\u0026#34; ) type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) const ENV_VAR = \u0026#34;MY_ENV\u0026#34; 声明分组可以在任意位置使用。例如，可以在函数内部使用。\nfunc f() string { var red = color.New(0xff0000) var green = color.New(0x00ff00) var blue = color.New(0x0000ff) ... } func f() string { var ( red = color.New(0xff0000) green = color.New(0x00ff00) blue = color.New(0x0000ff) ) ... } Import 组内顺序 import 有两类导入组：\n 标准库 其他  goimports 默认的分组如下：\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;go.uber.org/atomic\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;go.uber.org/atomic\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) 包名 当为包命名时，请注意如下事项：\n 字符全部小写，没有大写或者下划线 在大多数情况下引入包不需要去重命名 简单明了，命名需要能够在被导入的地方准确识别 不要使用复数。例如，net/url, 而不是 net/urls 不要使用“common”，“util”，“shared”或“lib”之类的。这些都是不好的，表达信息不明的名称  另见 Package Names 和 Style guideline for Go packages\n函数命名 我们遵循 Go 社区关于使用的 MixedCaps for function names。有一种情况例外，对相关的测试用例进行分组时，函数名可能包含下划线，如: TestMyFunction_WhatIsBeingTested。\n包导入别名 如果包的名称与导入路径的最后一个元素不匹配，那必须使用导入别名。\nimport ( \u0026#34;net/http\u0026#34; client \u0026#34;example.com/client-go\u0026#34; trace \u0026#34;example.com/trace/v2\u0026#34; ) 在其他情况下，除非导入的包名之间有直接冲突，否则应避免使用导入别名。\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; nettrace \u0026#34;golang.net/x/trace\u0026#34; ) import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; nettrace \u0026#34;golang.net/x/trace\u0026#34; ) 函数分组与排布顺序  函数应该粗略的按照调用顺序来排布 同一文件中的函数应该按照接收器的类型来分组排布  所以，公开的函数应排布在文件首，并在 struct、const 和 var 定义之后。\nnewXYZ()/ NewXYZ() 之类的函数应该排布在声明类型之后，具有接收器的其余方法之前。\n因为函数是按接收器类别分组的，所以普通工具函数应排布在文件末尾。\nfunc (s *something) Cost() { return calcCost(s.weights) } type something struct{ ... } func calcCost(n int[]) int {...} func (s *something) Stop() {...} func newSomething() *something { return \u0026amp;something{} } type something struct{ ... } func newSomething() *something { return \u0026amp;something{} } func (s *something) Cost() { return calcCost(s.weights) } func (s *something) Stop() {...} func calcCost(n int[]) int {...} 减少嵌套 代码应该通过尽可能地先处理错误情况/特殊情况，并且及早返回或继续下一循环来减少嵌套。尽量减少嵌套于多个级别的代码数量。\nfor _, v := range data { if v.F1 == 1 { v = process(v) if err := v.Call(); err == nil { v.Send() } else { return err } } else { log.Printf(\u0026#34;Invalid v: %v\u0026#34;, v) } } for _, v := range data { if v.F1 != 1 { log.Printf(\u0026#34;Invalid v: %v\u0026#34;, v) continue } v = process(v) if err := v.Call(); err != nil { return err } v.Send() } 不必要的 else 如果一个变量在 if 的两个分支中都设置了，那应该使用单个 if 。\nvar a int if b { a = 100 } else { a = 10 } a := 10 if b { a = 100 } 全局变量声明 在顶层使用标准 var 关键字声明变量时，不要显式指定类型，除非它与表达式的返回类型不同。\nvar _s string = F() func F() string { return \u0026#34;A\u0026#34; } var _s = F() // F 已经明确声明返回一个字符串类型，我们没有必要显式指定 _s 的类型  func F() string { return \u0026#34;A\u0026#34; } 如果表达式的返回类型与所需的类型不完全匹配，请显示指定类型。\ntype myError struct{} func (myError) Error() string { return \u0026#34;error\u0026#34; } func F() myError { return myError{} } var _e error = F() // F 返回一个 myError 类型的实例，但是我们要 error 类型 非导出的全局变量或者常量以 _ 开头 非导出的全局变量和常量前面加上前缀 _，以明确表示它们是全局符号。\n例外：未导出的错误类型变量，应以 err 开头。\n解释：顶级（全局）变量和常量具有包范围作用域。使用通用名称命名，可能在其他文件中不经意间地使用一个错误值。\n// foo.go  const ( defaultPort = 8080 defaultUser = \u0026#34;user\u0026#34; ) // bar.go  func Bar() { defaultPort := 9090 ... fmt.Println(\u0026#34;Default port\u0026#34;, defaultPort) // We will not see a compile error if the first line of  // Bar() is deleted. } // foo.go  const ( _defaultPort = 8080 _defaultUser = \u0026#34;user\u0026#34; ) 结构体中的嵌入类型 嵌入式类型（例如 mutex ）应该放置在结构体字段列表的顶部，并且必须以空行与常规字段隔开。\ntype Client struct { version int http.Client } type Client struct { http.Client version int } 使用字段名来初始化结构 初始化结构体时，必须指定字段名称。go vet 强制执行。\nk := User{\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;, true} k := User{ FirstName: \u0026#34;John\u0026#34;, LastName: \u0026#34;Doe\u0026#34;, Admin: true, } 例外：在测试文件中，如果结构体只有3个或更少的字段，则可以省略字段名称。\ntests := []struct{ }{ op Operation want string }{ {Add, \u0026#34;add\u0026#34;}, {Subtract, \u0026#34;subtract\u0026#34;}, } 局部变量声明 如果声明局部变量时需要明确设值，应使用短变量声明形式（:=）。\nvar s = \u0026#34;foo\u0026#34; s := \u0026#34;foo\u0026#34; 但是，在某些情况下，使用 var 关键字声明变量，默认的初始化值会更清晰。例如，声明空切片。\nfunc f(list []int) { filtered := []int{} for _, v := range list { if v \u0026gt; 10 { filtered = append(filtered, v) } } } func f(list []int) { var filtered []int for _, v := range list { if v \u0026gt; 10 { filtered = append(filtered, v) } } } nil是一个有效的slice nil 是一个有效的长度为 0 的 slice，这意味着：\n  不应明确返回长度为零的切片，而应该直接返回 nil 。\nif x == \u0026#34;\u0026#34; { return []int{} } if x == \u0026#34;\u0026#34; { return nil }   若要检查切片是否为空，始终使用 len(s) == 0 ，不要与 nil 比较来检查。\nfunc isEmpty(s []string) bool { return s == nil } func isEmpty(s []string) bool { return len(s) == 0 }   零值切片（通过 var 声明的切片）可直接使用，无需调用 make 创建。\nnums := []int{} // or, nums := make([]int)  if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } var nums []int if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) }   缩小变量作用域 如果有可能，尽量缩小变量作用范围，除非这样与减少嵌套的规则冲突。\nerr := ioutil.WriteFile(name, data, 0644) if err != nil { return err } if err := ioutil.WriteFile(name, data, 0644); err != nil { return err } 如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。\nif data, err := ioutil.ReadFile(name); err == nil { err = cfg.Decode(data) if err != nil { return err } fmt.Println(cfg) return nil } else { return err } data, err := ioutil.ReadFile(name) if err != nil { return err } if err := cfg.Decode(data); err != nil { return err } fmt.Println(cfg) return nil 避免裸参数 函数调用中的裸参数可能会降低代码可读性。所以当参数名称的含义不明显时，请为参数添加 C 样式的注释（/* … */）。\n// func printInfo(name string, isLocal, done bool)  printInfo(\u0026#34;foo\u0026#34;, true, true) // func printInfo(name string, isLocal, done bool)  printInfo(\u0026#34;foo\u0026#34;, true /* isLocal */, true /* done */) 上面更好的作法是将 bool 类型替换为自定义类型，从而使代码更易读且类型安全。将来需要拓展时，该参数也可以不止两个状态（true/false）。\ntype Region int const ( UnknownRegion Region = iota Local ) type Status int const ( StatusReady = iota + 1 StatusDone // 也许将来我们会有 StatusInProgress。 ) func printInfo(name string, region Region, status Status) 使用原始字符串字面值，避免使用转义 Go 支持原始字符串字面值，可以多行并包含引号。使用它可以避免使用肉眼阅读较为困难的手工转义的字符串。\nwantError := \u0026#34;unknown name:\\\u0026#34;test\\\u0026#34;\u0026#34; wantError := `unknown error:\u0026#34;test\u0026#34;` 初始化结构体引用 在初始化结构引用时，使用 \u0026amp;T{} 而非 new(T)，以使其与结构体初始化方式保持一致。\nsval := T{Name: \u0026#34;foo\u0026#34;} // 定义方式不一致 sptr := new(T) sptr.Name = \u0026#34;bar\u0026#34; sval := T{Name: \u0026#34;foo\u0026#34;} sptr := \u0026amp;T{Name: \u0026#34;bar\u0026#34;} 格式化字符串放在 Printf 外部 如果为 Printf-style 函数声明格式化字符串，将格式化字符串放在函数外面 ，并将其设置为 const 常量。\n这有助于 go vet 对格式字符串进行静态分析。\nmsg := \u0026#34;unexpected values %v, %v\\n\u0026#34; fmt.Printf(msg, 1, 2) const msg = \u0026#34;unexpected values %v, %v\\n\u0026#34; fmt.Printf(msg, 1, 2) 为 Printf 样式函数命名 声明 Printf-style 函数时，请确保 go vet 可以检查它的格式化字符串。\n这意味着应尽可能使用预定义的 Printf-style 函数名称。go vet 默认会检查它们。更多相关信息，请参见 Printf系列。\n如果不能使用预定义的名称，请以 f 结尾：Wrapf，而非 Wrap。因为 go vet 可以指定检查特定的 Printf 样式名称，但名称必须以 f 结尾。\n$ go vet -printfuncs=wrapf,statusf ... 另见 go vet: Printf family check\n模式 测试表 在核心测试逻辑重复时，将表驱动测试与子测试一起使用，以避免重复代码。\n// func TestSplitHostPort(t *testing.T)  host, port, err := net.SplitHostPort(\u0026#34;192.0.2.0:8000\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;192.0.2.0\u0026#34;, host) assert.Equal(t, \u0026#34;8000\u0026#34;, port) host, port, err = net.SplitHostPort(\u0026#34;192.0.2.0:http\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;192.0.2.0\u0026#34;, host) assert.Equal(t, \u0026#34;http\u0026#34;, port) host, port, err = net.SplitHostPort(\u0026#34;:8000\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;\u0026#34;, host) assert.Equal(t, \u0026#34;8000\u0026#34;, port) host, port, err = net.SplitHostPort(\u0026#34;1:8\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;1\u0026#34;, host) assert.Equal(t, \u0026#34;8\u0026#34;, port) // func TestSplitHostPort(t *testing.T)  tests := []struct{ give string wantHost string wantPort string }{ { give: \u0026#34;192.0.2.0:8000\u0026#34;, wantHost: \u0026#34;192.0.2.0\u0026#34;, wantPort: \u0026#34;8000\u0026#34;, }, { give: \u0026#34;192.0.2.0:http\u0026#34;, wantHost: \u0026#34;192.0.2.0\u0026#34;, wantPort: \u0026#34;http\u0026#34;, }, { give: \u0026#34;:8000\u0026#34;, wantHost: \u0026#34;\u0026#34;, wantPort: \u0026#34;8000\u0026#34;, }, { give: \u0026#34;1:8\u0026#34;, wantHost: \u0026#34;1\u0026#34;, wantPort: \u0026#34;8\u0026#34;, }, } for _, tt := range tests { t.Run(tt.give, func(t *testing.T) { host, port, err := net.SplitHostPort(tt.give) require.NoError(t, err) assert.Equal(t, tt.wantHost, host) assert.Equal(t, tt.wantPort, port) }) } 测试表使得向错误消息注入上下文信息，减少重复的逻辑，添加新的测试用例变得更加容易。\n我们遵循这样的约定：将结构体切片称为 tests。 每个测试用例称为 tt 。此外，我们鼓励使用 give 和 want 前缀说明每个测试用例的输入和输出值。\ntests := []struct{ give string wantHost string wantPort string }{ // ... } for _, tt := range tests { // ... } 功能选项 功能选项是一种模式，声明一个不透明 Option 类型，该类型记录某些内部结构体的信息。您的函数接受这些不定数量的选项参数，并将选项参数上的信息作用于内部结构上。\n此模式可用于扩展构造函数和实现其他公共 API 中的可选参数，特别是这些参数已经有三个或者超过三个的情况下。\n// package db  func Connect( addr string, timeout time.Duration, caching bool, ) (*Connection, error) { // ... } // Timeout and caching must always be provided, // even if the user wants to use the default.  db.Connect(addr, db.DefaultTimeout, db.DefaultCaching) db.Connect(addr, newTimeout, db.DefaultCaching) db.Connect(addr, db.DefaultTimeout, false /* caching */) db.Connect(addr, newTimeout, false /* caching */) type options struct { timeout time.Duration caching bool } // Option overrides behavior of Connect. type Option interface { apply(*options) } type optionFunc func(*options) func (f optionFunc) apply(o *options) { f(o) } func WithTimeout(t time.Duration) Option { return optionFunc(func(o *options) { o.timeout = t }) } func WithCaching(cache bool) Option { return optionFunc(func(o *options) { o.caching = cache }) } // Connect creates a connection. func Connect( addr string, opts ...Option, ) (*Connection, error) { options := options{ timeout: defaultTimeout, caching: defaultCaching, } for _, o := range opts { o.apply(\u0026amp;options) } // ... } // Options must be provided only if needed.  db.Connect(addr) db.Connect(addr, db.WithTimeout(newTimeout)) db.Connect(addr, db.WithCaching(false)) db.Connect( addr, db.WithCaching(false), db.WithTimeout(newTimeout), ) 另见，\n Self-referential functions and the design of options Functional options for friendly APIs  ","permalink":"https://mogutou.xyz/posts/go/uber-go-guide/","summary":"Uber Go 风格指南  译文：https://github.com/Allenxuxu/uber-go-guide 原文：https://github.com/uber-go/guide/blob/master/style.md  简介 风格是指规范代码的共同约定。风格一词其实是有点用词不当的，因为共同约定的范畴远远不止 gofmt 所做的源代码格式化这些。\n本指南旨在通过详尽描述 Uber 在编写 Go 代码中的注意事项（规定）来解释其中复杂之处。制定这些注意事项（规定）是为了提高代码可维护性同时也让工程师们高效的使用 Go 的特性。\n这份指南最初由 Prashant Varanasi 和 Simon Newton 编写，目的是让一些同事快速上手 Go 。多年来，已经根据其他人的反馈不断修改。\n这份文档记录了我们在 Uber 遵守的 Go 惯用准则。其中很多准则是 Go 的通用准则，其他方面依赖于外部资源：\n Effective Go The Go common mistakes guide  所有的代码都应该通过 golint 和 go vet 检查。我们建议您设置编辑器：\n 保存时自动运行 goimports 自动运行 golint 和 go vet 来检查错误  您可以在这找到关于编辑器设定 Go tools 的相关信息：\nhttps://github.com/golang/go/wiki/IDEsAndTextEditorPlugins\n指南 指向接口（interface）的指针 你基本永远不需要一个指向接口的指针。你应该直接将接口作为值传递，因为接口的底层数据就是指针。\n一个接口包含两个字段：\n 类型指针，指向某些特定类型信息的指针。 数据指针。如果存储数据是一个指针变量，那就直接存储。如果存储数据是一个值变量，那就存储指向该值的指针。  如果你需要接口方法来修改这些底层数据，那你必须使用指针。","title":"Uber Go 风格指南"},{"content":"https://github.com/Allenxuxu/gev\n本文主要测试 gev 网络库和其他三方 Go 网络库以及标准库的吞吐量对比。\n测试对象  gev ：一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库 eviop ：evio 的优化版本 evio ：Fast event-loop networking for Go gnet ：eviop 的网络模型替换版本 net 标准库  测试方法 采用陈硕测试 muduo 使用的 ping pong 协议来测试吞吐量。\n 简单地说，ping pong 协议是客户端和服务器都实现 echo 协议。当 TCP 连接建立时，客户端向服务器发送一些数据，服务器会 echo 回这些数据，然后客户端再 echo 回服务器。这些数据就会像乒乓球一样在客户端和服务器之间来回传送，直到有一方断开连接为止。这是用来测试吞吐量的常用办法。\n 测试的客户端代码： https://github.com/Allenxuxu/gev/blob/master/benchmarks/client/main.go\n测试脚本：https://github.com/Allenxuxu/gev/blob/master/benchmarks/bench-pingpong.sh\n主要做两项测试：\n 单线程单个 work 协程测试，测试并发连接数为 10/100/1000/10000 时的吞吐量 4线程4个 work 协程测试，测试并发连接数为 10/100/1000/10000 时的吞吐量  所有测试中，ping pong 消息的大小均为 4096 bytes，客户端始终是4线程运行。\n测试结果 总结与思考 无论是单线程，还是多线程模式下，gev 都比其他网络库吞吐量略高出一些。\nevio 因为 epoll 使用一些 bug 和可优化之处，所以在 linux 环境中的吞吐量远不如优化版本 eviop 。\neviop 是我对 evio bug 修复和优化的版本，所以其性能也是比 evio 提升不少。我曾尝试在 eviop 中替换 evio 的网络模型（evio 利用 accpet 的惊群现象工作），但是因为其代码耦合度过高，修改成本过大，最终决定一边完善 eviop（维持网络模型不变）一边自己借鉴muduo 的网络模型重新撸一个新的 \u0026ndash; gev 。\ngnet 是研究了 eviop 的代码，继续在其之上替换网络模型的版本。但是网络模型的优势在单线程模式中并没有体现出来，吞吐量反而比 eviop 小一些。在多线程模式下，网络模型的优势得以体现。\ngev 与其他使用 epoll 构建的基于事件驱动的网络库在逐步的优化中，相信性能都差不多。因为作者目的不同，网络库不同的设计，优势点都会不同。我研究 evio，最终自己撸了 gev ，也是因为想要一个在内存占用低前提下，速度足够快，能负载更多连接的网络库。\n如果对 gev 网络库感兴趣，欢迎提意见和 PR 。➡️ https://github.com/Allenxuxu/gev\n","permalink":"https://mogutou.xyz/posts/open-source/gev-benchmark/","summary":"https://github.com/Allenxuxu/gev\n本文主要测试 gev 网络库和其他三方 Go 网络库以及标准库的吞吐量对比。\n测试对象  gev ：一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库 eviop ：evio 的优化版本 evio ：Fast event-loop networking for Go gnet ：eviop 的网络模型替换版本 net 标准库  测试方法 采用陈硕测试 muduo 使用的 ping pong 协议来测试吞吐量。\n 简单地说，ping pong 协议是客户端和服务器都实现 echo 协议。当 TCP 连接建立时，客户端向服务器发送一些数据，服务器会 echo 回这些数据，然后客户端再 echo 回服务器。这些数据就会像乒乓球一样在客户端和服务器之间来回传送，直到有一方断开连接为止。这是用来测试吞吐量的常用办法。\n 测试的客户端代码： https://github.com/Allenxuxu/gev/blob/master/benchmarks/client/main.go\n测试脚本：https://github.com/Allenxuxu/gev/blob/master/benchmarks/bench-pingpong.sh\n主要做两项测试：\n 单线程单个 work 协程测试，测试并发连接数为 10/100/1000/10000 时的吞吐量 4线程4个 work 协程测试，测试并发连接数为 10/100/1000/10000 时的吞吐量  所有测试中，ping pong 消息的大小均为 4096 bytes，客户端始终是4线程运行。","title":"Go 网络库并发吞吐量测试"},{"content":"gev 轻量、快速的 Golang 网络库 gev 是一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库，支持自定义协议，轻松快速搭建高性能服务器。\n为什么有 gev Golang 的 goroutine 虽然非常轻量，但是每启动一个 goroutine 仍需要 4k 左右的内存。读了鸟窝大佬的文章【百万 Go TCP 连接的思考: epoll方式减少资源占用】后，便去研究了了下 evio。\nevio 虽然非常快，但是仍然存在一些问题，便尝试去优化它，于是有了 eviop 项目。关于 evio 的问题可以看我的另一篇博文 【Golang 网络库evio一些问题/bug和思考】。在优化 evio 完成 eviop 的过程中，因为其网络模型的缘故，愈加感觉修改它非常麻烦，成本比重新搞一个还高。\n最终决定自己重搞一个，更加轻量，不需要的全去掉。加上大学时学习过 muduo ，便参考 muduo 的使用的 Reactor 模型实现 gev 。\n在 linux 环境下，gev 底层使用 epoll ，这是 gev 会专注优化的地方。在 mac 下底层使用 kqueue，可能不会过多关注这部分的优化，毕竟很少有用 mac 做服务器的（Windows 环境\u0026quot;暂\u0026quot;不支持）。\n特点  基于 epoll 和 kqueue 实现的高性能事件循环 支持多核多线程 动态扩容 Ring Buffer 实现的读写缓冲区 异步读写 SO_REUSEPORT 端口重用支持 支持 WebSocket 支持定时任务，延时任务 支持自定义协议，处理 TCP 粘包  网络模型 gev 只使用极少的 goroutine, 一个 goroutine 负责监听客户端连接，其他 goroutine （work 协程）负责处理已连接客户端的读写事件，work 协程数量可以配置，默认与运行主机 CPU 数量相同。\n性能测试  测试环境 Ubuntu18.04\n  gnet eviop evio net (标准库)  吞吐量测试 evio 压测方式: 限制 GOMAXPROCS=1，1 个 work 协程\n限制 GOMAXPROCS=1，4 个 work 协程\n限制 GOMAXPROCS=4，4 个 work 协程\n","permalink":"https://mogutou.xyz/posts/open-source/gev/","summary":"gev 轻量、快速的 Golang 网络库 gev 是一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库，支持自定义协议，轻松快速搭建高性能服务器。\n为什么有 gev Golang 的 goroutine 虽然非常轻量，但是每启动一个 goroutine 仍需要 4k 左右的内存。读了鸟窝大佬的文章【百万 Go TCP 连接的思考: epoll方式减少资源占用】后，便去研究了了下 evio。\nevio 虽然非常快，但是仍然存在一些问题，便尝试去优化它，于是有了 eviop 项目。关于 evio 的问题可以看我的另一篇博文 【Golang 网络库evio一些问题/bug和思考】。在优化 evio 完成 eviop 的过程中，因为其网络模型的缘故，愈加感觉修改它非常麻烦，成本比重新搞一个还高。\n最终决定自己重搞一个，更加轻量，不需要的全去掉。加上大学时学习过 muduo ，便参考 muduo 的使用的 Reactor 模型实现 gev 。\n在 linux 环境下，gev 底层使用 epoll ，这是 gev 会专注优化的地方。在 mac 下底层使用 kqueue，可能不会过多关注这部分的优化，毕竟很少有用 mac 做服务器的（Windows 环境\u0026quot;暂\u0026quot;不支持）。\n特点  基于 epoll 和 kqueue 实现的高性能事件循环 支持多核多线程 动态扩容 Ring Buffer 实现的读写缓冲区 异步读写 SO_REUSEPORT 端口重用支持 支持 WebSocket 支持定时任务，延时任务 支持自定义协议，处理 TCP 粘包  网络模型 gev 只使用极少的 goroutine, 一个 goroutine 负责监听客户端连接，其他 goroutine （work 协程）负责处理已连接客户端的读写事件，work 协程数量可以配置，默认与运行主机 CPU 数量相同。","title":"开源 gev: Go 实现基于 Reactor 模式的非阻塞 TCP 网络库"},{"content":"GO HTTP Server 使用标准库构建 HTTP 服务 Go 语言标准库自带一个完善的 net/http 包，可以很方便编写一个可以直接运行的 Web 服务。\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func hello(w http.ResponseWriter, r *http.Request) { log.Println(r.Method, r.Host, r.RequestURI) w.Write([]byte(\u0026#34;hello\u0026#34;)) } func main() { http.HandleFunc(\u0026#34;/hello\u0026#34;, hello) //设置访问的路由 \t// http.Handle(\u0026#34;/hello\u0026#34;, http.HandlerFunc(hello)) // 和上面写法等价  err := http.ListenAndServe(\u0026#34;:9090\u0026#34;, nil) //设置监听的端口并启动 HTTP 服务  if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } $ curl -v 127.0.0.1:9090/hello * Trying 127.0.0.1... * TCP_NODELAY set * Connected to 127.0.0.1 (127.0.0.1) port 9090 (#0) \u0026gt; GET /hello HTTP/1.1 \u0026gt; Host: 127.0.0.1:9090 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Tue, 10 Sep 2019 10:52:07 GMT \u0026lt; Content-Length: 5 \u0026lt; Content-Type: text/plain; charset=utf-8 \u0026lt; * Connection #0 to host 127.0.0.1 left intact hello 上面短短几行代码，已经启动了一个 HTTP 服务。 在浏览输入 127.0.0.1:9090/hello 或者执行 curl -v 127.0.0.1:9090/hello 可以验证。\nfunc HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } http.HandleFunc(\u0026quot;/hello\u0026quot;, hello) 会在 net/http 的默认路由中注册 hello 处理函数，这也是我们为什么在 http.ListenAndServe(\u0026quot;:9090\u0026quot;, nil) 中传入 nil，传入 nil 意味着使用默认的路由器。\n上面的 main 函数和如下其实是一样的：\nfunc main() { mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/hello\u0026#34;, hello) //设置访问的路由 \t// mux.Handle(\u0026#34;/hello\u0026#34;, http.HandlerFunc(hello)) // 和上面的写法等价  err := http.ListenAndServe(\u0026#34;:9090\u0026#34;, mux) //设置监听的端口并启动 HTTP 服务  if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } Go 自带的 http.ServerMux 实现比较简单，只支持路径匹配，不支持按照 Method 等信息匹配，没法直接实现 RESTful 接口，所有有很多其他优秀的路由器和 HTTP 库实现，后面的文章中会介绍。\nGo net/http 库浅析 Go 的标准库 net/http 内部处理了 TCP 连接和 HTTP 报文解析的等繁琐的细节，仅仅对外提供 HTTP 处理的相关接口。\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } 开发者只需实现对应的 Handler 接口并注册， 在处理函数中和 http.request 、 http.ResponseWriter 交互读取请求信息，设置返回信息即可，就像文章开头的例子那样。\n Request： 用户请求的信息，用来解析用户的请求信息，包括 post、get、cookie、url 等信息 ResponseWriter： 服务器需要返回给客户端的信息  mux.HandleFunc(\u0026quot;/hello\u0026quot;, hello) 第一个参数是 URL 路径，第二个参数就是设置的 Handler。这里 net/http 做了一个适配器，让我们可以不用每次都定义一个结构体去实现 ServeHTTP(ResponseWriter, *Request) 。 第二个参数传入一个函数，并其函数签名为 func(ResponseWriter, *Request)，内部通过适配器将其封装，主要代码如下：\n// HandleFunc registers the handler function for the given pattern. func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } mux.Handle(pattern, HandlerFunc(handler)) } // The HandlerFunc type is an adapter to allow the use of // ordinary functions as HTTP handlers. If f is a function // with the appropriate signature, HandlerFunc(f) is a // Handler that calls f. type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } type Handler interface { ServeHTTP(ResponseWriter, *Request) } net/http 库中会去调用 ServeHTTP 方法，这也是接口规定我们实现的方法。HandlerFunc 适配器封装了它，在其内部调用我们传入的函数 f(w, r) 。\n我们一步步查看最后启动 Web 服务的 ListenAndServe 实现：\nfunc ListenAndServe(addr string, handler Handler) error { server := \u0026amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == \u0026#34;\u0026#34; { addr = \u0026#34;:http\u0026#34; } ln, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) //创建一个 TCP listener \tif err != nil { return err } return srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)}) } 上面两层封装，主要是保存了 HTTP Server 的运行参数，并且创建了 TCP Listener ，最后 Serve 方法会进入真正的循环。\nfunc (srv *Server) Serve(l net.Listener) error { if fn := testHookServerServe; fn != nil { fn(srv, l) // call hook with unwrapped listener \t} l = \u0026amp;onceCloseListener{Listener: l} defer l.Close() if err := srv.setupHTTP2_Serve(); err != nil { return err } if !srv.trackListener(\u0026amp;l, true) { return ErrServerClosed } defer srv.trackListener(\u0026amp;l, false) var tempDelay time.Duration // how long to sleep on accept failure \tbaseCtx := context.Background() // base is always background, per Issue 16220 \tctx := context.WithValue(baseCtx, ServerContextKey, srv) // 死循环，不断接受客户端连接处理 \tfor { rw, e := l.Accept() // 接受客户端连接 \tif e != nil { select { case \u0026lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok \u0026amp;\u0026amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay \u0026gt; max { tempDelay = max } srv.logf(\u0026#34;http: Accept error: %v; retrying in %v\u0026#34;, e, tempDelay) time.Sleep(tempDelay) continue } return e } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return \tgo c.serve(ctx) // 启动一个协程来执行处理逻辑 \t} } 这个函数内部有一个无限循环会不断接受新的客户断连接，并且启动一个协程来处理它。\nfunc (c *conn) serve() { ... for { w, err := c.readRequest() if c.lr.N != c.server.initialLimitedReaderSize() { // If we read any bytes off the wire, we\u0026#39;re active.  c.setState(c.rwc, StateActive) } ... // HTTP cannot have multiple simultaneous active requests.[*]  // Until the server replies to this request, it can\u0026#39;t read another,  // so we might as well run the handler in this goroutine.  // [*] Not strictly true: HTTP pipelining. We could let them all process  // in parallel even if their responses need to be serialized.  serverHandler{c.server}.ServeHTTP(w, w.req) w.finishRequest() if w.closeAfterReply { if w.requestBodyLimitHit { c.closeWriteAndWait() } break } c.setState(c.rwc, StateIdle) } } 对客户端的请求处理，会执行 serverHandler{c.server}.ServeHTTP(w, w.req) ，这里面会调用我们注册的路由器 ServeHTTP 方法，继而根据路由判断，调用我们注册的 Handler 。\nfunc (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; req.Method == \u0026#34;OPTIONS\u0026#34; { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req) } 接下来我们看看默认的路由器 ServeMux 的实现 ：\ntype ServeMux struct { mu sync.RWMutex m map[string]muxEntry es []muxEntry // slice of entries sorted from longest to shortest. \thosts bool // whether any patterns contain hostnames } type muxEntry struct { h Handler pattern string } 内部通过一个 map 来实现路由映射，这也是它只支持路径匹配，不支持按照 Method 等信息匹配的原因。我们知道在对客户端的请求处理中会首先调用其 ServeHTTP 方法，我们先来看看其实现：\nfunc (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == \u0026#34;*\u0026#34; { if r.ProtoAtLeast(1, 1) { w.Header().Set(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) } w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) h.ServeHTTP(w, r) } 这个函数非常短小，主要是首先执行 h, _ := mux.Handler(r) 来匹配路由，然后再调用其 ServeHTTP，也就是我们注册的 Handler。\nfunc (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // CONNECT requests are not canonicalized. \tif r.Method == \u0026#34;CONNECT\u0026#34; { // If r.URL.Path is /tree and its handler is not registered, \t// the /tree -\u0026gt; /tree/ redirect applies to CONNECT requests \t// but the path canonicalization does not. \tif u, ok := mux.redirectToPathSlash(r.URL.Host, r.URL.Path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } return mux.handler(r.Host, r.URL.Path) } // All other requests have any port stripped and path cleaned \t// before passing to mux.handler. \thost := stripHostPort(r.Host) path := cleanPath(r.URL.Path) // If the given path is /tree and its handler is not registered, \t// redirect for /tree/. \tif u, ok := mux.redirectToPathSlash(host, path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } if path != r.URL.Path { _, pattern = mux.handler(host, path) url := *r.URL url.Path = path return RedirectHandler(url.String(), StatusMovedPermanently), pattern } return mux.handler(host, r.URL.Path) } ServeMux 的 Handler 方法内部主要就是根据用户请求的 URL 来找到其对应的 Handler ，也就是 mux.HandleFunc(\u0026quot;/hello\u0026quot;, hello) 中注册的路由和 Handler 。\n我们梳理一下 Go Web 的主要执行流程：\n 启动 TCP Server 监听指定端口，等待客户端连接 接受客户端连接，并启动一个协程单独处理客户端逻辑 在新启动的协程中，默认路由器根据 URL 匹配对应的用户处理函数并执行  接下来，我们看下业务开发时接触最多的 Request 和 ResponseWriter 。\ntype Request struct { Method string URL *url.URL Proto string // \u0026#34;HTTP/1.0\u0026#34; \tProtoMajor int // 1 \tProtoMinor int // 0 \tHeader Header Body io.ReadCloser GetBody func() (io.ReadCloser, error) ContentLength int64 TransferEncoding []string Close bool Host string Form url.Values PostForm url.Values MultipartForm *multipart.Form Trailer Header RemoteAddr string RequestURI string TLS *tls.ConnectionState Cancel \u0026lt;-chan struct{} Response *Response ctx context.Context } 从 Request 结构体中，可以看出，我们在 Handler 需要的 HTTP 请求相关信息都在这个结构体中，在实际开发中通过 Request 的公开方法或者直接读取公开变量获取。\ntype ResponseWriter interface { Header() Header Write([]byte) (int, error) WriteHeader(statusCode int) } ResponseWriter 的实现更加简洁，主要就是通过 Header 来设置返回头，Write 来设置返回 body ，WriteHeader 来设置返回状态码。\n关于 Request 和 ResponseWriter 更多的使用方法这里就不细说，可以查阅其他相关资料。\n至此，我们已经大概清楚 net/http 的大概工作流程了。得益于 Go 协程的轻量，net/http 库采用 per request per goroutine ，这使得 Go 的 HTTP 请求处理非常快速。同时 net/http 内部封装大量细节，让开发者通过简单的 API 调用就可以搭建 HTTP 服务。\n","permalink":"https://mogutou.xyz/posts/go/go-http/","summary":"GO HTTP Server 使用标准库构建 HTTP 服务 Go 语言标准库自带一个完善的 net/http 包，可以很方便编写一个可以直接运行的 Web 服务。\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func hello(w http.ResponseWriter, r *http.Request) { log.Println(r.Method, r.Host, r.RequestURI) w.Write([]byte(\u0026#34;hello\u0026#34;)) } func main() { http.HandleFunc(\u0026#34;/hello\u0026#34;, hello) //设置访问的路由 \t// http.Handle(\u0026#34;/hello\u0026#34;, http.HandlerFunc(hello)) // 和上面写法等价  err := http.ListenAndServe(\u0026#34;:9090\u0026#34;, nil) //设置监听的端口并启动 HTTP 服务  if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } $ curl -v 127.0.0.1:9090/hello * Trying 127.0.0.1... * TCP_NODELAY set * Connected to 127.","title":"Go net/http 浅析"},{"content":"Go 的 channel 使用非常方便，但是总听说 channel 会拷贝传递的数据，生怕频繁拷贝影响效率。\n究竟是怎么个拷贝法呢，下面会有两个 demo 验证下。\n先说结论： Go channel 的发送接收数据的拷贝和 Go 的函数传参道理是一样的，都是默认的值拷贝。 如果你传递一个值，那么 Go 会复制一份新的；如果传递一个指针，则会拷贝这个指针，不会去拷贝这个指针所指的变量（这一点 C++ 选手可能会理解比较深）。\n所以，如果你需要通过 channel 传递一个很大的 struct ，那么应该传递 指针。但是，要非常注意通过 channel 发送后，不要修改这个指，这会导致线程间潜在的竞争。\n 下面是两个验证的小 demo：\n 通过 channel 传递指针  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func recv(ch \u0026lt;-chan *int) { time.Sleep(1 * time.Second) out := \u0026lt;-ch fmt.Println(\u0026#34;recv : \u0026#34;, out, *out) } func main() { i := 1 ch := make(chan *int, 2) fmt.Println(\u0026#34;i : \u0026#34;, \u0026amp;i, i) go recv(ch) ch \u0026lt;- \u0026amp;i i = 2 time.Sleep(2 * time.Second) fmt.Println(\u0026#34;i : \u0026#34;, \u0026amp;i, i) } 输出：\ni : 0xc000084000 1 recv : 0xc000084000 2 i : 0xc000084000 2 上面的代码通过 channel 发送了 *int 的数据，在接收的协程中先 sleep 1 秒钟让别的协程去更改传递的值。\n从打印结果可以看出，通过 channel 接收的数据，只是拷贝了对象的地址而已。\n 通过 channel 传递值  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func recv(ch \u0026lt;-chan int) { time.Sleep(1 * time.Second) out := \u0026lt;-ch fmt.Println(\u0026#34;recv : \u0026#34;, \u0026amp;out, out) } func main() { i := 1 ch := make(chan int, 2) fmt.Println(\u0026#34;i : \u0026#34;, \u0026amp;i, i) go recv(ch) ch \u0026lt;- i i = 2 time.Sleep(2 * time.Second) fmt.Println(\u0026#34;i : \u0026#34;, \u0026amp;i, i) } 输出：\ni : 0xc00008e000 1 recv : 0xc00007e008 1 i : 0xc00008e000 2 ","permalink":"https://mogutou.xyz/posts/go/go-channel-copy/","summary":"Go 的 channel 使用非常方便，但是总听说 channel 会拷贝传递的数据，生怕频繁拷贝影响效率。\n究竟是怎么个拷贝法呢，下面会有两个 demo 验证下。\n先说结论： Go channel 的发送接收数据的拷贝和 Go 的函数传参道理是一样的，都是默认的值拷贝。 如果你传递一个值，那么 Go 会复制一份新的；如果传递一个指针，则会拷贝这个指针，不会去拷贝这个指针所指的变量（这一点 C++ 选手可能会理解比较深）。\n所以，如果你需要通过 channel 传递一个很大的 struct ，那么应该传递 指针。但是，要非常注意通过 channel 发送后，不要修改这个指，这会导致线程间潜在的竞争。\n 下面是两个验证的小 demo：\n 通过 channel 传递指针  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func recv(ch \u0026lt;-chan *int) { time.Sleep(1 * time.Second) out := \u0026lt;-ch fmt.Println(\u0026#34;recv : \u0026#34;, out, *out) } func main() { i := 1 ch := make(chan *int, 2) fmt.","title":"Go channel 拷贝问题"},{"content":"go get 拉包一直时国内选手头疼的问题，虽然梯子可以解决问题，但是总是有很慢的时候，而且需要每台电脑都配置，特别是 CI 的服务器等，很烦人。\n七牛云开源了 goproxy ，还免费提供 https://goproxy.cn 作为代理来拉包。\n不过 GOPROXY 只有在 Go module 下才能使用，索性全面拥抱 Go module 一劳永逸。\n修改一下配置文件，即可：\nsudo vi /etc/profile 在最后添加如下内容，开启 Go module 和代理：\nexport GO111MODULE=on export GOPROXY=https://goproxy.cn 让配置文件立即生效\nsource /etc/profile 接下来就可以畅快 Go 了！\nPS： Go 1.16 已经默认开启 go moudle了。\n","permalink":"https://mogutou.xyz/posts/go/go-module/","summary":"go get 拉包一直时国内选手头疼的问题，虽然梯子可以解决问题，但是总是有很慢的时候，而且需要每台电脑都配置，特别是 CI 的服务器等，很烦人。\n七牛云开源了 goproxy ，还免费提供 https://goproxy.cn 作为代理来拉包。\n不过 GOPROXY 只有在 Go module 下才能使用，索性全面拥抱 Go module 一劳永逸。\n修改一下配置文件，即可：\nsudo vi /etc/profile 在最后添加如下内容，开启 Go module 和代理：\nexport GO111MODULE=on export GOPROXY=https://goproxy.cn 让配置文件立即生效\nsource /etc/profile 接下来就可以畅快 Go 了！\nPS： Go 1.16 已经默认开启 go moudle了。","title":"拥抱 Go module"},{"content":" Fast event-loop networking for Go\n 最近翻了 evio 的源码，发现一些问题，主要集中在 linux 平台 epoll 上和读写的处理。\n 用来唤醒 epoll 的 eventfd 写入数据没有读出 listen 的 fd 注册到所有事件循环，epoll 的惊群问题 loopWrite 在内核缓冲区满，无法一次写入时，出现写入数据丢失  eventfd 的使用问题 在 internal/internal_linux.go 中封装了 epoll 的使用 API 。\n// Poll ... type Poll struct { fd int // epoll fd \twfd int // wake fd \tnotes noteQueue } 在 OpenPoll 时，会创建一个 eventfd 并将 fd 赋值给 Poll 的 wfd 成员， 并且注册到 epoll 监听可读事件。\n当需要唤醒当前 epoll 时，提供了 Trigger 方法\n// Trigger ... func (p *Poll) Trigger(note interface{}) error { p.notes.Add(note) _, err := syscall.Write(p.wfd, []byte{0, 0, 0, 0, 0, 0, 0, 1}) return err } 这是往刚刚提到的 eventfd 中写入八字节数据，此时 epol l会被唤醒 epoll_wait 函数返回。 但是，evio 并没有去把 8 个字节的数据读取出来，内核缓冲区会不断积压，并且 evio 使用的是 epoll 的LT模式（默认模式），只要缓冲区中有数据，epoll 就会不断唤醒。这应该算是一个 bug 吧。\nlisten 的 fd 注册到所有事件循环，epoll 的惊群问题 evio 可以指定启动多个事件循环。evio 将 listen fd 注册到每一个事件循环中（epoll）监听可读事件，所以当一个连接到来时，所有的事件循环都会唤醒。\n// create loops locally and bind the listeners. \tfor i := 0; i \u0026lt; numLoops; i++ { l := \u0026amp;loop{ idx: i, poll: internal.OpenPoll(), packet: make([]byte, 0xFFFF), fdconns: make(map[int]*conn), } for _, ln := range listeners { l.poll.AddRead(ln.fd) } s.loops = append(s.loops, l) } // start loops in background \ts.wg.Add(len(s.loops)) for _, l := range s.loops { go loopRun(s, l) } 这并不是一个 bug ，因为最终只有一个线程可以accept调用返回成功，其他线程（协程）的accept函数调用返回EAGAIN错误 ，作者也做出了处理。\nnfd, sa, err := syscall.Accept(fd) if err != nil { if err == syscall.EAGAIN { return nil } return err } 并且作者还利用每个事件循环都会被唤醒，来做客户端连接的负载均衡策略。\nLeastConnections : 当存在其他事件循环的注册的客户端连接数比当前事件循环的连接数少的时候，直接 return nil 。当有两个最下连接数相同的时候，也没关系，因为 accept 会保证只有一个可以成功。\nRoundRobin： 原理也是一样，每个事件循环都会去判断 int(atomic.LoadUintptr(\u0026amp;s.accepted)) % len(s.loops) ，轮到自己了，才继续执行，否则 return nil 。\nif ln.fd == fd { if len(s.loops) \u0026gt; 1 { switch s.balance { case LeastConnections: n := atomic.LoadInt32(\u0026amp;l.count) for _, lp := range s.loops { if lp.idx != l.idx { if atomic.LoadInt32(\u0026amp;lp.count) \u0026lt; n { return nil // do not accept \t} } } case RoundRobin: idx := int(atomic.LoadUintptr(\u0026amp;s.accepted)) % len(s.loops) if idx != l.idx { return nil // do not accept \t} atomic.AddUintptr(\u0026amp;s.accepted, 1) } } 这样的做法没有问题，但是个人觉得 muduo 的做法似乎更好。\nloopWrite 在内核缓冲区满，无法一次写入时，出现写入数据丢失 func loopWrite(s *server, l *loop, c *conn) error { if s.events.PreWrite != nil { s.events.PreWrite() } n, err := syscall.Write(c.fd, c.out) if err != nil { if err == syscall.EAGAIN { return nil } return loopCloseConn(s, l, c, err) } if n == len(c.out) { c.out = nil } else { c.out = c.out[n:] } if len(c.out) == 0 \u0026amp;\u0026amp; c.action == None { l.poll.ModRead(c.fd) } return nil } 当内核缓冲区满时， syscall.Write(c.fd, c.out) 会无法全部写入，可以通过返回值得到已经写入的个数。\nif n == len(c.out) { c.out = nil } else { c.out = c.out[n:] } 作者也做出了处理，判断了 返回值 n 不是 c.out 长度的情况，c.out = c.out[n:] 。\n但是作者并没有去注册 epoll 可写事件啊。\n在当前文件搜索 ModReadWrite ，注册可读可写的事件，共有两处。一次是 loopWake 函数，一次是在 loopRead 函数。会不会作者在 loopRead 方法中了做了处理，规避了没有注册可写事件这种情况呢？\n我们看下 loopRead\nfunc loopRead(s *server, l *loop, c *conn) error { var in []byte n, err := syscall.Read(c.fd, l.packet) if n == 0 || err != nil { if err == syscall.EAGAIN { return nil } return loopCloseConn(s, l, c, err) } in = l.packet[:n] if !c.reuse { in = append([]byte{}, in...) } if s.events.Data != nil { out, action := s.events.Data(c, in) c.action = action if len(out) \u0026gt; 0 { c.out = append([]byte{}, out...) } } if len(c.out) != 0 || c.action != None { l.poll.ModReadWrite(c.fd) } return nil } 果然，作者做了处理！ 当 s.events.Data(c, in) 函数返回，如果 c.out 有数据，就注册可读可写事件。\n所以，执行的流程是：\n 客户端有数据到来，loopRead 函数执行 调用客户注册的回调函数 events.Data 函数，客户将需要的写入给客户端的数据返回，evio 将需要写给客户端数据存到 c.out , 然后监听可读可写事件 eopll 可写事件唤醒，执行 loopWrite 直接 write 数据。 如果写完就重新注册，只注册可读事件；如果没写完，就不重新注册，还是可读可写事件都监听  当缓冲区有空间了时，epoll 又会唤醒继续 loopWrite 。\n似乎没问题，但是仔细想一想，会不会有这种情况呢：\n内核的缓冲区满了，第一次没写完，等待缓冲区可写。此时客户端又来了数据，继续执行 loopRead 。调用用户回调函数，又有要写入的数据。这是来看看处理逻辑\nif s.events.Data != nil { out, action := s.events.Data(c, in) c.action = action if len(out) \u0026gt; 0 { c.out = append([]byte{}, out...) } } c.out = append([]byte{}, out\u0026hellip;) 这里，之前没写完存在 c.out 里的数据直接被清空了啊。这样要写入的数据就丢失了一部分啊。\n 思考 evio 速度非常快，但是翻了源码，发现 evio 并没有刻意去减少 epoll 的唤醒次数，相反 evio 利用 epoll 的多次唤醒去做操作。\n比如，调用客户回调后，并没有直接处理 action 的状态，反而是先把 action 存起来，增加注册 fd 的可写事件，让epoll 再唤醒，在 loopAction 中再来处理 action。先不说这样会不会有问题，这样让 epoll 频繁唤醒似乎不妥。\nevio 的处理 read 和 write 的方式，也导致多次的内存拷贝，换种方式，性能还可以再次提升。evio 在 linux 环境（epoll）下，单元测试因为 用来唤醒 epoll 的 eventfd 写入数据没有读出 这个bug ，单元测试并不能通过。在 ubuntu 环境下跑 evio 的压测，显示性能并没有 stdlib 好。\nevio 非常轻量，这也说明它非常简单，使用起来还是非常不方便，并且对于 epoll 的处理还有很多可以优化的地方。而且，作者似乎很忙。。。 PR也不理，Issues 也不理。所以决定自己撸一个了，更好用，更快速：eviop 。eviop 是想优化 evio ，但是由于 evio 的代码耦合性问题，举步维艰，所以干脆全部重写，撸了 gev。\n推荐库  gev 一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库。  ","permalink":"https://mogutou.xyz/posts/open-source/evio-code-bug/","summary":"Fast event-loop networking for Go\n 最近翻了 evio 的源码，发现一些问题，主要集中在 linux 平台 epoll 上和读写的处理。\n 用来唤醒 epoll 的 eventfd 写入数据没有读出 listen 的 fd 注册到所有事件循环，epoll 的惊群问题 loopWrite 在内核缓冲区满，无法一次写入时，出现写入数据丢失  eventfd 的使用问题 在 internal/internal_linux.go 中封装了 epoll 的使用 API 。\n// Poll ... type Poll struct { fd int // epoll fd \twfd int // wake fd \tnotes noteQueue } 在 OpenPoll 时，会创建一个 eventfd 并将 fd 赋值给 Poll 的 wfd 成员， 并且注册到 epoll 监听可读事件。","title":"Golang 网络库 evio 一些问题/bug和思考"},{"content":" 阅读前提：了解 epoll\n evio 是一个基于事件驱动的网络框架，它非常轻量而且相比 Go net 标准库更快。其底层使用epoll 和 kqueue 系统调度实现。\n 原理 evio 是 Reactor 模式的简单实现。Reactor 本质就是“non-blocking IO + IO multiplexing”，通过非阻塞IO+ IO 多路复用来处理并发。程序运行一个或者多个事件循环，通过在事件循环中注册回调的方式实现业务逻辑。\nevio 将所有文件描述符设为非阻塞，并注册到事件循环（ epoll / kqueue ）中。相较于传统的 per thread per connection 的处理方法，线程使用更少，线程资源利用率更高。\nevio 需要在服务启动前，注册回调函数，当事件循环中有事件到来时，会调用回调函数处理。\n使用示例 先从一个简单的 echo server 的例子来了解 evio 。\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/tidwall/evio\u0026#34; ) func main() { var port int var loops int var udp bool var trace bool var reuseport bool var stdlib bool flag.IntVar(\u0026amp;port, \u0026#34;port\u0026#34;, 5000, \u0026#34;server port\u0026#34;) flag.BoolVar(\u0026amp;udp, \u0026#34;udp\u0026#34;, false, \u0026#34;listen on udp\u0026#34;) flag.BoolVar(\u0026amp;reuseport, \u0026#34;reuseport\u0026#34;, false, \u0026#34;reuseport (SO_REUSEPORT)\u0026#34;) flag.BoolVar(\u0026amp;trace, \u0026#34;trace\u0026#34;, false, \u0026#34;print packets to console\u0026#34;) flag.IntVar(\u0026amp;loops, \u0026#34;loops\u0026#34;, 0, \u0026#34;num loops\u0026#34;) flag.BoolVar(\u0026amp;stdlib, \u0026#34;stdlib\u0026#34;, false, \u0026#34;use stdlib\u0026#34;) flag.Parse() var events evio.Events events.NumLoops = loops events.Serving = func(srv evio.Server) (action evio.Action) { log.Printf(\u0026#34;echo server started on port %d (loops: %d)\u0026#34;, port, srv.NumLoops) if reuseport { log.Printf(\u0026#34;reuseport\u0026#34;) } if stdlib { log.Printf(\u0026#34;stdlib\u0026#34;) } return } events.Data = func(c evio.Conn, in []byte) (out []byte, action evio.Action) { if trace { log.Printf(\u0026#34;%s\u0026#34;, strings.TrimSpace(string(in))) } out = in return } scheme := \u0026#34;tcp\u0026#34; if udp { scheme = \u0026#34;udp\u0026#34; } if stdlib { scheme += \u0026#34;-net\u0026#34; } log.Fatal(evio.Serve(events, fmt.Sprintf(\u0026#34;%s://:%d?reuseport=%t\u0026#34;, scheme, port, reuseport))) } 上面的例子主要就是注册了两个回调函数： events.Serving 和 events.Data 。\n当 server 启动时，会来执行注册的 events.Serving 回调函数； 当有数据到来时，执行 events.Data 回调函数。\n程序最后调用 evio.Serve 方法开启事件循环，程序在此处不断循环检测是否有事件发生并处理（有数据到来，有数据要发送\u0026hellip;)。\nevio 都是通过回调函数来执行业务逻辑的。 当客户端有数据发送过来时，调用用户注册的 events.Data 函数。\n需要发送数据给客户端时，只可以通过注册的回调函数的返回值来返回，evio 框架来负责发送（有bug）。\n回调函数的返回值主要有两个 out []byte, action evio.Action , out 就是需要发送给客户端的， Action 就是返回一些状态，用来关闭连接，或者服务器退出啥的操作。主要状态如下：\nconst ( // None indicates that no action should occur following an event. \tNone Action = iota // Detach detaches a connection. Not available for UDP connections. \tDetach // Close closes the connection. \tClose // Shutdown shutdowns the server. \tShutdown ) evio 的事件循环 evio.Serve 我们先来看下 evio.Serve 方法的实现\nfunc Serve(events Events, addr ...string) error { var lns []*listener defer func() { // 这个函数如果推出，需要关闭所有 listener \tfor _, ln := range lns { ln.close() } }() var stdlib bool // 可以选择使用 stdlib（stdlib 主要是为了支持 非 *unix 平台） \tfor _, addr := range addr { // 生成 listener \tvar ln listener var stdlibt bool ln.network, ln.addr, ln.opts, stdlibt = parseAddr(addr) if stdlibt { stdlib = true } if ln.network == \u0026#34;unix\u0026#34; { os.RemoveAll(ln.addr) } var err error if ln.network == \u0026#34;udp\u0026#34; { if ln.opts.reusePort { ln.pconn, err = reuseportListenPacket(ln.network, ln.addr) } else { ln.pconn, err = net.ListenPacket(ln.network, ln.addr) } } else { if ln.opts.reusePort { ln.ln, err = reuseportListen(ln.network, ln.addr) } else { ln.ln, err = net.Listen(ln.network, ln.addr) } } if err != nil { return err } if ln.pconn != nil { ln.lnaddr = ln.pconn.LocalAddr() } else { ln.lnaddr = ln.ln.Addr() } if !stdlib { if err := ln.system(); err != nil { return err } } lns = append(lns, \u0026amp;ln) } if stdlib { return stdserve(events, lns) // 使用 std net 库 启动server \t} return serve(events, lns) // 使用 epoll or kqueue 启动server } 从 Serve 函数签名中可以看出 evio 是支持绑定多地址监听的\nfunc Serve(events Events, addr ...string) error 使用方式如下：\nevio.Serve(events, \u0026#34;tcp://localhost:5000\u0026#34;, \u0026#34;tcp://192.168.0.10:5001\u0026#34;); 现在我们看看 evio 的核心部分: serve(events, lns) ，这里会启动 evio 的 sever 。\nfunc serve(events Events, listeners []*listener) error { numLoops := events.NumLoops\t// 确定启动的事件循环数量 \tif numLoops \u0026lt;= 0 { if numLoops == 0 { numLoops = 1 } else { numLoops = runtime.NumCPU() } } s := \u0026amp;server{} s.events = events s.lns = listeners s.cond = sync.NewCond(\u0026amp;sync.Mutex{}) s.balance = events.LoadBalance s.tch = make(chan time.Duration) //println(\u0026#34;-- server starting\u0026#34;) \tif s.events.Serving != nil {\t// 如果注册了回调函数，就执行 \tvar svr Server svr.NumLoops = numLoops svr.Addrs = make([]net.Addr, len(listeners)) for i, ln := range listeners { svr.Addrs[i] = ln.lnaddr } action := s.events.Serving(svr) switch action { case None: case Shutdown: return nil } } defer func() {\t// server 退出后的清理工作 \t// wait on a signal for shutdown \ts.waitForShutdown() // notify all loops to close by closing all listeners \tfor _, l := range s.loops { l.poll.Trigger(errClosing) } // wait on all loops to complete reading events \ts.wg.Wait() // close loops and all outstanding connections \tfor _, l := range s.loops { for _, c := range l.fdconns { loopCloseConn(s, l, c, nil) } l.poll.Close() } //println(\u0026#34;-- server stopped\u0026#34;) \t}() // create loops locally and bind the listeners. \tfor i := 0; i \u0026lt; numLoops; i++ { l := \u0026amp;loop{ idx: i, poll: internal.OpenPoll(), packet: make([]byte, 0xFFFF), // event loop 的 read 缓冲区 \tfdconns: make(map[int]*conn), } for _, ln := range listeners { l.poll.AddRead(ln.fd)\t// 将 fd 注册到 epoll 中并监听可读事件 \t} s.loops = append(s.loops, l) } // start loops in background \ts.wg.Add(len(s.loops)) for _, l := range s.loops { // 启动所有的 event loop \tgo loopRun(s, l) } return nil } serve 主要做这些事：\n 根据配置启动指定数量的 event loop，如果传入配置的 loop 数量为 0 则设置启动一个事件循环，如果传入配置小于 0 则设置为运行平台的CPU核心数量 如果设置了回调函数 events.Serving ，运行它 按照指定 event loop 数量，创建 epoll 句柄生成 loop ，并将所有的 listener 注册到 epoll 监听可读事件（有客户端连接） 启动所有事件循环(一个事件循环一个 goroutine)  需要注意的是，evio 将所有的 listener 的 fd 在每一个事件循环的 epoll 中都注册了。也就是说，如果有三个事件循环，一个 listener ，那么这个 listener 的 fd 会注册到三个 epoll 中。这就会出现 epoll 的惊群现象，感兴趣的可以自己搜索了解下。\nevio 当一个新连接到来时，所有的事件循环都会唤醒，但是最终只有一个线程可以accept调用返回成功，其他线程（协程）的accept函数调用返回EAGAIN错误 。\nloopRun 下面我们看看 loopRun 的内部实现\nfunc loopRun(s *server, l *loop) { defer func() { //fmt.Println(\u0026#34;-- loop stopped --\u0026#34;, l.idx) \ts.signalShutdown() s.wg.Done() }() if l.idx == 0 \u0026amp;\u0026amp; s.events.Tick != nil { go loopTicker(s, l) } //fmt.Println(\u0026#34;-- loop started --\u0026#34;, l.idx) \tl.poll.Wait(func(fd int, note interface{}) error { if fd == 0 { return loopNote(s, l, note) } c := l.fdconns[fd] switch { case c == nil: return loopAccept(s, l, fd) case !c.opened: return loopOpened(s, l, c) case len(c.out) \u0026gt; 0: return loopWrite(s, l, c) case c.action != None: return loopAction(s, l, c) default: return loopRead(s, l, c) } }) } l.poll.Wait 传入一个回调函数作为参数，当 epoll 收到事件通知时，会执行这个回调函数。\n在这个函数中接受客户端连接，读取客户端数据，调用客户回调函数处理业务逻辑\u0026hellip;\n我们先来看下 poll.Wait 的内部实现，再看看 loopAccept，loopOpened，loopWrite 等函数。 loopRun 方法中最重要的就是 poll.Wait ，我们看看 Linux 下 epoll 的实现\nfunc (p *Poll) Wait(iter func(fd int, note interface{}) error) error { events := make([]syscall.EpollEvent, 64) for { n, err := syscall.EpollWait(p.fd, events, -1) if err != nil \u0026amp;\u0026amp; err != syscall.EINTR { return err } if err := p.notes.ForEach(func(note interface{}) error { return iter(0, note) }); err != nil { return err } for i := 0; i \u0026lt; n; i++ { if fd := int(events[i].Fd); fd != p.wfd { if err := iter(fd, nil); err != nil { return err } } else { } } } } 这个函数中是一个死循环，程序会阻塞在此处等待 epoll 的”通知“，然后处理就绪的 fd （读取/发送数据、执行用户注册的回调函数）。\n当有 fd 就绪的时候，syscall.EpollWait 函数返回，并且将就绪的 fd 通过 events 传出，返回值 n 为就绪 fd 的个数。\n然后循环逐个遍历就绪的 fd，调用回调函数处理。\nfor i := 0; i \u0026lt; n; i++ { if fd := int(events[i].Fd); fd != p.wfd { if err := iter(fd, nil); err != nil { return err } } else { } } evio 的事件处理 l.poll.Wait(func(fd int, note interface{}) error { if fd == 0 { return loopNote(s, l, note) } c := l.fdconns[fd] switch { case c == nil: return loopAccept(s, l, fd) case !c.opened: return loopOpened(s, l, c) case len(c.out) \u0026gt; 0: return loopWrite(s, l, c) case c.action != None: return loopAction(s, l, c) default: return loopRead(s, l, c) } }) 当 epoll 检测到有就绪的 fd 时，会逐个调用上面的回调函数，evio 的主要逻辑也在这里。\n当 fd == 0 时，会执行 loopNote 函数。loopNote 主要是用来处理一些非 fd 就绪的事件，比如定时任务、强制退出等。当然，我们都知道 fd 为 0 是标准输入，所以此处并不是真的去处理 fd 为 0 的文件描述符（注册到 epoll 的文件描述 \u0026gt;= 3）。作者知道 epoll 返回的就绪 fd 中不会有为 0 的情况，所以此处 fd 为 0，是作者调用时传入，用来表示一种特殊的唤醒场景。\nfunc (p *Poll) Wait(iter func(fd int, note interface{}) error) error { ... p.changes = p.changes[:0] if err := p.notes.ForEach(func(note interface{}) error { return iter(0, note) ... 我们跳到调用它的地方，可以看到只有在 p.notes.ForEach 这个函数中注册的回调函数中才会传入 fd 为 0 来执行 iter 回调函数。\nnotes noteQueue\nnoteQueue 的实现在 internal 目录中的 notequeue.go , 是一个无锁队列。我们不详细分析，只看下 ForEach 这个方法：\nfunc (q *noteQueue) ForEach(iter func(note interface{}) error) error { q.mu.Lock() if len(q.notes) == 0 { q.mu.Unlock() return nil } notes := q.notes q.notes = nil q.mu.Unlock() for _, note := range notes { if err := iter(note); err != nil { // 执行回调函数 \treturn err } } return nil } 当队列中有数据时， 会执行回调函数，即\nfunc(note interface{}) error { return iter(0, note) } 从上面的分析中可以我们已经知道为什么会有 fd 为 0 ，下面我们看下 loopNote 做什么。\nloopNote func loopNote(s *server, l *loop, note interface{}) error { var err error switch v := note.(type) { case time.Duration: delay, action := s.events.Tick() switch action { case None: case Shutdown: err = errClosing } s.tch \u0026lt;- delay case error: // shutdown \terr = v case *conn: // Wake called for connection \tif l.fdconns[v.fd] != v { return nil // ignore stale wakes \t} return loopWake(s, l, v) } return err } 传入的 note 是 interface{} ，首先对 note 进行类型判断。\n当 note 是 time.Duration 时，调用回调函数 events.Tick() ，这是 evio 提供的定时任务接口。\n在 loopRun 函数中，如果设置了定时回调函数，会启动一个协程来来运行 loopTicker\nif l.idx == 0 \u0026amp;\u0026amp; s.events.Tick != nil { go loopTicker(s, l) } loopTicker 实现如下，可以看出会定时去触发 l.poll.Trigger，并且传入 time.Duration(0)\nfunc loopTicker(s *server, l *loop) { for { if err := l.poll.Trigger(time.Duration(0)); err != nil { break } time.Sleep(\u0026lt;-s.tch) } } 我们跳到 poll.Trigger 的 linux 下的实现，可以发现 evio 在此处 p.notes.Add(note) ，也就是 time.Duration(0)\nfunc (p *Poll) Trigger(note interface{}) error { p.notes.Add(note) _, err := syscall.Write(p.wfd, []byte{0, 0, 0, 0, 0, 0, 0, 1}) return err } poll.Trigger 这个函数不仅仅是在 p.notes 里增加了一个 note，还唤醒了事件循环。\n当 epoll 中注册 fd 都没有就绪事件时，线程会挂起，epoll 的 wait 方法会处于阻塞状态。evio 使用 linux 提供的 eventfd 来实现事件循环的唤醒，也就是代码上中的 syscall.Write(p.wfd, []byte{0, 0, 0, 0, 0, 0, 0, 1}) ,往 p.wfd 这个文件描述符中写入了 8 个字节的数据。\np.wfd 是一个 eventfd , 是 Poll 结构体的成员，在 OpenPoll 时赋值，即打开一个 eventfd 代码如下：\ntype Poll struct { fd int // epoll fd \twfd int // wake fd \tnotes noteQueue } func OpenPoll() *Poll { l := new(Poll) p, err := syscall.EpollCreate1(0) if err != nil { panic(err) } l.fd = p r0, _, e0 := syscall.Syscall(syscall.SYS_EVENTFD2, 0, 0, 0) if e0 != 0 { syscall.Close(p) panic(err) } l.wfd = int(r0) l.AddRead(l.wfd) return l } syscall.Syscall(syscall.SYS_EVENTFD2, 0, 0, 0) 创建了一个 eventfd ，然后将这个 eventfd 注册到了 epoll 监听可读事件。当 syscall.Write(p.wfd, []byte{0, 0, 0, 0, 0, 0, 0, 1}) 时候，epoll 就会唤醒。\n但是，我翻了好久，也没有找到 evio 在哪里读取 eventfd 写入的8个字节（epoll）。这是一个 bug，所以在 linux 机器上，这是不能用的。\n 这个bug会造成 epoll 不断唤醒，cpu被长期占用\n 当我们注册了 evio 的定时任务 Tick 回调函数，程序启动后会往 eventfd 里写入 8 个字节数据，但是 evio 并没有读取，并且 evio 使用的是 epoll 的默认模式 LT，即只要可读缓冲区里还有数据，epoll 会一直不断唤醒，这是一个严重的 bug，作者应该没有在 linux 环境下严格测试过。\n我们抛开这个 bug， 继续来看 note 为 error 类型的情况。在 serve 函数中，当函数退出时，通过 l.poll.Trigger(errClosing) 来通知每个事件循环退出。\nfunc serve(events Events, listeners []*listener) error { ... defer func() { // wait on a signal for shutdown \ts.waitForShutdown() // notify all loops to close by closing all listeners \tfor _, l := range s.loops { l.poll.Trigger(errClosing) } // wait on all loops to complete reading events \ts.wg.Wait() // close loops and all outstanding connections \tfor _, l := range s.loops { for _, c := range l.fdconns { loopCloseConn(s, l, c, nil) } l.poll.Close() } //println(\u0026#34;-- server stopped\u0026#34;) }() ... 当 note 为 *conn 这种情况，是用来提供给使用者主动唤醒当前事件循环\nfunc (c *conn) Wake() { if c.loop != nil { c.loop.poll.Trigger(c) } } loopAccept c := l.fdconns[fd] switch { case c == nil: return loopAccept(s, l, fd) type loop struct { idx int // loop index in the server loops list \tpoll *internal.Poll // epoll or kqueue \tpacket []byte // read packet buffer \tfdconns map[int]*conn // loop connections fd -\u0026gt; conn \tcount int32 // connection count } fdconns 是用来存储已连接的TCP connection 信息，key 为 fd， value 为 *conn 。\n当 epoll 唤醒时，如果 fd 不在当前事件循环的连接，那就说明它是新连接，则执行 loopAccept 。\nfunc loopAccept(s *server, l *loop, fd int) error { for i, ln := range s.lns { if ln.fd == fd { if len(s.loops) \u0026gt; 1 { switch s.balance { case LeastConnections: n := atomic.LoadInt32(\u0026amp;l.count) for _, lp := range s.loops { if lp.idx != l.idx { if atomic.LoadInt32(\u0026amp;lp.count) \u0026lt; n { return nil // do not accept \t} } } case RoundRobin: idx := int(atomic.LoadUintptr(\u0026amp;s.accepted)) % len(s.loops) if idx != l.idx { return nil // do not accept \t} atomic.AddUintptr(\u0026amp;s.accepted, 1) } } if ln.pconn != nil { return loopUDPRead(s, l, i, fd) } nfd, sa, err := syscall.Accept(fd) if err != nil { if err == syscall.EAGAIN { return nil } return err } if err := syscall.SetNonblock(nfd, true); err != nil { return err } c := \u0026amp;conn{fd: nfd, sa: sa, lnidx: i, loop: l} l.fdconns[c.fd] = c l.poll.AddReadWrite(c.fd) atomic.AddInt32(\u0026amp;l.count, 1) break } } return nil } 因为 evio 支持多地址监听，所以会存在多个 listener ，也就是 s.lns 。\n第一步，先遍历所有的 listener 看看当前 epoll 中就绪的 fd 是哪一个 listener ，然后执行客户端的负载策略，决定新的客户端连接放在哪一个事件循环中。\n这里关于客户端的负载策略，evio 利用了 epoll 的惊群效果，所有的事件循环都会唤醒进入loopAccept，不符合负载策略直接 return nil。 关于这边的更多细节，可以看我的另一篇文章 【Golang 网络库 evio 一些问题/bug和思考】。\n接下来就是常规操作了， syscall.Accept(fd) 接受连接，然后  syscall.SetNonblock(nfd, true) 设置成非阻塞模式，\tl.poll.AddReadWrite(c.fd) 最后加入事件循环，注册可读可写事件。\nloopOpened func loopOpened(s *server, l *loop, c *conn) error { c.opened = true c.addrIndex = c.lnidx c.localAddr = s.lns[c.lnidx].lnaddr c.remoteAddr = internal.SockaddrToAddr(c.sa) if s.events.Opened != nil { out, opts, action := s.events.Opened(c) if len(out) \u0026gt; 0 { c.out = append([]byte{}, out...) } c.action = action c.reuse = opts.ReuseInputBuffer if opts.TCPKeepAlive \u0026gt; 0 { if _, ok := s.lns[c.lnidx].ln.(*net.TCPListener); ok { internal.SetKeepAlive(c.fd, int(opts.TCPKeepAlive/time.Second)) } } } if len(c.out) == 0 \u0026amp;\u0026amp; c.action == None { l.poll.ModRead(c.fd) } return nil } loopOpened 是在 loopAccept 执行完成后，epoll 会立马再次唤醒然后执行的。\n因为在 loopAccept 中最后将新的客户端连接加入 epoll 管理时注册的是可读可写事件，当前的内核写缓冲区肯定是为空的，所以 epoll 会再次唤醒。\n... case !c.opened: return loopOpened(s, l, c) ... 唤醒后会执行到这个 case case !c.opened:，因为在 loopAccept 中并没有去设置这个值。\nloopOpened 内部的操作，主要就是设置一下 conn 的属性，然后调用客户注册的回调函数 events.Opened 。\n如果在回调函数中，没有给客户端发送数据，则需要重新注册，只注册可读事件，不然 epoll 会一直唤醒（可写事件）。\nloopAction func loopAction(s *server, l *loop, c *conn) error { switch c.action { default: c.action = None case Close: return loopCloseConn(s, l, c, nil) case Shutdown: return errClosing case Detach: return loopDetachConn(s, l, c, nil) } if len(c.out) == 0 \u0026amp;\u0026amp; c.action == None { l.poll.ModRead(c.fd) } return nil } case c.action != None: return loopAction(s, l, c) loopAction 会在 case c.action != None: 的情况下执行， c.action 是执行完用户回调函数后会被赋值的状态。\n在会有 action 的 loopXXX 中都会有如下类似操作。\nif len(c.out) != 0 || c.action != None { l.poll.ModReadWrite(c.fd) } 也就是说 loopAction 依赖于 epoll 被可写事件再次唤醒来执行，这样会不会有问题呢？ 内核缓冲区满了？？\nloopAction 内部的主要操作就是根据 action 做一些处理，关闭连接等等。\nloopRead 和 loopWrite loopRead 和 loopWrite 主要就是调用系统调用读取和发送数据，并且调用用户回调函数，根据回调函数返回值来重新注册 epoll 的可读可写事件。\nfunc loopRead(s *server, l *loop, c *conn) error { var in []byte n, err := syscall.Read(c.fd, l.packet) if n == 0 || err != nil { if err == syscall.EAGAIN { return nil } return loopCloseConn(s, l, c, err) } in = l.packet[:n] if !c.reuse { in = append([]byte{}, in...) } if s.events.Data != nil { out, action := s.events.Data(c, in) c.action = action if len(out) \u0026gt; 0 { c.out = append([]byte{}, out...) } } if len(c.out) != 0 || c.action != None { l.poll.ModReadWrite(c.fd) } return nil } 调用 n, err := syscall.Read(c.fd, l.packet) 读取内核缓冲区的数据，如果返回出错 err == syscall.EAGAIN 意思是再试一次，\u0008直接返回。\n如果 n == 0 或者 err 错误不为 syscall.EAGAIN ，则说明对方关闭了连接或是其他错误，直接 loopCloseConn 。\n然后调用用户回调函数 s.events.Data ，根据返回值做相应操作。c.action = action\n如果 out 里有数据，则赋给 c.out , 并且注册可读可写事件。\n如果 c.action != None ，同样需要注册可读可写事件，原因上面已经说过了。\nloopWrite 操作也大同小异，就不细说了。\n但是其实关于 loopWrite 和 loopRead 的处理是会有 bug 的，详情可以看另一篇文章。\n推荐库  gev 一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库。  ","permalink":"https://mogutou.xyz/posts/open-source/evio-code/","summary":"阅读前提：了解 epoll\n evio 是一个基于事件驱动的网络框架，它非常轻量而且相比 Go net 标准库更快。其底层使用epoll 和 kqueue 系统调度实现。\n 原理 evio 是 Reactor 模式的简单实现。Reactor 本质就是“non-blocking IO + IO multiplexing”，通过非阻塞IO+ IO 多路复用来处理并发。程序运行一个或者多个事件循环，通过在事件循环中注册回调的方式实现业务逻辑。\nevio 将所有文件描述符设为非阻塞，并注册到事件循环（ epoll / kqueue ）中。相较于传统的 per thread per connection 的处理方法，线程使用更少，线程资源利用率更高。\nevio 需要在服务启动前，注册回调函数，当事件循环中有事件到来时，会调用回调函数处理。\n使用示例 先从一个简单的 echo server 的例子来了解 evio 。\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/tidwall/evio\u0026#34; ) func main() { var port int var loops int var udp bool var trace bool var reuseport bool var stdlib bool flag.","title":"Golang 高性能网络库 evio 源码解析"},{"content":"Hello World 我们以传统的“hello\tworld”案例开始吧。\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello World\u0026#34;) } Go的源文件以 .go 为后缀名，这些文件名均由小写字母（推荐做法）组成且不包含空格和其他特殊字符，如 main.go 。如果文件名由多个部分组成，则使用下划线 _ 对它们进行分隔，如 main_test.go 。\nGo是一门编译型语言,Go语言的工具链将源代码及其依赖转换成计算机的机器指令。Go语言提供的工具都通过一个单独的命令 go\t调用，go 命令有一系列子命令。\n$ go help Go is a tool for managing Go source code. Usage: go \u0026lt;command\u0026gt; [arguments] The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages ... 我们通过 go run 命令编译 main.go 文件并且运行它。\n$ go run main.go Hello World 前面已经说过了GO语言是一门编译型语言，所以通过 go 工具同样可以编译生成二进制文件保存下来。\n$ go build main.go 执行后，会在当前目录生成一个可执行文件 main （Windows平台是 main.exe）。我们可以直接在命令行运行它，就像执行 C/C++ 静态编译出来的可执行文件一样。\n$ ./main Hello World Go语言的代码通过包组织,包机制类似于其它语言里的库或者模块。一个包由位于单个目录下的一个或多个 .go 源代码文件组成。每个源文件都以一条 package 声明语句开始，这个例子里就是 package main，表示该文件属于哪个包，紧跟着一系列导入 (import) 的包。\nimport \u0026#34;fmt\u0026#34; 接下来是这个文件的程序代码，在本例中是 main 函数。\nmain 包是一个比较特殊的包，它定义了一个独立可执行的程序，而不是一个库。在 main 包里的 main 函数是整个程序执行时的入口，就像 C/C++ 里一样。\nGo的标准库提供了100多个包， fmt\t包含有格式化输出、接收输入等方法。Println 函数是其中一个基础函数,可以打印以空格间隔的一个或多个值,并在最后添加一个换行符。\nfunc 是Go语言的关键字之一，用于声明一个函数。一个函数的声明由 func 关键字、函数名、参数列表、返回值列表以及包含在大括号里的函数体组成。本例中的 main 函数参数列表和返回值都是空的，意思就是没有参数和返回值，无需像 C/C++ 中那样再手动添加 void，也不会存在隐式的默认参数。\nGo语言不需要在语句或者声明的末尾添加分号,除非一行上有多条语句。但是,实际上编译器会帮我们添加分号。\nGo语言在代码格式上强制统一，比如函数作左括号 { 必须另起一行，否则会编译报错。这样省去了很多口水仗，也统一了代码风格，提高了代码可读性。Go语言提供 gofmt (go fmt)\t工具把代码格式化为标准格式。\ngofmt -w main.go 该命令会格式化该源文件的代码并且将格式化后的代码覆盖原始内容，如果不加参数 -w 则只会打印格式化后的结果而不重写文件。在实际开发中，我们可以使用IDE或者编辑器插件自动格式化，无需每次执行命令来格式化代码。\nGolang 的主要特点  我发现我花了四年时间锤炼自己用 C 语言构建系统的能力，试图找到一个规范，可以更好的编写软件。结果发现只是对 Go 的模仿。缺乏语言层面的支持，只能是一个拙劣的模仿。 \u0026ndash;云风\n 极简设计 Go 语言给人的第一感觉便是简洁。Go 语言通过减少关键字的数量（25 个，截止至发稿日期）来简化编码过程中的复杂度。这些关键字在编译过程中少到不需要符号表来协助解析，这也是Go语言的编译速度也是非常快的原因之一。极少的关键字，极简的语法都极大减少开发者编码的工作量，也提高了代码的可读性。\nGo 语言的强类型系统禁止一切隐式类型转换，让代码更加容易阅读，减少犯错的机会。\ndefer 实现 RAII 也比 C++ 中通过对象生命周期和析构函数的实现方式更加容易理解和简洁明了。\nfile, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { panic(err) } defer file.Close() Go 语言默认所有类型 zero 初始化，省去了很多无意义的初始化操作，也降低了开发者出错的几率。\nGo 语言部署非常简单，编译出来一个静态可执行文件，除了 glibc 外没有其他外部依赖便可以直接运行。并且 Go 语言支持交叉编译，使用自带的工具 go build 可以直接将源代码编译成不同平台上的可执行程序。\n比如，我们在Mac或者Windows上为Linux编译应用：\nGOOS=linux GOARCH=amd64 go build main.go 只需要声明目标系统（GOOS）与CPU架构（GOARCH）即可。\nGo 语言从设计上就坚持极简理念，并且极力给作者提供简单高效的开发体验。\n开发效率与运行效率齐飞 “少即是多” 这就是 Go 语言贯穿始终的哲学。极简的语法，语言级别的并发管理，自动垃圾回收让开发者可以用最少的代码实现功能强大的程序。Go 语言没有隐式转换，没有构造函数和析构函数,没有运算符重载,没有继承\u0026hellip;，极大的降低了开发者的心智负担。完善的类型系统让 Go 语言可以避免动态语言那种粗心的类型错误，同时又没有 C++ 那样繁杂的具体类型属性需要考量。Go 语言强制统一代码风格，减少了不少口水战，也让代码的可读性，可维护性更高了，这也是提高开发效率的关键。Go 语言致力于提供更少的语言特性，通过简洁的设计，减少代码出错的机会，让开发者更容易写出更高质量的代码。\nGo 语言出现之前，各种语言在运行效率和开发效率上都不能兼备。Python开发效率高，但是性能差强人意; C/C++ 运行效率毋庸置疑，但是开发效率略低。Go 语言运行效率高是因为 Go 语言是编译型的静态语言，它在执行速度上比解释型语言具有先天的优势，但是同时其简洁的语法又让开发者有种写动态语言的轻松感。Go 语言的运行效率直逼 C/C++ ，之所以稍逊于 C/C++ 主要还是因为 GC（自动垃圾回收机制），考虑到开发效率上的提升，这一点性能损失还是值得的。\n强大的内置类型和标准库 Go 语言除了几乎所有语言都支持的简单内置类型(比如整型和浮点型等)外， 也内置了一些比较新的语言中内置的高级类型，比如数组、字符串、字典类型(map)。Go语言的标准库覆盖网络、系统、加密、编码、图形等各个方面，可以直接使用标准库的 http 包进行 HTTP 协议的收发处理;网络库基于高性能的操作系统通信模型(Linux 的 epoll、Windows 的 IOCP);所有的加密、编码都内建支持，不需要再从第三方开发者处获取。\n   Go语言标准库包名 功 能     bufio 带缓冲的 I/O 操作   bytes 实现字节操作   container 封装堆、列表和环形列表等容器   crypto 加密算法   database 数据库驱动和接口   debug 各种调试文件格式访问及调试功能   encoding 常见算法如 JSON、XML、Base64 等   flag 命令行解析   fmt 格式化操作   go Go 语言的词法、语法树、类型等。可通过这个包进行代码信息提取和修改   html HTML 转义及模板系统   image 常见图形格式的访问及生成   io 实现 I/O 原始访问接口及访问封装   math 数学库   net 网络库，支持 Socket、HTTP、邮件、RPC、SMTP 等   os 操作系统平台不依赖平台操作封装   path 兼容各操作系统的路径操作实用函数   plugin Go 1.7 加入的插件系统。支持将代码编译为插件，按需加载   reflect 语言反射支持。可以动态获得代码中的类型信息，获取和修改变量的值   regexp 正则表达式封装   runtime 运行时接口   sort 排序接口   strings 字符串转换、解析及实用函数   time 时间接口   text 文本模板及 Token 词法器   \u0026hellip; \u0026hellip;    并发 并发编程可以充分发挥多核处理器的性能。在 C/C++ 中，可以通过编写多线程程序来实现并发，但是滥用线程会加重系统负担，所以更优的做法是使用通过 epoll 等方式来实现IO多路复用，以及使用各种协程库。除此之外，多个线程之间肯定还需要传递数据，可以通过 shared_ptr 来做，但是也需要小心翼翼，整个编码过程非常容易犯错。\ngoroutine 是 Go 语言并发设计的核心。goroutine 其实就是协程，比线程更轻量，是一种运行在用户态的用户线程。goroutine 并不是对应于内核线程，一个内核线程会调度若干个协程，goroutine 是在语言层面提供了调度器，并且对网络IO库进行了封装，屏蔽了复杂的细节，对外提供统一的语法关键字支持，简化了并发程序编写的成本。channel 是设计来在 goroutine 之间传递数据，channel 在实现原理上其实是一个阻塞的消息队列。在一个 goroutine 中将消息发送到 channel 中，然后在监听这个 channel 的 goroutine 处理，实现了不同 goroutine 的解耦。\n接口设计 接口类型是对其它类型行为的抽象和概括;因为接口类型不会和特定的实现细节绑定在一起,通过这种抽象的方式我们可以让我们的函数更加灵活和更具有适应能力。\nGo语言的主要设计者之一 Rob Pike 曾经说过，如果只能选择一个Go语言的特性移植到其他语言中，他会选择接口。可见接口在Go 语言中的地位，及其对gloang这门语言所带来的活力。\nC++,Java 中使用侵入式接口，实现类需要明确声明自己实现了某个接口。这种强制性的接口继承方式是面向对象编程思想发展过程中一个争议颇多的特性。\nGo语言采用的是非侵入式接口,只要某类型的公开方法完全满足接口的要求，就可以把此类型的对象用在需要该接口的地方。满足接口的要求，即是指实现了接口所规定的一组成员(方法)。Go 语言的接口实现者无需指明实现了哪一个接口，编译器会去完成这项工作并发现错误。\n控制结构 Go 程序和大多数编程语言一样从 main() 函数开始执行，然后按顺序执行该函数体中代码。代码中必然需要进行条件判断，Go 中提供如下分支结构：\n if-else switch select  Go 中同样有循环结构来重复执行某段代码：\n for(range)  if-else 结构 if 是用于测试某个条件（布尔型或逻辑型）的语句，如果该条件成立，则会执行 if 后由大括号括起来的代码块。else 这个代码块中的代码只有在 if 条件不满足时才会执行。if 和 else 后的两个代码块是相互独立的分支，永远只会执行其中一个。\nif condition { // do something\t} else { // do something\t} 如果需要 增加更多分支选择，可以使用 else if 。else-if 分支的数量是没有限制的，但是当选择条件过多时，应该使用 switch 。\nif condition1 { // do something\t} else if condition2 { // do something else\t} else { // catch-all or default } if 可以包含一个初始化语句，常用于 err 的条件判断。\nif initialization; condition { // do something } 例如：\nif err := fun(); err != nil { // do something } switch 结构 相比较 C/C++ 等其他语言而言，Go 语言中的 switch 结构使用非常灵活, 并且不需要 breake 语句来跳出。\nswitch value { case v1: ... case v2: ... default: ... } value 变量可以是任何类型，v1 和 v2 是同类型的任意值或者是最终结果为相同类型的表达式，但不限于常量和整数。 同一个 case 可以匹配多个可能符合条件的值，通过逗号分割：\nswitch i { case 0: case 1,2,3: f() // 当 i == 1 或者 i == 2 或者 i == 3 则执行 f() } switch 语句可以不提供任何被判断的值，然后在每个 case 分支中进行测试不同的条件。当任一分支的测试结果为 true 时，该分支的代码会被执行。这看起来非常像链式的 if-else 语句。\nswitch { case i \u0026lt; 0: f1() case i == 0: f2() case i \u0026gt; 0: f3() } switch 语句还可以包含一个初始化语句：\nswitch result := calculate(); { case result \u0026lt; 0: ... case result \u0026gt; 0: ... default: // 0 } switch a, b := x[i], y[j]; { case a \u0026lt; b: t = -1 case a == b: t = 0 case a \u0026gt; b: t = 1 } 因为 Go 的 switch 相当于每个case最后都自带一个 break ，匹配成功后就不会向下执行其他 case ，所以如果需要接着执行下一个 case 的可以使用 fallthrough 关键字。\ni:= 2 switch i { case 1: fmt.Println(\u0026#34;1\u0026#34;) fallthrough case 2: fmt.Println(\u0026#34;2\u0026#34;) fallthrough case 3: fmt.Println(\u0026#34;3\u0026#34;) fallthrough case 4: fmt.Println(\u0026#34;4\u0026#34;) fallthrough default: fmt.Println(\u0026#34;default\u0026#34;) } 输出：\n2 3 4 default fallthrough 只会强制执行下一个 case 。\ni:= 2 switch i { case 1: fmt.Println(\u0026#34;1\u0026#34;) fallthrough case 2: fmt.Println(\u0026#34;2\u0026#34;) fallthrough case 3: fmt.Println(\u0026#34;3\u0026#34;) // fallthrough  case 4: fmt.Println(\u0026#34;4\u0026#34;) fallthrough default: fmt.Println(\u0026#34;default\u0026#34;) } 输出：\n2 3 Go 中的 switch 还可以用来做类型判断。\npackage main import \u0026#34;fmt\u0026#34; func Type(v interface{}) { switch v.(type) { case bool: fmt.Println(\u0026#34;bool\u0026#34;) case float64: fmt.Println(\u0026#34;float64\u0026#34;) case int: fmt.Println(\u0026#34;int\u0026#34;) case nil: fmt.Println(\u0026#34;nil\u0026#34;) case string: fmt.Println(\u0026#34;string\u0026#34;) default: fmt.Println(\u0026#34;default\u0026#34;) } } func main() { Type(1)\tType(\u0026#34;\u0026#34;) Type(true) Type(nil) i := 1 Type(\u0026amp;i)\t// *int } 输出：\nint string bool nil default for 结构 Go 中循环结构只有 for 语句，并没有 while 语句。\nfor 语句基本用法和其他语言无异：\nfor i := 0; i \u0026lt; 5; i++ { // do } 支持多个变量控制循环：\nfor i, j := 0, 1; i \u0026lt; j; i, j = i+1, j-1 { // do } for 语句实现 while 语句功能：\nvar i int = 3 for i \u0026gt;= 0 { i-- // do } 无限循环：\nfor { } for i := 0; ; i++ { } for ; ; { } Go 中还提供一个关键字用于循环结构 range ，它可以迭代任何一个集合（数组，map）。\nfor k, v := range s { // do } 需要注意的是，v 对于元素的值拷贝，任何对 v 的修改都不会影响集合 s 。\nbreak 和 continue 和其他语言一样，break 用于跳出整个循环，continue 用于跳出当前循环继续下一次循环。\nfor i := 0; i \u0026lt; 3; i++ { if i == 1 { continue } println(i) } 输出：\n0 2 for i := 0; i \u0026lt; 3; i++ { if i == 1 { break } println(i) } 输出：\n0 基本数据类型和要素 包的概念 类似其他语言中的库和模块的概念，目的都是为了支持模块化、封装、单独编译和代码重用。每一个 Go 文件都属于且仅属于一个包，每个包可以有多个 Go 文件。每个包中的程序可以使用自身的包或者导入其他包。\n当包内的全局变量或者常量标识符以一个大写字母开头，如： Test，那么它就是可以直接被外部包使用的，称为导出，类似于其他面向对象语言中 public。如果是以小写的字母开头，则对包外是不可见的，但是可以在包内直接使用（同一个包内的不同 .go 文件可以直接使用），类似于其他面向对象语言中的 private。\n每个包都对应一个独立的名称空间。不同包的导出函数或者变量即使名称相同，也不会有命名冲突。在外部调用时必须显示指定包，例如： fmt.Println 。如果包名有冲突，可以在导入的时候设置别名，如：\npackage main import f \u0026#34;fmt\u0026#34; func main() { f.Println(\u0026#34;Hello World\u0026#34;) } 如果需要导入多个包\nimport \u0026#34;fmt\u0026#34; import \u0026#34;os\u0026#34; 但是有更简短的做法\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) 注释 Go 提供了 C 样式 /* */ 块注释和 C++ 样式 // 行注释。行注释是标准规范，块注释主要作为包注释出现或者是禁用大量代码时使用。\n// 单行注释  /* 块注释 */ 常量 Go 的常量使用 const 关键字定义，常量的数据类型只可以是布尔型、数字型和字符串类型。\nconst a string = \u0026#34;abc\u0026#34; const b = \u0026#34;abc\u0026#34; Go 的编译器可以自动推断类型，所以以上两种定义方法都是可以的。\n常量的值必须是能够在编译期就能够确定的，可以在其赋值表达式中涉及计算过程，但是所有用于计算的值必须在编译期间就能获得。\nconst c = 1+3 上面是正确的做法，但是下面的 func1 自定义函数无法在编译期求值，因此无法用于常量的赋值，但是 Go 内置的函数是可以的，如： len() 。\nconst c = func1() Go 对关键字十分吝啬，对于枚举类型没有专门的关键字，但是常量可以用作枚举。\nconst ( a = 0 b = 1 c = 2 ) Go 语言还提供了 iota 关键字，可以用来简化常量的增长数字的定义。iota 会自增 1 ,每遇到一次 const 关键字，就重置为 0 。\nconst ( a = iota //0 \tb //1 \tc //2 ) 变量 Go 声明变量使用 var 关键字：\nvar a int = 1 var ( a int // 0 \tb bool // false \tc string // \u0026#34;\u0026#34;  d *int // nil ) 声明变量时可以不赋值，默认初始化都会是 ”零“ 值，不会出现 C/C++ 那样的随机值。\nGo 的编译器同样可以根据变量的值来自动推断其类型：\nvar a = 12 Go 还提供简短声明语法 := ，不过只可以用于声明函数体内的局部变量，不能用在全局变量的声明与赋值，例如：\na := 1 //等价于 var a = 1 需要注意的是 := 是声明并初始化，所以 := 左边必须是一个新值，否则会出现编译错误。\n基本类型和运算符 布尔类型 var a bool = true 布尔类型的值只可以是 true 或者 false ，两个类型相同的值可以使用 == 和 != 运算符来比较并且得到一个布尔类型的值。Go 是一门强类型的语言，所以必须是相同类型的两个值才可以进行比较。如果是一个字面量和一个值比较，值的类型必须和字面量类型兼容。\nvar a = 10 if a == 1 { // 可以  } if a == 3.5 { // 编译报错  } 数字类型 Go 支持整型、浮点型数字和复数类型。\n整形  int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64  int 和 uint 在 32 位系统上是 32 位（4个字节），在64位操作系统上是 64 位（8个字节）。其他如 int8 这种都是与系统无关的类型，有固定的大小，从类型的名称就可以看出其大小。\n浮点型  float32 float64  float32 精确到小数点后 7 位，float64 精确到小数点后 15 位。应该尽可能地使用 float64，因为 math 包中所有有关数学运算的函数都会要求接收这个类型。\n复数 Go 提供以下复数类型：\n complex64 complex128  复数使用 re+imI 来表示，其中 re 代表实数部分，im 代表虚数部分，I 代表根号负 1 。\nvar c complex64 = 5 + 10i 内置的 complex 函数用于构建复数,内建的 real 和 imag 函数分别返回复数的实部和虚部。\nvar\tx complex128 = complex(1, 2)\t// 1+2i var\ty complex128 = complex(3, 4) // 3+4i fmt.Println(x*y) // \u0026#34;(-5+10i)\u0026#34; fmt.Println(real(x*y)) // \u0026#34;-5\u0026#34; fmt.Println(imag(x*y)) // \u0026#34;10\u0026#34; 字符类型 Go 中字符类型 byte 只是整数的特殊用例，byte 类型是 uint8 的别名。\nvar ch1 byte = \u0026#39;a\u0026#39; var ch2 byte = 65 关系运算符 Go 中拥有以下逻辑运算符，和其他语言的用法相同，运算结果总是为布尔值。\n != 、 == \u0026lt; 、 \u0026lt;= 、 \u0026gt; 、 \u0026gt;= \u0026amp;\u0026amp; 、 ||  逻辑运算符 \u0026amp;\u0026amp; 、 || 逻辑与和逻辑或同样支持短路法则。\n 算术运算符 Go 提供常用的整数和浮点数的二元运算符： + 、 - 、* 、/ 。\nvar a = 5 / 2 // 2 var b = 5 % 2 // 1 对于语句 a = a + 2 ，同样提供 -= 、 *= 、 /= 、 %= 运算符来简化写法。\nvar a = 1 a = a + 2 a += 3 ++ 、 \u0026ndash; 一元操作符在 Go 中只能用于后缀，并且只能作为语句而非表达式。\ni++ // 正确 ++i // 编译报错，不能用于前缀  a = i++ // 编译报错，不能作为表达式 字符串 Go 语言的字符串是一个以UTF8编码的字节序列，并且一旦创建就无法更改。无法像 C/C++ 那样通过索引改变字符串中的某个字符（取字符串某个字节的地址也是非法的 \u0026amp;str[i] ），并且 Go 中的字符串是根据长度限定，不是特殊字符 \\0 。\nvar str string Go 语言的字符串如果声明时未初始化，则默认是 ”零“ 值，即空串 \u0026quot;\u0026quot; ，长度为0\nstr := \u0026#34;Hello \u0026#34; + \u0026#34;World\u0026#34; str += \u0026#34; ! \u0026#34; 字符串可以通过 + 号拼接，也可以使用 += 简写形式。\n数组 数组是一个有固定长度的且类型唯一的数据序列，\nvar arr [4]int fmt.Println(a[0]) // 打印第一个元素 0 fmt.Println(a[len(a)-1]) // 打印最后一个元素 0 同样，数组的每个元素都被初始化为元素类型对应的 ”零“ 值，在此处是 0 。\nvar\ta [3]int = [3]int{1, 2, 3} b := [...]int{ 1, 2, 3} 可以在声明数组时给定一组值来初始化数组，在数组长度位置用 \u0026ldquo;\u0026hellip;\u0026rdquo; 三个点来替代，代表数组的长度根据具体数值的个数来计算。\n把一个大数组通过函数传参会消耗大量内存，因为 Go 语言都是值传递，会将数组完整的拷贝一份。可以通过两种方法在避免：\n 传递数组的指针 使用切片  切片(slice) 切片是一个长度可变的数组，类似 C++ 的动态数组（vector）。切片的语法和数组很像，只是切片没有限定固定长度。\nvar a []int // 切片 var b [3]int // 数组 一个切片底层由三部分组成：指针、长度、容量。指针指向切片的第一个元素的地址，长度对应切片中元素的数量，容量是切片底层分配的连续内存空间可容纳元素的数量。切片提供 cap() 函数来计算其容量， len() 函数来计算其长度。\ns := []int{0, 1, 2, 3, 4, 5} fmt.Println(s[:2]) // [0 1] fmt.Println(s[2:]) // [2 3 4 5] fmt.Println(s) // [0 1 2 3 4 5] 一个 ”零“ 值的切片是nil，长度和容量都为0。\nvar s []int // len(s) == 0, s == nil s = nil // len(s) == 0, s == nil s = []int(nil) // len(s) == 0, s == nil s = []int{} // len(s) == 0, s !=nil 我们可以通过 make 函数创建以一个指定元素类型、长度和容量的切片。容量参数可以不传，Go 会按照指定的长度和类型初始化。\n// make([]T, len, cap)\tmake([]int, 3) // [0,0,0] make([]int, 3, 5) // [0,0,0, *, *] Go 内置的 append 函数可以向切片追加元素。\nvar s []int s = append(s, 2) append 函数底层在每次操作之前都会先检查切片的容量，如果容量够，就会直接将新添加的元素复制到对应位置并将长度加1;如果容量不够，会先分配一个足够大的内存空间，然后将原来的切片内容和新添加的全部复制过去，再返回这个切片。\nMap Map 是一个无序的 key/value 的集合，类似于其他编程语言中的字典，哈希表。Map 和 切片一样在使用过程会自动扩容。\nvar m map[string]int v := make(map[string]int) v1 := make(map[string]int, 10) // 初始化容量为 10 a := map[string]int{ \u0026#34;abc\u0026#34;: 1, \u0026#34;def\u0026#34;: 2, } m[\u0026#34;test\u0026#34;] = 1 // 错误， 此时 m 是 nil fmt.Println(a[\u0026#34;abc\u0026#34;]) delete(a,\u0026#34;abc\u0026#34;) Map 可以使用 make 函数创建（可以选择在创建时指定容量），也可以通过map字面值的语法创建，同时还可以指定一些最初的 key/value。需要注意的是，未初始化的 map 的值是 nil，直接访问会出错。Map 中的元素通过key对应的下标语法访问。使用内置的delete函数可以删除元素。\nkey对应的下标语法访问时，通过如果key在map中是存在的,那么将得到与key对应的value。如果key不存在,那么将得到value对应类型的零值。但是元素类型为 int，就无法区分 0 了。为此，Go 提供了两个返回值来区分。\nv, ok := a[\u0026#34;test\u0026#34;] if\t!ok\t{ } 当 ok 为 false 时表示 Map 中找不到 key 等于 \u0026ldquo;test\u0026rdquo; 对应的元素。\n结构体 结构体是一种聚合的数据类型,是由零个或多个任意类型的值聚合成的实体。结构体定义的一般方式如下：\n// type identifier struct { // field1 type1 // field2 type2 // ... // }  type Abc struct { A int B int C int } var s Abc s.A = 1 s.B =2 使用内置的 new 函数可以给一个新的结构体变量分配内存，它返回指向已分配内存的指针。Go 中使用点符号获取结构体中的值：structname.fieldname = value 。实际上，在 Go 中无论是值类型还是指针类型都使用点符号，并没有 C/C++ 中的 -\u0026gt; 符号。\nvar t *Abc t = new(Abc) t2 := new(Abc) t.A = 2 t2.B = 3 结构体初始化主要有两种方法，一种是按照结构体成员定义的顺序为每个成员指定一个面值，这样如果结构体成员顺序又调整就需要改动所有初始化结构体的地方了，所以不太建议着一种;另一种就是，以成员名字和对应值来初始化。\ntype Abc struct { A int B int C int } s := Abc{1, 2, 3} s2 := Abc{ A : 1, B : 2, C : 3, } 函数 Go 里面有三种类型的函数：\n 普通的命名函数 匿名函数或者lambda函数 方法  函数参数和返回值 除 main() 、init() 函数外，Go 中其它所有类型的函数都可以有参数与返回值。\n函数参数、返回值及它们的类型被统称为函数签名。函数可以返回零个或多个值，相较于 C/C++ 等语言多值返回是 Go 的一大特性。\nfunc Test1(a, b int) int { return a + b } func Test2(a, b int) (int, int) { return b, a } 命名返回值 命名返回值作为结果形参被初始化为相应类型的零值，当需要返回的时候，我们只需要一条简单的不带参数的return语句。\nfunc Test3() (ret1 int, ret2 int){ ret1 = 1 ret2 = 2 return } 按值传递 Go 中默认都是使用按值传递，也就是说函数传参时都会拷贝一个副本出来到函数内部使用。\n如果不希望拷贝带来太大的性能开销，或者希望可以改变参数的内容，可以传递指针。\na := 1 f(\u0026amp;a) 指针也是一个变量，函数传参时同样时按值传递，只不过拷贝的是指针，也就是变量的地址。指针通常是一个32位或者64位的值，所以性能开销比传递一些结构体要小的多。\n在 Go 中也有一些按引用传递的类型：切片（sleice）、字典（mao）、接口（interface）、通道（chan）。其实，这些类型的底层同样是使用指针来实现的。\n例如，切片的底层是一个指针指向一片内存的首地址，len 记录已用内存的长度，cap 记录切片的容量。在传递切片时，仅仅会将这三个值拷贝一份，而不会去拷贝切片里的全部数据。所以，我们在使用 Go 自带的这些引用类型时可以直接传参，无需担心性能开销而传递指针。\ntype slice struct { array unsafe.Pointer len int cap int } 变长参数 Go 中支持变长参数，在函数的最后一个参数采用 \u0026hellip;type 的形式，可以传递 0 个或者多个参数。\nfunc f(a int , args ...int) { } ... f(1, 23, 45, 67, 89) 如果参数是数组或者切片，可以通过 val\u0026hellip; 来自动展开。\nsl := []int{1, 2, 3} f(1, sl...) defer 关键字 defer 允许我们推迟到函数返回之前（或任意位置执行 return 语句之后）一刻才执行某个语句或函数。\nfunc a() { i := 0 defer fmt.Println(i) // 1 \ti++ return } 当有多个 defer 行为被注册时，它们会以 defer 的出现顺序逆序执行（类似栈，即后进先出）。 使用 defer 会有一定的性能开销，但是 defer 在程序 panic 的时候，还保证会执行。所以通过我们会使用 defer 进行一些函数执行收尾工作。例如，关闭文件描述符，解锁等。\n闭包 Go 支持匿名函数，函数在 Go 中是一等公民，可以将函数赋值给变量，在需要时再执行。\nf = func() { fmt.Println(\u0026#34;func\u0026#34;) } f() // 直接执行 func() { fmt.Println(\u0026#34;func\u0026#34;) }() 匿名函数同样被称之为闭包，闭包可使得某个函数捕捉到一些外部状态。例如：引用一些外部变量，这些变量可以在闭包中被操作，生命周期延长至和闭包一样。\nfunc fun() func() { i := 1 return func() { i++ fmt.Println(i) } } func fun1(f func()) { f() } func main() { fmt.Println(\u0026#34;Hello World\u0026#34;) f := fun() f() // 2 \tf() // 3  fun1(f) // 4 } init 函数 init 函数是 Go 中一个特殊函数，每个包都可以有 init 函数，它先于 main 函数执行，用于做一些初始化操作。\ninit 函数的主要特点：\n init 函数在全局变量初始化之后，main 函数执行前自动执行，不能被手动调用 init 函数没有参数和返回值 每个包可以包含多个 init 函数，同一个包的 init 函数间的执行顺序不确定 不同包内的 init 函数按照导入包的顺序执行  package main import ( \u0026#34;fmt\u0026#34; ) var T int = a() func a() int { fmt.Println(\u0026#34;var T int64 = a()\u0026#34;) return 1 } func init() { fmt.Println(\u0026#34;init()\u0026#34;) } func main() { fmt.Println(\u0026#34;main()\u0026#34;) } 输出：\nvar T int64 = a() init() main() 并发编程 并发与并行 并发与并行是不同的。一个并发程序可以在一个单核处理器使用多个线程来执行多个任务，就好像这些任务同时执行一样。但是同一时间点只有一个任务在执行，是操作系统内核在调度不同的线程交叉执行使得它们好像在同时执行一样。而并行是指在同一时间点程序同时执行多个任务，是物理上真正的同时执行，而非看着像。\n并行是一种利用多处理器提高运行速度的能力。所以并发程序可以是并行的，设计优秀的并发程序运行在多核或者多处理器上也可以实现并行。\n多线程程序可以编写出高并发应用，重复利用多核处理器性能，但是编写多线程程序非常容易出错，最主要的问题是内存中的数据共享。多线程程序在多核处理器上的并行执行和操作系统对线程调度的随机性，导致这多个线程中共享的数据会以无法预知的方式进行操作。\n传统解决方案是同步不同的线程，即对数据加锁。这样在同一时间点就只有一个线程可以变更数据，但是这使得原来可以在多核处理器上并行执行的程序串行化了，无法重复利用多核处理器的能力。\nGo 提供的并发编程特性 Go 语言原生支持程序的并发执行。Go 语言提供 协程 (goroutine) 与通道 (channel) 来支持并发编程。\nGo 的协程和其他语言中的协程是不太一样。Go 的协程意味着并行，或是可以并行，而其他语言的协程一般来说是单线程串形化执行的，需要程序主动让出当前CPU。\n协程 goroutine Go 的协程和操作系统线程不是一对一的关系，一个协程对应于一个或多个线程，映射（多路复用，执行于）在它们之上。也就是说一个协程可能会在多个操作系统线程上都运行过，同一个操作系统线程会运行多个 Go 协程，Go 语言的协程调度器负责完成调度。\n操作系统线程上的协程时间片让我们可以使用少量的操作系统线程就能运行任意多个协程，而且 Go 运行时可以聪明的意识到哪些协程被阻塞了，暂时搁置它们并处理其他协程。比如，当系统调用（比如等待 I/O）阻塞协程时，当前协程会被挂起，其他协程会继续在其他线程上工作，当 I/O 事件到来，挂起的协程会自动恢复执行。\nGo 每个协程创建时占用4k栈内存，协程的栈会根据需要进行伸缩，不出现栈溢出，开发者不需要关心栈的大小。当协程结束的时候，它会静默退出，用来启动这个协程的函数不会得到任何的返回值。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func GoRun(i int) int { fmt.Println(\u0026#34;go \u0026#34;, i) return i } func main() { fmt.Println(\u0026#34;Hello World\u0026#34;) go func() { fmt.Println(\u0026#34;go\u0026#34;) }() go func(i int) { fmt.Println(\u0026#34;go \u0026#34;, i) }(1) go GoRun(2) time.Sleep(1*time.Second) } 输出 ：\nHello World go 2 go go 1 这个输出结果的顺序并不是固定的，因为 go 关键字启动的协程都是并发执行的。\nGo 程序 main() 函数也可以看做是一个协程，尽管它并没有通过 go 来启动。如果 main() 函数退出了，其他协程也会随之退出，这就是为什么上面的代码要在最后加上 time.Sleep(1*time.Second)。\n 在一个协程中，如果需要进行非常密集的运算，可以在运算循环中周期的使用 runtime.Gosched()。这会让出处理器，允许运行其他协程；它并不会使当前协程挂起，所以它会自动恢复执行。使用 Gosched() 可以使计算均匀分布，使通信不至于迟迟得不到响应。\n 通道 channel 协程间可以使用共享内存来实现通信，Go 提供 sync 包来实现协程同步，不过 Go 中还提供一种更优雅的方式：使用 channels 来同步协程。\n通道就像一个可以用于发送类型化数据的管道，Go 保障在任何给定时间内，通道内的一个数据只有一个协程可以对其访问，所以不会发生数据竞争。也就是说，Go 语言保障通道的发送和接受的原子性。\npackage main import \u0026#34;fmt\u0026#34; func main() { var ch chan int fmt.Println(ch)\t// \u0026lt;nil\u0026gt;  ch = make(chan int, 1) fmt.Println(ch, len(ch), cap(ch)) // 0xc00008c000 0 1 } 通道是引用类型，未初始化的通道的值是nil，使用 make 分配内存 ch := make(chan int)。\n通道只能传输一种类型的数据，比如 chan int 或者 chan string，所有的类型都可以用于通道，空接口 interface{} 也可以。通道在 Go 中同样是一等公民，可以存储在变量中，作为函数的参数传递，作为函数返回值，甚至可以通过通道发送它们自身。\n通道使用 \u0026lt;- 符号来发送或是接受数据，信息按照箭头的方向流动。\nch \u0026lt;- int1 表示用通道 ch 发送变量 int1。\nint2 := \u0026lt;- ch 表示变量 int2 从通道 ch接收数据。如果 int2 已经声明过，则应该写成 int2 = \u0026lt;- ch  。\n\u0026lt;- ch 表示获取通道的一个值，并且丢弃之，\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func sendData(ch chan int) { ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 ch \u0026lt;- 4 } func getData(ch chan int) { var input int for { input = \u0026lt;-ch fmt.Println(input) } } func main() { ch := make(chan int) go sendData(ch) go getData(ch) time.Sleep(1*time.Second) } 输出：\n1 2 3 4 通道是可以带缓冲的，ch := make(chan int, 5) 即通道里可以容纳 5 个 int 类型的值。ch := make(chan int) 默认是没有缓冲区的，即容量大小为1 。当通道数据满时，往通道中发送操作会阻塞，直到通道中有空闲的空间。当通知中没有数据时，从通道中接受数据的操作会被阻塞，直到通道缓冲区中有数据。\n将上面的例子稍作修改：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func sendData(ch chan int) { fmt.Println(\u0026#34;sendData\u0026#34;) ch \u0026lt;- 1 fmt.Println(\u0026#34;ch \u0026lt;- 1\u0026#34;) ch \u0026lt;- 2 fmt.Println(\u0026#34;ch \u0026lt;- 2\u0026#34;) ch \u0026lt;- 3 fmt.Println(\u0026#34;ch \u0026lt;- 3\u0026#34;) ch \u0026lt;- 4 fmt.Println(\u0026#34;ch \u0026lt;- 4\u0026#34;) } func main() { ch := make(chan int) go sendData(ch) time.Sleep(1 * time.Second) } 输出：\nsendData 因为没有接收通道 ch 数据，所以协程 sendData 一直阻塞在 ch \u0026lt;- 1，直到 main 函数 time.Sleep 结束后程序退出。\n将通道设为有缓冲区的，设置容量为2: ch := make(chan int, 2), 重新执行，输出如下：\nsendData ch \u0026lt;- 1 ch \u0026lt;- 2 下面验证一下接收数据阻塞的情况\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func getData(ch chan int) { var input int for { fmt.Println(\u0026#34;getData\u0026#34;) input = \u0026lt;-ch fmt.Println(input) } } func main() { ch := make(chan int, 2) go getData(ch) time.Sleep(1 * time.Second) } 输出：\ngetData 程序启动了一个协程来接收通道 ch 中的数据，但是没有操作来往通道中发送数据，所以协程 getData 一直阻塞在 input = \u0026lt;-ch，直到程序退出。\n通道创建的时候都是双向的，但是通道类型可以用注解来表示它只发送或者只接收，从而来限制协程对通道的操作。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func sendData(ch chan\u0026lt;- int) { ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 ch \u0026lt;- 4 } func getData(ch \u0026lt;-chan int) { var input int for { input = \u0026lt;-ch fmt.Println(input) } } func main() { ch := make(chan int) go sendData(ch) go getData(ch) time.Sleep(1 * time.Second) } 通道可以通过 close 显式关闭，如果通道类型被注解，只有发送类型的通道可以被关闭。对已经 close 过的通过再次 close 会导致运行时的 panic 。读取已经关闭的通道，会立即返回通道数据类型的零值。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func sendData(ch chan\u0026lt;- int) { ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 ch \u0026lt;- 4 close(ch) } func getData(ch \u0026lt;-chan int) { var input int for { input = \u0026lt;-ch fmt.Println(input) } } func main() { ch := make(chan int) go sendData(ch) go getData(ch) time.Sleep(1 * time.Second) } 输出：\n1 2 3 4 0 0 ... 上面的输出，会继续一直打印 0 ，直到程序退出。\nGo 提供方法来检测通道是否已经关闭：\nv, ok := \u0026lt;-ch 当通道已经关闭的时候，ok 为 false；通道打开时，ok 为 true 。\n还可以使用 for-range 来读取通道，这会自动检测通道是否关闭。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func sendData(ch chan\u0026lt;- int) { ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 ch \u0026lt;- 4 close(ch) } func getData(ch \u0026lt;-chan int) { var input int for input = range ch { fmt.Println(input) } fmt.Println(\u0026#34;getData exit\u0026#34;) } func main() { ch := make(chan int) go sendData(ch) go getData(ch) time.Sleep(1 * time.Second) } 输出：\n1 2 3 4 getData exit 从上面的例子可以看出，当通道被关闭时， for-range 循环会自动跳出，结束循环。\n现实的开发中，会运行很多的协程，可能需要从多个通道中接收或者发送数据，Go 可以使用 select 关键字来处理多个通道的问题。\nselect 监听进入通道的数据，如果所有的通道的都没有数据则会一直阻塞，直到有一个通道有数据；如果有多个可以处理，select 会随机选择一个处理；特别需要注意的是，如果所有的通道都没有数据，而且写了 default 语句，则会执行 default 。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func sendData1(ch chan\u0026lt;- int) { ch \u0026lt;- 1 ch \u0026lt;- 2 ch \u0026lt;- 3 ch \u0026lt;- 4 // close(ch) } func sendData2(ch chan\u0026lt;- string) { ch \u0026lt;- \u0026#34;a\u0026#34; ch \u0026lt;- \u0026#34;b\u0026#34; ch \u0026lt;- \u0026#34;c\u0026#34; ch \u0026lt;- \u0026#34;d\u0026#34; // close(ch) } func getData(ch1 \u0026lt;-chan int, ch2 \u0026lt;-chan string) { for { select { case v := \u0026lt;-ch1: fmt.Println(v) case v := \u0026lt;-ch2: fmt.Println(v) // default: \t// fmt.Println(\u0026#34;default\u0026#34;) \t} } } func main() { ch1 := make(chan int) ch2 := make(chan string) go sendData1(ch1) go sendData2(ch2) go getData(ch1, ch2) time.Sleep(1 * time.Second) } 输出：\n1 2 a b 3 c 4 d 如果将上面注释掉的 default 语句处的代码打开，则在正确接收所有通道的所有数据后会一直打印 default ，直到程序退出。\nselect 不会自动处理通道关闭的情况，如果将代码中关于 close 的代码注释打开，select 正确接收所有通道的所有数据后会只一直打印 0 和 \u0026quot;\u0026quot; (int 和 string 的零值)。case v,ok := \u0026lt;-ch1: 可以判断通道的开关情况。\n","permalink":"https://mogutou.xyz/posts/go/go-tutorials/","summary":"Hello World 我们以传统的“hello\tworld”案例开始吧。\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello World\u0026#34;) } Go的源文件以 .go 为后缀名，这些文件名均由小写字母（推荐做法）组成且不包含空格和其他特殊字符，如 main.go 。如果文件名由多个部分组成，则使用下划线 _ 对它们进行分隔，如 main_test.go 。\nGo是一门编译型语言,Go语言的工具链将源代码及其依赖转换成计算机的机器指令。Go语言提供的工具都通过一个单独的命令 go\t调用，go 命令有一系列子命令。\n$ go help Go is a tool for managing Go source code. Usage: go \u0026lt;command\u0026gt; [arguments] The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages .","title":"Golang 极简入门教程"},{"content":"微服务应用使用容器部署非常方便，但是当应用服务注册自身地址(ip:port)到服务注册中心的时候，如果注册的是容器内的ip，别的服务是无法访问到的。\n解决这个问题，可以在运行容器的时候指定网络模式为 host (\u0026ndash;net=host) ，这样就可以跳过 Docker 的独立网络栈，直接通过本机IP端口就可以访问，但是这样会大量占用本地端口。\n最好的场景还是后端服务都在容器网络中，仅 API 网关暴露一个端口供外部访问，但是同时还后端服务还需要能实现跨机器的网络连通。\n早期 Docker 本身的容器网络本身并不支持跨机器，也就是说明如果容器部署在不同的节点（服务器）上面，只能通过暴露端口到宿主机上，再通过宿主机之间进行通信。Docker 12.0 之后的版本自带 Docker Swarm，Docker Swarm 的 Overlay 网络驱动可以实现跨主机网络通信。Kubernetes 固然好，但是同时也非常重，学习成本也很大，Swarm 在小项目中还是有用武之地的。\ndokcer swarm 集群搭建 准备两台安装有 docker 的机器： 192.168.0.1 192.168.0.2\n192.168.0.1 创建master节点\n# docker swarm init # docker swarm join \\ --token SWMTKN-1-3uu3gjkdt6xgk06wd1c9gfog8xec99ga69ilcclyzyk181n5ki-6f7frw75gvpdwsl1yvpf885lw \\  192.168.0.1:2377 This node joined a swarm as a worker. 复制上面的 docker swarm join \u0026hellip; 在 192.168.0.2 上执行，即将本机加入 swarm 集群。\n至此，我们已经创建了一个最基础的 swarm 的集群，执行命令查看：\n# docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS r76ighlnw0p2r0tbd9wmoqaep server2 Ready Active rzqbzl58hlu89xoty4cedn0er * server1 Ready Active Leader 创建 overlay 网络 先创建一个可以跨机器的 overlay 网络\ndocker network create -d overlay my_net 部署应用服务 部署服务注册中心 consul 在服务器 192.168.0.1 中使用 Docker 简单部署一个使用。\ndocker run --name consul -d -p 8500:8500/tcp consul agent -server -ui -bootstrap-expect=1 -client=0.0.0.0 部署 API 网关 采用 micro 官方的 micro api，不了解 micro 的可以看我之前的博客，或者去 micro 官方仓库查看。\ndocker service create --replicas 4 --publish published=8898,target=8080 --name micro-p -e MICRO_REGISTRY=consul -e MICRO_REGISTRY_ADDRESS=192.168.0.1:8500 -e MICRO_API_HANDLER=http --network=my_net microhq/micro:latest api 部署后端服务 编写一个简单的 micro web 服务\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/micro/go-micro/web\u0026#34; ) type Say struct{} func (s *Say) Anything(c *gin.Context) { log.Print(\u0026#34;Received Say.Anything API request\u0026#34;) c.JSON(200, map[string]string{ \u0026#34;message\u0026#34;: \u0026#34;Hi, this is the Greeter API\u0026#34;, }) } func main() { // Create service \tservice := web.NewService( web.Name(\u0026#34;go.micro.api.greeter\u0026#34;), ) service.Init() // Create RESTful handler (using Gin) \tsay := new(Say) router := gin.Default() router.GET(\u0026#34;/greeter\u0026#34;, say.Anything) // Register Handler \tservice.Handle(\u0026#34;/\u0026#34;, router) // Run server \tif err := service.Run(); err != nil { log.Fatal(err) } } Dockerfile 如下：\nFROM alpine:latest RUN apk --no-cache add ca-certificates COPY hello-gin /hello-gin ENTRYPOINT /hello-gin LABEL Name=hello-gin Version=0.0.1 将 Docker build 出来推到自己的 Docker 仓库上，或者直接 pull 我的镜像。\n部署服务\n docker service create --replicas 2 --name hello-xx -e MICRO_REGISTRY=consul -e MICRO_REGISTRY_ADDRESS=192.168.0.1:8500 --network=xuxu_net xuxu123/hello-gin:v0.1.0 测试demo curl --request GET --url http://192.168.0.1:8080/greeter 总结 主要简单演练了一遍Docker Swarm 集群部署以及微服务部署的一个简单场景部署。相较于 K8S 的强大功能，Swarm 似乎显得有些多余，但是 Swarm 的简单明了在小厂中未必有没有用武之地吧。\n","permalink":"https://mogutou.xyz/posts/docker/docker-swarm/","summary":"微服务应用使用容器部署非常方便，但是当应用服务注册自身地址(ip:port)到服务注册中心的时候，如果注册的是容器内的ip，别的服务是无法访问到的。\n解决这个问题，可以在运行容器的时候指定网络模式为 host (\u0026ndash;net=host) ，这样就可以跳过 Docker 的独立网络栈，直接通过本机IP端口就可以访问，但是这样会大量占用本地端口。\n最好的场景还是后端服务都在容器网络中，仅 API 网关暴露一个端口供外部访问，但是同时还后端服务还需要能实现跨机器的网络连通。\n早期 Docker 本身的容器网络本身并不支持跨机器，也就是说明如果容器部署在不同的节点（服务器）上面，只能通过暴露端口到宿主机上，再通过宿主机之间进行通信。Docker 12.0 之后的版本自带 Docker Swarm，Docker Swarm 的 Overlay 网络驱动可以实现跨主机网络通信。Kubernetes 固然好，但是同时也非常重，学习成本也很大，Swarm 在小项目中还是有用武之地的。\ndokcer swarm 集群搭建 准备两台安装有 docker 的机器： 192.168.0.1 192.168.0.2\n192.168.0.1 创建master节点\n# docker swarm init # docker swarm join \\ --token SWMTKN-1-3uu3gjkdt6xgk06wd1c9gfog8xec99ga69ilcclyzyk181n5ki-6f7frw75gvpdwsl1yvpf885lw \\  192.168.0.1:2377 This node joined a swarm as a worker. 复制上面的 docker swarm join \u0026hellip; 在 192.168.0.2 上执行，即将本机加入 swarm 集群。\n至此，我们已经创建了一个最基础的 swarm 的集群，执行命令查看：\n# docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS r76ighlnw0p2r0tbd9wmoqaep server2 Ready Active rzqbzl58hlu89xoty4cedn0er * server1 Ready Active Leader 创建 overlay 网络 先创建一个可以跨机器的 overlay 网络","title":"dokcer swarm 部署go-micro微服务应用"},{"content":"hystrix-go hystrix是Netflix开源的一个JAVA项目，不过GitHub也有golang的实现版本hystrix-go\nhystrix-dashboard hystrix并没有自带一个仪表盘，无法直观的查看接口的健康状况。所以，我们采用GitHub的一个开源实现hystrix-dashboard。\ndocker run --name hystrix-dashboard -d -p 8081:9002 mlabouardy/hystrix-dashboard:latest micro API网关插件 关于hystrix的工作原理，可以查阅相关资料，这里只讲解如何封装插件在micro API网关中使用。\nerr := hystrix.Do(\u0026quot;my_command\u0026quot;, func() error { // talk to other services return nil }, nil) 使用hystrix.Do() 同步API，第一个参数是command, 应该是与当前请求一一对应的一个名称，如入“GET-/test”。第二个参数传入一个函数，函数包含我我们自己的错误逻辑，当请求失败时应该返回error。hystrix会根据我们的失败率执行熔断策略。\n封装Handler // BreakerWrapper hystrix breaker func BreakerWrapper(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { name := r.Method + \u0026quot;-\u0026quot; + r.RequestURI log.Println(name) err := hystrix.Do(name, func() error { sct := \u0026amp;status_code.StatusCodeTracker{ResponseWriter: w, Status: http.StatusOK} h.ServeHTTP(sct.WrappedResponseWriter(), r) if sct.Status \u0026gt;= http.StatusBadRequest { str := fmt.Sprintf(\u0026quot;status code %d\u0026quot;, sct.Status) log.Println(str) return errors.New(str) } return nil }, nil) if err != nil { log.Println(\u0026quot;hystrix breaker err: \u0026quot;, err) return } }) } ... // 注册插件 plugin.Register(plugin.NewPlugin( plugin.WithName(\u0026quot;breaker\u0026quot;), plugin.WithHandler( hystrix.BreakerWrapper, ), )) ... 在 hystrix.Do 中，首先执行 h.ServeHTTP，该函数返回后，即请求执行完成。我们判断HTTP状态码，如果大于StatusBadRequest，则认为这次请求失败，返回一个错误，hystrix会收集错误，如果错误率达到某个阀值，就会触发断路器。 在做实验时，可以直接在main函数里设置hystrix的几个默认配置参数，方便看效果\n// hystrix-go/hystrix/settings.go // DefaultTimeout is how long to wait for command to complete, in milliseconds DefaultTimeout = 1000 // DefaultMaxConcurrent is how many commands of the same type can run at the same time DefaultMaxConcurrent = 10 // DefaultVolumeThreshold is the minimum number of requests needed before a circuit can be tripped due to health DefaultVolumeThreshold = 20 // DefaultSleepWindow is how long, in milliseconds, to wait after a circuit opens before testing for recovery DefaultSleepWindow = 5000 // DefaultErrorPercentThreshold causes circuits to open once the rolling measure of errors exceeds this percent of requests DefaultErrorPercentThreshold = 50 hystrix-go库还提供为每个commond动态设置配置的接口，我们可以通过这个接口结合配置中心，动态调节服务。\nhystrix.ConfigureCommand(\u0026quot;my_command\u0026quot;, hystrix.CommandConfig{ Timeout: 1000, MaxConcurrentRequests: 100, ErrorPercentThreshold: 25, }) 接入hystrix-dashboard docker run --name hystrix-dashboard -d -p 8081:9002 mlabouardy/hystrix-dashboard:latest  打开 http://localhost:8081/hystrix , 输入 http://{ip}:81/hystrix.stream , 此处ip为本机ip，因为hystrix-dashboard是容器启动的，无法直接访问本机127.0.0.1。\n Enable dashboard metrics In your main.go, register the event stream HTTP handler on a port and launch it in a goroutine. Once you configure turbine for your Hystrix Dashboard to start streaming events, your commands will automatically begin appearing.\nhystrixStreamHandler := hystrix.NewStreamHandler() hystrixStreamHandler.Start() go http.ListenAndServe(net.JoinHostPort(\u0026quot;\u0026quot;, \u0026ldquo;81\u0026rdquo;), hystrixStreamHandler)\n ","permalink":"https://mogutou.xyz/posts/go-micro/go-micro-hystrix/","summary":"hystrix-go hystrix是Netflix开源的一个JAVA项目，不过GitHub也有golang的实现版本hystrix-go\nhystrix-dashboard hystrix并没有自带一个仪表盘，无法直观的查看接口的健康状况。所以，我们采用GitHub的一个开源实现hystrix-dashboard。\ndocker run --name hystrix-dashboard -d -p 8081:9002 mlabouardy/hystrix-dashboard:latest micro API网关插件 关于hystrix的工作原理，可以查阅相关资料，这里只讲解如何封装插件在micro API网关中使用。\nerr := hystrix.Do(\u0026quot;my_command\u0026quot;, func() error { // talk to other services return nil }, nil) 使用hystrix.Do() 同步API，第一个参数是command, 应该是与当前请求一一对应的一个名称，如入“GET-/test”。第二个参数传入一个函数，函数包含我我们自己的错误逻辑，当请求失败时应该返回error。hystrix会根据我们的失败率执行熔断策略。\n封装Handler // BreakerWrapper hystrix breaker func BreakerWrapper(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { name := r.Method + \u0026quot;-\u0026quot; + r.RequestURI log.Println(name) err := hystrix.Do(name, func() error { sct := \u0026amp;status_code.StatusCodeTracker{ResponseWriter: w, Status: http.StatusOK} h.","title":"Go Micro hystrix 熔断"},{"content":"服务健康检查 在微服务架构中，每个服务都会存在多个实例，可能部署在不同的主机中。因为网络或者主机等不确定因素，每个服务都可能会出现故障。我们需要能够监控每个服务实例的健康状态，当一个服务故障时，及时将它从注册中心删除。\n实现 micro提供两个方法可以直接实现健康检查功能\nmicro.RegisterTTL(time.Second*30), micro.RegisterInterval(time.Second*20), Interval就是间隔多久服务会重新注册 TTL就是注册服务的过期时间，如果服务挂了，超过过期时间后，注册中心也会将服务删除\nmicro内部服务注册的流程 当我们执行service.Run() 时内部会执行Start() 在Start函数中又会执行s.opts.Server.Start()，方法的实现在go-micro/server/rpc_server.go中。 我们跳转到内部server的Start方法 可以发现micro使用一个定时器按照间隔时间去自动重新注册。当服务意外故障，无法向注册中心重新注册时，如果超过了设定的TTL时间，注册中心就会将服务删除。\n修改源码 \tservice := grpc.NewService( micro.Name(\u0026quot;go.micro.srv.hello\u0026quot;), micro.WrapHandler(ocplugin.NewHandlerWrapper(t)), +\tmicro.RegisterTTL(time.Second*15), +\tmicro.RegisterInterval(time.Second*10), // micro.Version(\u0026quot;latest\u0026quot;), ) service := web.NewService( web.Name(name), web.Version(\u0026quot;lastest\u0026quot;), +\tweb.RegisterTTL(time.Second*15), +\tweb.RegisterInterval(time.Second*10), web.MicroService(grpc.NewService()), ) ","permalink":"https://mogutou.xyz/posts/go-micro/go-micro-ttl/","summary":"服务健康检查 在微服务架构中，每个服务都会存在多个实例，可能部署在不同的主机中。因为网络或者主机等不确定因素，每个服务都可能会出现故障。我们需要能够监控每个服务实例的健康状态，当一个服务故障时，及时将它从注册中心删除。\n实现 micro提供两个方法可以直接实现健康检查功能\nmicro.RegisterTTL(time.Second*30), micro.RegisterInterval(time.Second*20), Interval就是间隔多久服务会重新注册 TTL就是注册服务的过期时间，如果服务挂了，超过过期时间后，注册中心也会将服务删除\nmicro内部服务注册的流程 当我们执行service.Run() 时内部会执行Start() 在Start函数中又会执行s.opts.Server.Start()，方法的实现在go-micro/server/rpc_server.go中。 我们跳转到内部server的Start方法 可以发现micro使用一个定时器按照间隔时间去自动重新注册。当服务意外故障，无法向注册中心重新注册时，如果超过了设定的TTL时间，注册中心就会将服务删除。\n修改源码 \tservice := grpc.NewService( micro.Name(\u0026quot;go.micro.srv.hello\u0026quot;), micro.WrapHandler(ocplugin.NewHandlerWrapper(t)), +\tmicro.RegisterTTL(time.Second*15), +\tmicro.RegisterInterval(time.Second*10), // micro.Version(\u0026quot;latest\u0026quot;), ) service := web.NewService( web.Name(name), web.Version(\u0026quot;lastest\u0026quot;), +\tweb.RegisterTTL(time.Second*15), +\tweb.RegisterInterval(time.Second*10), web.MicroService(grpc.NewService()), ) ","title":"Go Micro 服务健康检查"},{"content":"在golang 中是不支持默认参数的，micro中有一种优雅的实现方法(并非 micro 首创)，叫做 Functional Options Patter。Functional Options 可以用来实现简洁的支持默认参数的函数方法。\noptions package server import ( \u0026#34;time\u0026#34; ) type Options struct { ConnectTimeOut time.Duration Name string Address string } type Option func(*Options) func newOptions(opt ...Option) Options { opts := Options{} for _, o := range opt { o(\u0026amp;opts) } if len(opts.Address) == 0 { opts.Address = DefaultAddress } if len(opts.Name) == 0 { opts.Name = DefaultName } if opts.ConnectTimeOut == time.Duration(0) { opts.ConnectTimeOut = DefaultConnectTimeOut } return opts } // Name server name func Name(n string) Option { return func(o *Options) { o.Name = n } } // Address server address func Address(a string) Option { return func(o *Options) { o.Address = a } } // ConnectTimeOut 连接超时时间 func ConnectTimeOut(t time.Duration) Option { return func(o *Options) { o.ConnectTimeOut = t } } server package server import \u0026#34;sync\u0026#34; var ( DefaultAddress = \u0026#34;:0\u0026#34; DefaultName = \u0026#34;server\u0026#34; DefaultConnectTimeOut = time.Second * 4 ) type Server struct { sync.RWMutex opts Options } func NewServer(opts ...Option) Server { options := newOptions(opts...) return \u0026amp;Server{ opts: options, } } func (s *Server) Options() Options { s.RLock() opts := s.opts s.RUnlock() return opts } func (s *Server) Init(opts ...Option) error { s.Lock() for _, opt := range opts { opt(\u0026amp;s.opts) } s.Unlock() return nil } func (s *Server) Start() error { return nil } func (s *Server) Stop() error { return nil } 使用 server := NewServer( Name(\u0026#34;test Name\u0026#34;), Address(\u0026#34;test Address\u0026#34;), ) ","permalink":"https://mogutou.xyz/posts/go/go-options/","summary":"在golang 中是不支持默认参数的，micro中有一种优雅的实现方法(并非 micro 首创)，叫做 Functional Options Patter。Functional Options 可以用来实现简洁的支持默认参数的函数方法。\noptions package server import ( \u0026#34;time\u0026#34; ) type Options struct { ConnectTimeOut time.Duration Name string Address string } type Option func(*Options) func newOptions(opt ...Option) Options { opts := Options{} for _, o := range opt { o(\u0026amp;opts) } if len(opts.Address) == 0 { opts.Address = DefaultAddress } if len(opts.Name) == 0 { opts.Name = DefaultName } if opts.ConnectTimeOut == time.Duration(0) { opts.","title":"Golang实现默认参数"},{"content":"micro API网关 micro API网关是基于go-micro开发的，具有服务发现，负载均衡和RPC通信的能力。\n业界普遍做法是将鉴权，限流，熔断等功能也纳入API网关。micro API网关本身是可插拔的，可以通过新增插件的方式加入其他功能。\nJWT (JSON Web Token) JWT是是微服务中常用的授权技术，关于JWT的技术原理可以参考阮一峰的博文\nJWT库封装  lib/token 目录下封装了JWT的库。有一点特殊的是，库中利用consul的KV存储和micro的go-config库实现了动态更新JWT的PrivateKey功能，实际生产中还是应该使用拥有发布和权限管理的配置中心。  go-config 是micro作者实现的一个可动态加载、可插拔的配置库，可以从多种格式文件或者远程服务获取配置。详情可以参考文档中文文档|英文文档 PrivateKey是JWT在编解码时使用的私钥，一旦泄漏，客户端便可以利用这个私钥篡改、伪造Token。所以一般生产环境中都必须具备动态更新私钥的能力，一旦发现泄漏可以立即更改，或者定期更换私钥，提高安全性。    // InitConfig 初始化 func (srv *Token) InitConfig(address string, path ...string) { consulSource := consul.NewSource( consul.WithAddress(address), ) srv.conf = config.NewConfig() err := srv.conf.Load(consulSource) if err != nil { log.Fatal(err) } value := srv.conf.Get(path...).Bytes() if err != nil { log.Fatal(err) } srv.put(value) log.Println(\u0026quot;JWT privateKey:\u0026quot;, string(srv.get())) srv.enableAutoUpdate(path...) } func (srv *Token) enableAutoUpdate(path ...string) { go func() { for { w, err := srv.conf.Watch(path...) if err != nil { log.Println(err) } v, err := w.Next() if err != nil { log.Println(err) } value := v.Bytes() srv.put(value) log.Println(\u0026quot;New JWT privateKey:\u0026quot;, string(srv.get())) } }() } 作者已经实现了consul的KV配置的插件，所以只需要导入这个库\u0026quot;github.com/micro/go-config/source/consul\u0026quot;，便可以直接读取consul中的配置。\n动态跟新实现就是利用go-config的watch方法，当consul KV里的配置更改，Watch函数返回再通过Next方法读取新数据。将watch 读取的操作起一个协程循环执行（没有考虑优雅退出），通过读写锁来保证操作安全。\n实现API网关插件 将JWT Token在HTTP头中携带，通过HTTP中间件过滤每一个HTTP请求，提取头中的Token鉴权，通过则继续执行，不通过就直接返回。\n//microservices/lib/wrapper/auth // JWTAuthWrapper JWT鉴权Wrapper func JWTAuthWrapper(token *token.Token) plugin.Handler { return func(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { log.Println(\u0026quot;auth plugin received: \u0026quot; + r.URL.Path) // TODO 从配置中心动态获取白名单URL if r.URL.Path == \u0026quot;/user/login\u0026quot; || r.URL.Path == \u0026quot;/user/register\u0026quot;{ h.ServeHTTP(w, r) return } tokenstr := r.Header.Get(\u0026quot;Authorization\u0026quot;) userFromToken, e := token.Decode(tokenstr) if e != nil { w.WriteHeader(http.StatusUnauthorized) return } log.Println(\u0026quot;User Name : \u0026quot;, userFromToken.UserName) r.Header.Set(\u0026quot;X-Example-Username\u0026quot;, userFromToken.UserName) h.ServeHTTP(w, r) }) } } ... // main.go func init() { token := \u0026amp;token.Token{} token.InitConfig(\u0026quot;127.0.0.1:8500\u0026quot;, \u0026quot;micro\u0026quot;, \u0026quot;config\u0026quot;, \u0026quot;jwt-key\u0026quot;, \u0026quot;key\u0026quot;) plugin.Register(plugin.NewPlugin( plugin.WithName(\u0026quot;auth\u0026quot;), plugin.WithHandler( auth.JWTAuthWrapper(token), ), )) } const name = \u0026quot;API gateway\u0026quot; func main() { cmd.Init() }  初始化我们封装JWT Token  func (srv *Token) InitConfig(address string, path ...string) token.InitConfig(\u0026quot;127.0.0.1:8500\u0026quot;, \u0026quot;micro\u0026quot;, \u0026quot;config\u0026quot;, \u0026quot;jwt-key\u0026quot;, \u0026quot;key\u0026quot;) \u0026ldquo;127.0.0.1:8500\u0026rdquo; 是本地consul 监听地址，path是可变参数，传递consul KV中的配置路径：micro/config/jwt-key。  注册插件  func Register(plugin Plugin) error //全局注册一个插件 func NewPlugin(opts ...Option) Plugin //生成一个插件 func WithName(n string) Option //设置插件的名字 func WithHandler(h ...Handler) Option //http handler中间件 注册一个新插件的时候，还可以定制其他操作，具体可以看作者的文档英文文档|中文文档\n在hander中将Token进行校验，如果鉴权成功，则调用\th.ServeHTTP(w, r) ，此时micro会调用下一个hander。 如果鉴权失败，就修改状态码w.WriteHeader(http.StatusUnauthorized)， 不调用 h.ServeHTTP(w, r)，此时链式调用中断，micro框架不会调用剩下的hander。\ngithub完整代码地址\n","permalink":"https://mogutou.xyz/posts/go-micro/go-micro-gateway-jwt/","summary":"micro API网关 micro API网关是基于go-micro开发的，具有服务发现，负载均衡和RPC通信的能力。\n业界普遍做法是将鉴权，限流，熔断等功能也纳入API网关。micro API网关本身是可插拔的，可以通过新增插件的方式加入其他功能。\nJWT (JSON Web Token) JWT是是微服务中常用的授权技术，关于JWT的技术原理可以参考阮一峰的博文\nJWT库封装  lib/token 目录下封装了JWT的库。有一点特殊的是，库中利用consul的KV存储和micro的go-config库实现了动态更新JWT的PrivateKey功能，实际生产中还是应该使用拥有发布和权限管理的配置中心。  go-config 是micro作者实现的一个可动态加载、可插拔的配置库，可以从多种格式文件或者远程服务获取配置。详情可以参考文档中文文档|英文文档 PrivateKey是JWT在编解码时使用的私钥，一旦泄漏，客户端便可以利用这个私钥篡改、伪造Token。所以一般生产环境中都必须具备动态更新私钥的能力，一旦发现泄漏可以立即更改，或者定期更换私钥，提高安全性。    // InitConfig 初始化 func (srv *Token) InitConfig(address string, path ...string) { consulSource := consul.NewSource( consul.WithAddress(address), ) srv.conf = config.NewConfig() err := srv.conf.Load(consulSource) if err != nil { log.Fatal(err) } value := srv.conf.Get(path...).Bytes() if err != nil { log.Fatal(err) } srv.put(value) log.Println(\u0026quot;JWT privateKey:\u0026quot;, string(srv.get())) srv.enableAutoUpdate(path...) } func (srv *Token) enableAutoUpdate(path .","title":"Go Micro API网管增加 JWT 鉴权"},{"content":"安装jaeger jaeger提供一个all in one 的docker镜像，可以快速搭建实验环境\ndocker run -d --name jaeger -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:1.6 OpenTracing OpenTracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。 OpenTracing提供了用于运营支撑系统的和针对特定平台的辅助程序库。 jaeger兼容OpenTracing API，所以我们使用OpenTracing的程序库可以方便的替换追踪工具。 OpenTracing中文文档\njaeger使用 封住一下jaeger的初始化操作方便使用，详细用法可以查看 jaeger-client-go\n// lib/tracer // NewTracer 创建一个jaeger Tracer func NewTracer(servicename string, addr string) (opentracing.Tracer, io.Closer, error) { cfg := jaegercfg.Configuration{ ServiceName: servicename, Sampler: \u0026amp;jaegercfg.SamplerConfig{ Type: jaeger.SamplerTypeConst, Param: 1, }, Reporter: \u0026amp;jaegercfg.ReporterConfig{ LogSpans: true, BufferFlushInterval: 1 * time.Second, }, } sender, err := jaeger.NewUDPTransport(addr, 0) if err != nil { return nil, nil, err } reporter := jaeger.NewRemoteReporter(sender) // Initialize tracer with a logger and a metrics factory tracer, closer, err := cfg.NewTracer( jaegercfg.Reporter(reporter), ) return tracer, closer, err } func main() { t, io, err := tracer.NewTracer(\u0026quot;tracer\u0026quot;, \u0026quot;\u0026quot;) if err != nil { log.Fatal(err) } defer io.Close() opentracing.SetGlobalTracer(t) } opentracing.SetGlobalTracer(t) 方法执行会将jaeger tracer注册到全局，接下来只需要使用opentracing 的标准API便可以了。 如果不想使用jaeger了，想替换成其他分布式追踪工具，只需要工具支持opentracing标准，并将main函数的SetGlobalTracer操作替换即可，其他文件都不需要更改。\nmicro链路追踪插件 micro自带的opentracing插件 在micro自带的插件中已经有opentracing的插件了，包含server，client等，不过这个插件只能go-micro构建的微服务（api，srv）中使用。因为micro网关有一个独立的插件系统，但是并没有提供opentracing相关的插件。\n micro/go-plugins/wrapper/trace/opentracing/opentracing.go\n 我们可以在构建服务的时候直接使用，只需要在服务初始化时增加一行函数就可以了。\nservice := micro.NewService( micro.Name(name), micro.Version(\u0026quot;latest\u0026quot;), micro.WrapHandler(ocplugin.NewHandlerWrapper(opentracing.GlobalTracer())), ) srv/user/main.go 目录下的user 服务是一个完整的使用实例。\n为micro网关增加opentracing插件 实现原理 外部HTTP请求首先经过API网关，网关生成第一个SpanContexts并且通过HTTP头传递到聚合层的API服务，这边需要我们实现一个插件去做这件事，原理很简单，拦截每一次请求添加信息就可以了。 查看micro自带的opentracing插件，可以发现是通过golang的context传递，micro的RPC已经封装好了通过context在跨进程服务间传递SpanContexts机制，所以我们需要在API服务层实现一个插件，从HTTP头中取出SpanContexts并按照micro自带的方式注入golang context。\n// micro opentracing插件中wHandlerWrappe // NewHandlerWrapper accepts an opentracing Tracer and returns a Handler Wrapper func NewHandlerWrapper(ot opentracing.Tracer) server.HandlerWrapper { return func(h server.HandlerFunc) server.HandlerFunc { return func(ctx context.Context, req server.Request, rsp interface{}) error { name := fmt.Sprintf(\u0026quot;%s.%s\u0026quot;, req.Service(), req.Endpoint()) ctx, span, err := traceIntoContext(ctx, ot, name) if err != nil { return err } defer span.Finish() return h(ctx, req, rsp) } } } micro API网关插件  lib/wrapper/tracer/opentracing/stdhttp/stdhttp.go\n 和实现JWT鉴权插件一样，实现一个HTTP中间件通过mciro的插件机制全局注册就可以实现拦截每次请求并处理。\n// TracerWrapper tracer wrapper func TracerWrapper(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { spanCtx, _ := opentracing.GlobalTracer().Extract(opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(r.Header)) sp := opentracing.GlobalTracer().StartSpan(r.URL.Path, opentracing.ChildOf(spanCtx)) defer sp.Finish() if err := opentracing.GlobalTracer().Inject( sp.Context(), opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(r.Header)); err != nil { log.Println(err) } sct := \u0026amp;status_code.StatusCodeTracker{ResponseWriter: w, Status: http.StatusOK} h.ServeHTTP(sct.WrappedResponseWriter(), r) ext.HTTPMethod.Set(sp, r.Method) ext.HTTPUrl.Set(sp, r.URL.EscapedPath()) ext.HTTPStatusCode.Set(sp, uint16(sct.Status)) if sct.Status \u0026gt;= http.StatusInternalServerError { ext.Error.Set(sp, true) } }) }  Tracer相关的概念可以查看这个文档\n  opentracing.GlobalTracer().Extract 方法提取HTTP头中的spanContexts opentracing.ChildOf 方法基于提取出来的spanContexts生成新的child spanContexts opentracing.GlobalTracer().StartSpan 方法生成一个新的span github.com/opentracing/opentracing-go/ext 通过ext可以为追踪添加一些tag来展示更多信息，比如URL，请求类型(GET，POST\u0026hellip;), 返回码 sp.Finish() 结束这一个span  API服务（使用gin）插件  lib/wrapper/tracer/opentracing/gin2micro/gin2micro.go\n // TracerWrapper tracer 中间件 func TracerWrapper(c *gin.Context) { md := make(map[string]string) spanCtx, _ := opentracing.GlobalTracer().Extract(opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(c.Request.Header)) sp := opentracing.GlobalTracer().StartSpan(c.Request.URL.Path, opentracing.ChildOf(spanCtx)) defer sp.Finish() if err := opentracing.GlobalTracer().Inject(sp.Context(), opentracing.TextMap, opentracing.TextMapCarrier(md)); err != nil { log.Log(err) } ctx := context.TODO() ctx = opentracing.ContextWithSpan(ctx, sp) ctx = metadata.NewContext(ctx, md) c.Set(contextTracerKey, ctx) c.Next() statusCode := c.Writer.Status() ext.HTTPStatusCode.Set(sp, uint16(statusCode)) ext.HTTPMethod.Set(sp, c.Request.Method) ext.HTTPUrl.Set(sp, c.Request.URL.EscapedPath()) if statusCode \u0026gt;= http.StatusInternalServerError { ext.Error.Set(sp, true) } } // ContextWithSpan 返回context func ContextWithSpan(c *gin.Context) (ctx context.Context, ok bool) { v, exist := c.Get(contextTracerKey) if exist == false { ok = false return } ctx, ok = v.(context.Context) return } 基本操作流程和给micro编写的插件相同，但是有两点不同。其一，因为我使用gin开发API服务，所以基于gin的API。其二，因为micro内部提供通过golang context传递spanContexts的机制，所以将这边会将child spanContexts注入到gin 的context，在API服务通过micro提供RPC接口(生成的XX.micro.go文件中调用函数第一个参数都是context)调用其他服务时传入提取的context，如下：\n... ctx, ok := gin2micro.ContextWithSpan(c) if ok == false { log.Log(\u0026quot;get context err\u0026quot;) } res, err := s.helloC.Call(ctx, \u0026amp;helloS.Request{Name: \u0026quot;xuxu\u0026quot;}) ... 完整的实现细节可以查看，github仓库中 lib/wrapper/tracer/opentracing， 这里。\n完整体验 ","permalink":"https://mogutou.xyz/posts/go-micro/go-micro-jaeger/","summary":"安装jaeger jaeger提供一个all in one 的docker镜像，可以快速搭建实验环境\ndocker run -d --name jaeger -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:1.6 OpenTracing OpenTracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。 OpenTracing提供了用于运营支撑系统的和针对特定平台的辅助程序库。 jaeger兼容OpenTracing API，所以我们使用OpenTracing的程序库可以方便的替换追踪工具。 OpenTracing中文文档\njaeger使用 封住一下jaeger的初始化操作方便使用，详细用法可以查看 jaeger-client-go\n// lib/tracer // NewTracer 创建一个jaeger Tracer func NewTracer(servicename string, addr string) (opentracing.Tracer, io.Closer, error) { cfg := jaegercfg.Configuration{ ServiceName: servicename, Sampler: \u0026amp;jaegercfg.SamplerConfig{ Type: jaeger.SamplerTypeConst, Param: 1, }, Reporter: \u0026amp;jaegercfg.ReporterConfig{ LogSpans: true, BufferFlushInterval: 1 * time.","title":"Go Micro jaeger 分布式链路追踪"},{"content":"在分布式系统中，经常会有服务出现故障，所以良好的重试机制可以大大的提高系统的可用性。本文主要分析micro的客户端重试机制，以及实例演示。\nmicro 重试实现 micro框架提供方法设置客户端重试的次数。\nClient.Init( client.Retries(3), ) 当client请求失败时，客户端会根据selector的策略选择下一个节点重试请求。这样当一个服务实例故障时，客户端可以自动调用另一个实例。\n我们来看看micro 客户端内部重试的实现：\n go-micro\\client\\rpc_client.go\n func (r *rpcClient) Call(ctx context.Context, request Request, response interface{}, opts ...CallOption) error { ... //客户端call 调用函数， 在下面的循环中调用 call := func(i int) error { // call backoff first. Someone may want an initial start delay t, err := callOpts.Backoff(ctx, request, i) if err != nil { return errors.InternalServerError(\u0026quot;go.micro.client\u0026quot;, \u0026quot;backoff error: %v\u0026quot;, err.Error()) } // only sleep if greater than 0 if t.Seconds() \u0026gt; 0 { time.Sleep(t) } // 根据selector策略 选出 下一个节点 node, err := next() if err != nil \u0026amp;\u0026amp; err == selector.ErrNotFound { return errors.NotFound(\u0026quot;go.micro.client\u0026quot;, \u0026quot;service %s: %v\u0026quot;, request.Service(), err.Error()) } else if err != nil { return errors.InternalServerError(\u0026quot;go.micro.client\u0026quot;, \u0026quot;error getting next %s node: %v\u0026quot;, request.Service(), err.Error()) } // 客户端调用 err = rcall(ctx, node, request, response, callOpts) r.opts.Selector.Mark(request.Service(), node, err) return err } ch := make(chan error, callOpts.Retries+1) var gerr error //根据设定的**Retries**（重试次数）循环调用 call，如果执行成功，调用超时或者设置的**Retry**函数执行出错则直接退出，不继续重试 for i := 0; i \u0026lt;= callOpts.Retries; i++ { go func(i int) { ch \u0026lt;- call(i) }(i) select { case \u0026lt;-ctx.Done(): //超时 return errors.Timeout(\u0026quot;go.micro.client\u0026quot;, fmt.Sprintf(\u0026quot;call timeout: %v\u0026quot;, ctx.Err())) case err := \u0026lt;-ch: // if the call succeeded lets bail early if err == nil { //调用成功 return nil } retry, rerr := callOpts.Retry(ctx, request, i, err) if rerr != nil { return rerr } if !retry { return err } gerr = err } } return gerr } micro将选举下一个节点，RPC调用封装到一个匿名函数中，然后根据设定的重试次数循环调用。如果调用成功或者超时则直接返回，不继续重试。其中，当callOpts里设定的Retry函数执行失败，即第一个返回值为false，或者第二个返回值为err不会nil时，也会退出循环直接返回。\n我们来看下Retry是什么：\ntype CallOptions struct { Retry RetryFunc } client的CallOptions中定义了Retry，我们跳转到RetryFunc\n go-micro\\client\\retry.go\n // note that returning either false or a non-nil error will result in the call not being retried type RetryFunc func(ctx context.Context, req Request, retryCount int, err error) (bool, error) // RetryAlways always retry on error func RetryAlways(ctx context.Context, req Request, retryCount int, err error) (bool, error) { return true, nil } // RetryOnError retries a request on a 500 or timeout error func RetryOnError(ctx context.Context, req Request, retryCount int, err error) (bool, error) { if err == nil { return false, nil } e := errors.Parse(err.Error()) if e == nil { return false, nil } switch e.Code { // retry on timeout or internal server error case 408, 500: return true, nil default: return false, nil } } 从中我们可以发现，作者预实现了两个Retry函数：RetryAlways、RetryOnError。 RetryAlways直接返回true, nil，即不退出重试。 RetryOnError只有当e.Code（上一次RPC调用结果）为408或者500时才会返回true, nil，继续重试。 micro的默认Retry为RetryOnError，但是我们可以自定义并设置，下面的实验中将会演示。\n\tDefaultRetry = RetryOnError // DefaultRetries is the default number of times a request is tried DefaultRetries = 1 // DefaultRequestTimeout is the default request timeout DefaultRequestTimeout = time.Second * 5 实验 当客户端请求另一个服务时，如果被请求的服务突然挂了，而此时客户端依旧会去请求，重试时客户端会请求另一个实例（有一定几率还会请求同一个实例，因为默认的负载均衡策略是哈希随机）。\n我们修改api/user下的服务，在main函数中设置客户端重试。\nsClient := hystrixplugin.NewClientWrapper()(service.Options().Service.Client()) sClient.Init( client.WrapCall(ocplugin.NewCallWrapper(t)), client.Retries(3), client.Retry(func(ctx context.Context, req client.Request, retryCount int, err error) (bool, error) { log.Log(req.Method(), retryCount, \u0026quot; client retry\u0026quot;) return true, nil }), ) 然后，我们依次启动 micro网关，user API服务，hello SRV服务（启动两个实例）。\ncd micro \u0026amp;\u0026amp; make run cd api/user \u0026amp;\u0026amp; make run cd srv/hello \u0026amp;\u0026amp; make run cd srv/hello \u0026amp;\u0026amp; make run 我们通过kill -9 杀死其中一个hello服务，然后通过postman请求 GET 172.0.0.1:8080/user/test。\n[GIN] 2019/05/14 - 14:52:20 | 200 | 1.253576ms | 127.0.0.1 | GET /user/test 2019/05/14 14:52:48 Received Say.Anything API request 2019/05/14 14:52:48 0x19a1680 0 retry func 2019/05/14 14:52:48 msg:\u0026quot;Hello xuxu\u0026quot; [GIN] 2019/05/14 - 14:52:48 | 200 | 13.821193ms | 127.0.0.1 | GET /user/test 通过usr API服务的输出，我们可以看到重试一次后，客户端成功请求了另一个实例。\ngithub完整代码地址 https://github.com/Allenxuxu/microservices\n","permalink":"https://mogutou.xyz/posts/go-micro/go-micro-retry/","summary":"在分布式系统中，经常会有服务出现故障，所以良好的重试机制可以大大的提高系统的可用性。本文主要分析micro的客户端重试机制，以及实例演示。\nmicro 重试实现 micro框架提供方法设置客户端重试的次数。\nClient.Init( client.Retries(3), ) 当client请求失败时，客户端会根据selector的策略选择下一个节点重试请求。这样当一个服务实例故障时，客户端可以自动调用另一个实例。\n我们来看看micro 客户端内部重试的实现：\n go-micro\\client\\rpc_client.go\n func (r *rpcClient) Call(ctx context.Context, request Request, response interface{}, opts ...CallOption) error { ... //客户端call 调用函数， 在下面的循环中调用 call := func(i int) error { // call backoff first. Someone may want an initial start delay t, err := callOpts.Backoff(ctx, request, i) if err != nil { return errors.InternalServerError(\u0026quot;go.micro.client\u0026quot;, \u0026quot;backoff error: %v\u0026quot;, err.Error()) } // only sleep if greater than 0 if t.","title":"Go Micro 重试机制"},{"content":"Email - 120582243@qq.com\nGithub - https://github.com/Allenxuxu\n我的开源项目  🚀比标准库更快的 tcp/websocket 网络库：gev Go 微服务框架：stark  工作相关 就职于 字节跳动，有需要内推的小伙伴自取内推信息哈，也可以邮件联系我。\n字节跳动 内推\n社招： https://job.toutiao.com/s/eRUBN97\n校招内推码: DZ2MHGB 投递链接: https://jobs.toutiao.com/s/eRULyxU\n","permalink":"https://mogutou.xyz/about/","summary":"Email - 120582243@qq.com\nGithub - https://github.com/Allenxuxu\n我的开源项目  🚀比标准库更快的 tcp/websocket 网络库：gev Go 微服务框架：stark  工作相关 就职于 字节跳动，有需要内推的小伙伴自取内推信息哈，也可以邮件联系我。\n字节跳动 内推\n社招： https://job.toutiao.com/s/eRUBN97\n校招内推码: DZ2MHGB 投递链接: https://jobs.toutiao.com/s/eRULyxU","title":"平平无奇的程序员"}]